{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/train/'\n",
    "TEST_PATH = 'data/test/'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineDataset(Dataset):\n",
    "    def __init__(self, transform=None, path=TRAIN_PATH):\n",
    "        self.data = []\n",
    "        self.target = []\n",
    "        for file in os.listdir(path):\n",
    "            df = pd.read_csv(path + file, sep='|')\n",
    "            df = df.fillna(method='ffill') # if possible fill with previous value\n",
    "            df = df.fillna(0) # else fill with 0\n",
    "            sepsis_discovered = df[df['SepsisLabel'] == 1].drop('SepsisLabel', axis=1)\n",
    "            self.target.append(1 if not sepsis_discovered.empty else 0)\n",
    "            self.data.append(torch.Tensor(df.drop('SepsisLabel', axis=1).iloc[-1] if sepsis_discovered.empty else sepsis_discovered.iloc[0]))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.target[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size=40, hidden_size=128, output_size=2, activation=nn.ReLU(), dropout=0.2):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, int(hidden_size/2))\n",
    "        self.fc3 = nn.Linear(int(hidden_size/2), output_size)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.activation = activation\n",
    "        self.sequence = nn.Sequential(self.fc1, self.activation, self.dropout, self.fc2, self.activation, self.dropout, self.fc3, self.activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequence(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = BaselineDataset()\n",
    "test_set = BaselineDataset(path=TEST_PATH)\n",
    "train_dataloader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loss_fn, optimizer, model,  train_dataloader, test_dataloader, device=device, epochs=20, save_best=False, save_name='best_baseline_model.pt', accumulate_grad=False, batch_size=32):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_f1_scores = []\n",
    "    test_f1_scores = []\n",
    "    max_f1_score = 0\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_f1_score = 0\n",
    "        for j, data in enumerate(train_dataloader):\n",
    "            input, target = data\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            train_f1_score += f1_score(target.to(torch.device('cpu')), pred.to(torch.device('cpu')))\n",
    "            loss = loss_fn(output, target)\n",
    "            train_loss += loss.item()\n",
    "            if accumulate_grad:\n",
    "                loss = loss/batch_size\n",
    "            loss.backward()\n",
    "            if not accumulate_grad or j+1 % batch_size == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "        if accumulate_grad and j+1 % batch_size != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        train_f1_scores.append(train_f1_score/len(train_dataloader))\n",
    "        train_losses.append(train_loss/len(train_dataloader))\n",
    "        test_loss, test_f1_score = activity(model, test_dataloader, loss_fn, device)\n",
    "        test_losses.append(test_loss)\n",
    "        test_f1_scores.append(test_f1_score)\n",
    "        if save_best and test_f1_score > max_f1_score:\n",
    "            max_f1_score = test_f1_score\n",
    "            torch.save(model, save_name)\n",
    "        if ((i+1) % 1) == 0:\n",
    "            print('Epoch: {} Train Loss: {} Test Loss: {}'.format(i+1, train_losses[-1], test_losses[-1]))\n",
    "    return train_losses, test_losses, train_f1_scores, test_f1_scores\n",
    "\n",
    "def activity(model, test_dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    test_loss = 0\n",
    "    test_f1_score = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            input, target = data\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            preds.append(pred)\n",
    "            targets.append(target)\n",
    "            loss = loss_fn(output, target)\n",
    "            test_loss += loss.item()\n",
    "        return test_loss/len(test_dataloader), f1_score(torch.cat(targets).to(torch.device('cpu')), torch.cat(preds).to(torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 18:57:35,605]\u001b[0m A new study created in memory with name: no-name-ba0a5e70-77d0-43ac-be51-244e39f75e5e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2849283045530319 Test Loss: 0.26862093839592066\n",
      "Epoch: 10 Train Loss: 0.2996696368515491 Test Loss: 0.2580919856556688\n",
      "Epoch: 20 Train Loss: 0.44400461468696595 Test Loss: 0.2576608962406175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 18:58:24,456]\u001b[0m Trial 0 finished with value: 0.2193087008343266 and parameters: {'hidden_size': 34, 'activation': 'LeakyReLU', 'dropout': 0.45170610376247833, 'optimizer': 'SGD', 'lr': 0.0897902106926009}. Best is trial 0 with value: 0.2193087008343266.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.37481662158966067 Test Loss: 0.3779879840799033\n",
      "Epoch: 10 Train Loss: 0.37282218551635743 Test Loss: 0.3761645909696341\n",
      "Epoch: 20 Train Loss: 0.3696290683746338 Test Loss: 0.37402535218019456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 18:59:38,460]\u001b[0m Trial 1 finished with value: 0.3285556780595369 and parameters: {'hidden_size': 422, 'activation': 'Sigmoid', 'dropout': 0.31941093005908283, 'optimizer': 'Adagrad', 'lr': 0.012593939376746341}. Best is trial 1 with value: 0.3285556780595369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.22676582374572754 Test Loss: 0.22092872754501078\n",
      "Epoch: 10 Train Loss: 0.218454593783617 Test Loss: 0.21751990037175795\n",
      "Epoch: 20 Train Loss: 0.20051098237633705 Test Loss: 0.19550164428334266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:00:38,084]\u001b[0m Trial 2 finished with value: 0.4170905391658189 and parameters: {'hidden_size': 446, 'activation': 'LeakyReLU', 'dropout': 0.47250498039237493, 'optimizer': 'SGD', 'lr': 0.02326316582562312}. Best is trial 2 with value: 0.4170905391658189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.3851619474887848 Test Loss: 0.3882559073237946\n",
      "Epoch: 10 Train Loss: 0.3845842962265015 Test Loss: 0.3879026607773936\n",
      "Epoch: 20 Train Loss: 0.38428718719482424 Test Loss: 0.3874645753028675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:01:48,055]\u001b[0m Trial 3 finished with value: 0.0 and parameters: {'hidden_size': 176, 'activation': 'Sigmoid', 'dropout': 0.23671597001421707, 'optimizer': 'SGD', 'lr': 0.014167663049686991}. Best is trial 2 with value: 0.4170905391658189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.38449625544548033 Test Loss: 0.38754711516748985\n",
      "Epoch: 10 Train Loss: 0.3842476710319519 Test Loss: 0.3875892168035903\n",
      "Epoch: 20 Train Loss: 0.3841280940532684 Test Loss: 0.38770957657704336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:02:55,608]\u001b[0m Trial 4 finished with value: 0.0 and parameters: {'hidden_size': 64, 'activation': 'Sigmoid', 'dropout': 0.24537159804164427, 'optimizer': 'SGD', 'lr': 0.06929998144519978}. Best is trial 2 with value: 0.4170905391658189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.24955121126174926 Test Loss: 0.25449886975196984\n",
      "Epoch: 10 Train Loss: 0.2483787306547165 Test Loss: 0.2540035681507458\n",
      "Epoch: 20 Train Loss: 0.2486189647436142 Test Loss: 0.25391187045140007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:03:46,362]\u001b[0m Trial 5 finished with value: 0.25611175785797435 and parameters: {'hidden_size': 146, 'activation': 'Tanh', 'dropout': 0.17754799731228355, 'optimizer': 'SGD', 'lr': 0.08627811173332545}. Best is trial 2 with value: 0.4170905391658189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2455145938873291 Test Loss: 0.25228357953004565\n",
      "Epoch: 10 Train Loss: 0.2455427809715271 Test Loss: 0.2607932885329183\n",
      "Epoch: 20 Train Loss: 0.2441560864686966 Test Loss: 0.2511727026285836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:04:26,137]\u001b[0m Trial 6 finished with value: 0.3036649214659686 and parameters: {'hidden_size': 306, 'activation': 'Tanh', 'dropout': 0.020515591190151783, 'optimizer': 'SGD', 'lr': 0.08300026917518447}. Best is trial 2 with value: 0.4170905391658189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:05:11,597]\u001b[0m Trial 7 finished with value: 0.0 and parameters: {'hidden_size': 220, 'activation': 'ReLU', 'dropout': 0.4833368107324993, 'optimizer': 'Adam', 'lr': 0.05066326131481137}. Best is trial 2 with value: 0.4170905391658189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 152.97585046875437 Test Loss: 21.73873467948109\n",
      "Epoch: 10 Train Loss: 18.315893552377077 Test Loss: 6.938804901684054\n",
      "Epoch: 20 Train Loss: 23.625510354128103 Test Loss: 5.908177728672932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:05:54,964]\u001b[0m Trial 8 finished with value: 0.18604651162790695 and parameters: {'hidden_size': 109, 'activation': 'LeakyReLU', 'dropout': 0.45139004077246353, 'optimizer': 'Adam', 'lr': 0.09711447856925819}. Best is trial 2 with value: 0.4170905391658189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.38401195030212404 Test Loss: 0.3873433371702322\n",
      "Epoch: 10 Train Loss: 0.3840119439125061 Test Loss: 0.38724349720028645\n",
      "Epoch: 20 Train Loss: 0.38401193079948426 Test Loss: 0.38764286060302783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:06:51,237]\u001b[0m Trial 9 finished with value: 0.0 and parameters: {'hidden_size': 480, 'activation': 'Sigmoid', 'dropout': 0.34676808051679336, 'optimizer': 'Adagrad', 'lr': 0.09801225696711671}. Best is trial 2 with value: 0.4170905391658189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18929922153055667 Test Loss: 0.17973165281902487\n",
      "Epoch: 10 Train Loss: 0.16627933861017227 Test Loss: 0.16072332521025745\n",
      "Epoch: 20 Train Loss: 0.15465037134587764 Test Loss: 0.14861383418829296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:08:13,827]\u001b[0m Trial 10 finished with value: 0.6202749140893471 and parameters: {'hidden_size': 348, 'activation': 'LeakyReLU', 'dropout': 0.41090768272293177, 'optimizer': 'Adagrad', 'lr': 0.02689756244343235}. Best is trial 10 with value: 0.6202749140893471.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2148353850990534 Test Loss: 0.18717113469307795\n",
      "Epoch: 10 Train Loss: 0.16631976574957372 Test Loss: 0.16403953082407244\n",
      "Epoch: 20 Train Loss: 0.14417487835884094 Test Loss: 0.14635471988933535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:09:37,168]\u001b[0m Trial 11 finished with value: 0.6377295492487479 and parameters: {'hidden_size': 356, 'activation': 'LeakyReLU', 'dropout': 0.40262495100285284, 'optimizer': 'Adagrad', 'lr': 0.03020346078087209}. Best is trial 11 with value: 0.6377295492487479.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.19000061289668083 Test Loss: 0.179024915023448\n",
      "Epoch: 10 Train Loss: 0.17070935186743735 Test Loss: 0.16212807869473203\n",
      "Epoch: 20 Train Loss: 0.1525764712035656 Test Loss: 0.14708593600212386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:11:01,257]\u001b[0m Trial 12 finished with value: 0.6390728476821192 and parameters: {'hidden_size': 338, 'activation': 'LeakyReLU', 'dropout': 0.3764017818018412, 'optimizer': 'Adagrad', 'lr': 0.033593017104972686}. Best is trial 12 with value: 0.6390728476821192.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17287188583612442 Test Loss: 0.16815567834261128\n",
      "Epoch: 10 Train Loss: 0.15535460460484027 Test Loss: 0.15089368461943664\n",
      "Epoch: 20 Train Loss: 0.1413241145566106 Test Loss: 0.14171398425111756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:12:26,137]\u001b[0m Trial 13 finished with value: 0.6778846153846153 and parameters: {'hidden_size': 370, 'activation': 'LeakyReLU', 'dropout': 0.36156160832289447, 'optimizer': 'Adagrad', 'lr': 0.03769992108503013}. Best is trial 13 with value: 0.6778846153846153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.3991130017220974 Test Loss: 0.2722036193925352\n",
      "Epoch: 10 Train Loss: 0.3717410601735115 Test Loss: 0.26004715790501987\n",
      "Epoch: 20 Train Loss: 0.33174030215144157 Test Loss: 0.24481286920202425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:13:47,967]\u001b[0m Trial 14 finished with value: 0.0 and parameters: {'hidden_size': 253, 'activation': 'ReLU', 'dropout': 0.3412507916656817, 'optimizer': 'Adagrad', 'lr': 0.00031071736464097915}. Best is trial 13 with value: 0.6778846153846153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17087411305606365 Test Loss: 0.16648096490663272\n",
      "Epoch: 10 Train Loss: 0.15187885648310184 Test Loss: 0.1505317841701138\n",
      "Epoch: 20 Train Loss: 0.14102259194254876 Test Loss: 0.13957222557653443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:15:13,278]\u001b[0m Trial 15 finished with value: 0.6812652068126521 and parameters: {'hidden_size': 390, 'activation': 'LeakyReLU', 'dropout': 0.37891165798873416, 'optimizer': 'Adagrad', 'lr': 0.0413240412965081}. Best is trial 15 with value: 0.6812652068126521.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17438832492530346 Test Loss: 0.16957025204936918\n",
      "Epoch: 10 Train Loss: 0.154192311835289 Test Loss: 0.15094591044603636\n",
      "Epoch: 20 Train Loss: 0.14028562143445014 Test Loss: 0.14062286035928387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:16:38,227]\u001b[0m Trial 16 finished with value: 0.6751389992057188 and parameters: {'hidden_size': 404, 'activation': 'LeakyReLU', 'dropout': 0.3067065670027266, 'optimizer': 'Adagrad', 'lr': 0.04613986621278497}. Best is trial 15 with value: 0.6812652068126521.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1771072748452425 Test Loss: 0.16638176341335803\n",
      "Epoch: 10 Train Loss: 0.16022987003922462 Test Loss: 0.15163348226572948\n",
      "Epoch: 20 Train Loss: 0.14743117610812187 Test Loss: 0.1429197732240152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:18:05,520]\u001b[0m Trial 17 finished with value: 0.6797488226059654 and parameters: {'hidden_size': 495, 'activation': 'LeakyReLU', 'dropout': 0.40975030425513226, 'optimizer': 'Adagrad', 'lr': 0.04918386597037119}. Best is trial 15 with value: 0.6812652068126521.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.26842803676128385 Test Loss: 0.27489128789772244\n",
      "Epoch: 10 Train Loss: 0.2687501529932022 Test Loss: 0.2752906506815657\n",
      "Epoch: 20 Train Loss: 0.2684280328989029 Test Loss: 0.27509097459788523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:19:29,631]\u001b[0m Trial 18 finished with value: 0.0 and parameters: {'hidden_size': 495, 'activation': 'Tanh', 'dropout': 0.4391569714617947, 'optimizer': 'Adam', 'lr': 0.05566466683177075}. Best is trial 15 with value: 0.6812652068126521.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:21:01,385]\u001b[0m Trial 19 finished with value: 0.0 and parameters: {'hidden_size': 509, 'activation': 'ReLU', 'dropout': 0.40943205537386806, 'optimizer': 'Adagrad', 'lr': 0.059745390188541456}. Best is trial 15 with value: 0.6812652068126521.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2059317122220993 Test Loss: 0.18921796308633998\n",
      "Epoch: 10 Train Loss: 0.17769801118075848 Test Loss: 0.16475688763700735\n",
      "Epoch: 20 Train Loss: 0.15396029249727727 Test Loss: 0.15173325378197833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:22:28,065]\u001b[0m Trial 20 finished with value: 0.6162988115449916 and parameters: {'hidden_size': 457, 'activation': 'LeakyReLU', 'dropout': 0.47922390657237585, 'optimizer': 'Adagrad', 'lr': 0.04271838060031962}. Best is trial 15 with value: 0.6812652068126521.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17112687753140926 Test Loss: 0.1606268012307037\n",
      "Epoch: 10 Train Loss: 0.15626648894548417 Test Loss: 0.15218224893576993\n",
      "Epoch: 20 Train Loss: 0.1425434987425804 Test Loss: 0.1413905341356707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:23:53,612]\u001b[0m Trial 21 finished with value: 0.6789431545236189 and parameters: {'hidden_size': 388, 'activation': 'LeakyReLU', 'dropout': 0.3751933224518114, 'optimizer': 'Adagrad', 'lr': 0.03964292473329941}. Best is trial 15 with value: 0.6812652068126521.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18190853913724422 Test Loss: 0.169079914379615\n",
      "Epoch: 10 Train Loss: 0.1509508971273899 Test Loss: 0.14993719150797247\n",
      "Epoch: 20 Train Loss: 0.1381586949571967 Test Loss: 0.14168766602135885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:25:19,074]\u001b[0m Trial 22 finished with value: 0.6827309236947791 and parameters: {'hidden_size': 412, 'activation': 'LeakyReLU', 'dropout': 0.296903747741246, 'optimizer': 'Adagrad', 'lr': 0.039841740741997485}. Best is trial 22 with value: 0.6827309236947791.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16657928357422352 Test Loss: 0.16929072098503004\n",
      "Epoch: 10 Train Loss: 0.15263629840910434 Test Loss: 0.1476760519245943\n",
      "Epoch: 20 Train Loss: 0.1395728259459138 Test Loss: 0.1409390457450582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:26:45,823]\u001b[0m Trial 23 finished with value: 0.6841686555290375 and parameters: {'hidden_size': 434, 'activation': 'LeakyReLU', 'dropout': 0.29214275769667697, 'optimizer': 'Adagrad', 'lr': 0.0629631610596523}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18235781821608543 Test Loss: 0.17268962648729927\n",
      "Epoch: 10 Train Loss: 0.15694808662235737 Test Loss: 0.15490076142235304\n",
      "Epoch: 20 Train Loss: 0.14477835512161255 Test Loss: 0.14337242173310666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:28:07,817]\u001b[0m Trial 24 finished with value: 0.6775956284153005 and parameters: {'hidden_size': 284, 'activation': 'LeakyReLU', 'dropout': 0.28546467342703813, 'optimizer': 'Adagrad', 'lr': 0.062330784862292786}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 34.3919604590077 Test Loss: 30.068323336470243\n",
      "Epoch: 10 Train Loss: 85.90413860219233 Test Loss: 27.539079666137695\n",
      "Epoch: 20 Train Loss: 186.37239535171366 Test Loss: 217.48276575838034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:29:30,954]\u001b[0m Trial 25 finished with value: 0.48405560098119377 and parameters: {'hidden_size': 429, 'activation': 'LeakyReLU', 'dropout': 0.26729443983697165, 'optimizer': 'Adam', 'lr': 0.06972036968429418}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16419436393082143 Test Loss: 0.15649335807004866\n",
      "Epoch: 10 Train Loss: 0.14806106577813624 Test Loss: 0.1456705488669225\n",
      "Epoch: 20 Train Loss: 0.13713743136525153 Test Loss: 0.1387553744958327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:30:54,304]\u001b[0m Trial 26 finished with value: 0.6839126919967663 and parameters: {'hidden_size': 319, 'activation': 'LeakyReLU', 'dropout': 0.305535892637119, 'optimizer': 'Adagrad', 'lr': 0.041291181758935744}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.25088322892189024 Test Loss: 0.256703481173363\n",
      "Epoch: 10 Train Loss: 0.2459313102722168 Test Loss: 0.2525158100806105\n",
      "Epoch: 20 Train Loss: 0.24261206471920013 Test Loss: 0.24898119903981877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:32:18,064]\u001b[0m Trial 27 finished with value: 0.3092324805339266 and parameters: {'hidden_size': 327, 'activation': 'Tanh', 'dropout': 0.22911913437030634, 'optimizer': 'Adagrad', 'lr': 0.05377023820446066}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:33:40,722]\u001b[0m Trial 28 finished with value: 0.0 and parameters: {'hidden_size': 248, 'activation': 'ReLU', 'dropout': 0.29846451235052474, 'optimizer': 'Adagrad', 'lr': 0.04612142455120896}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 23.367789037908256 Test Loss: 2.3375620191164277\n",
      "Epoch: 10 Train Loss: 8.121075596943498 Test Loss: 17.806511817644562\n",
      "Epoch: 20 Train Loss: 16.893758900292735 Test Loss: 14.613501767794885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:35:00,124]\u001b[0m Trial 29 finished with value: 0.45019607843137255 and parameters: {'hidden_size': 300, 'activation': 'LeakyReLU', 'dropout': 0.199285046901717, 'optimizer': 'Adam', 'lr': 0.03416512387168805}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17746544210314752 Test Loss: 0.16464325723747095\n",
      "Epoch: 10 Train Loss: 0.156701449367404 Test Loss: 0.1501961259034495\n",
      "Epoch: 20 Train Loss: 0.14162121120989324 Test Loss: 0.13842952385925636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:36:26,996]\u001b[0m Trial 30 finished with value: 0.6725806451612902 and parameters: {'hidden_size': 465, 'activation': 'LeakyReLU', 'dropout': 0.3249035012683452, 'optimizer': 'Adagrad', 'lr': 0.061893689644479596}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1715653391033411 Test Loss: 0.16156548524674136\n",
      "Epoch: 10 Train Loss: 0.15612885644435884 Test Loss: 0.14859531148554037\n",
      "Epoch: 20 Train Loss: 0.14510919791162014 Test Loss: 0.1442543012908282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:37:53,406]\u001b[0m Trial 31 finished with value: 0.6698564593301435 and parameters: {'hidden_size': 395, 'activation': 'LeakyReLU', 'dropout': 0.324146549126735, 'optimizer': 'Adagrad', 'lr': 0.04191958070731937}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17204251004755497 Test Loss: 0.16301337044578962\n",
      "Epoch: 10 Train Loss: 0.15217703764140605 Test Loss: 0.1485995479677908\n",
      "Epoch: 20 Train Loss: 0.13793432404398917 Test Loss: 0.1407508146339141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:39:19,672]\u001b[0m Trial 32 finished with value: 0.6747967479674796 and parameters: {'hidden_size': 420, 'activation': 'LeakyReLU', 'dropout': 0.2988830450528096, 'optimizer': 'Adagrad', 'lr': 0.03764034882248366}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17261985786557196 Test Loss: 0.16769922583604963\n",
      "Epoch: 10 Train Loss: 0.15712929239869117 Test Loss: 0.15064828799436458\n",
      "Epoch: 20 Train Loss: 0.14521489452123643 Test Loss: 0.1426522554264377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:40:44,892]\u001b[0m Trial 33 finished with value: 0.6629123089300081 and parameters: {'hidden_size': 375, 'activation': 'LeakyReLU', 'dropout': 0.33807469714989596, 'optimizer': 'Adagrad', 'lr': 0.04553810253890769}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.3722918674468994 Test Loss: 0.37630856151397996\n",
      "Epoch: 10 Train Loss: 0.37050151391029357 Test Loss: 0.3744124610203143\n",
      "Epoch: 20 Train Loss: 0.3675547732830048 Test Loss: 0.37243099563038007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:42:13,567]\u001b[0m Trial 34 finished with value: 0.3776824034334764 and parameters: {'hidden_size': 437, 'activation': 'Sigmoid', 'dropout': 0.25778280535775944, 'optimizer': 'Adagrad', 'lr': 0.02342893982911033}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.21187162821888925 Test Loss: 0.21501319989942894\n",
      "Epoch: 10 Train Loss: 0.19773774841725827 Test Loss: 0.19409129098533823\n",
      "Epoch: 20 Train Loss: 0.16592198562771082 Test Loss: 0.16559471604756462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:43:25,385]\u001b[0m Trial 35 finished with value: 0.6060606060606061 and parameters: {'hidden_size': 322, 'activation': 'LeakyReLU', 'dropout': 0.28075140727649983, 'optimizer': 'SGD', 'lr': 0.05253875864728655}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16536242596805095 Test Loss: 0.16851689356167954\n",
      "Epoch: 10 Train Loss: 0.14850682941377163 Test Loss: 0.14967830223254502\n",
      "Epoch: 20 Train Loss: 0.13373379005342723 Test Loss: 0.13913302902525035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:44:50,905]\u001b[0m Trial 36 finished with value: 0.6709367493995196 and parameters: {'hidden_size': 404, 'activation': 'LeakyReLU', 'dropout': 0.3158016066554155, 'optimizer': 'Adagrad', 'lr': 0.03153763729810962}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.38441645226478577 Test Loss: 0.387556844625991\n",
      "Epoch: 10 Train Loss: 0.38421299028396605 Test Loss: 0.38750408727901814\n",
      "Epoch: 20 Train Loss: 0.3841102400779724 Test Loss: 0.3874221742153168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:46:02,734]\u001b[0m Trial 37 finished with value: 0.0 and parameters: {'hidden_size': 451, 'activation': 'Sigmoid', 'dropout': 0.36193024452907796, 'optimizer': 'SGD', 'lr': 0.018387423546694294}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.24544061226844788 Test Loss: 0.25162761170452774\n",
      "Epoch: 10 Train Loss: 0.24266636352539062 Test Loss: 0.24972932293011357\n",
      "Epoch: 20 Train Loss: 0.23973508236408234 Test Loss: 0.2485886468483617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:47:24,634]\u001b[0m Trial 38 finished with value: 0.3252212389380531 and parameters: {'hidden_size': 195, 'activation': 'Tanh', 'dropout': 0.26688822433619763, 'optimizer': 'Adagrad', 'lr': 0.035462453845323524}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2090207516312599 Test Loss: 0.20841278691594592\n",
      "Epoch: 10 Train Loss: 0.19230533965229987 Test Loss: 0.19380053427939217\n",
      "Epoch: 20 Train Loss: 0.16957467306256294 Test Loss: 0.17627605840492364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:48:36,112]\u001b[0m Trial 39 finished with value: 0.5748709122203097 and parameters: {'hidden_size': 369, 'activation': 'LeakyReLU', 'dropout': 0.22872555333053396, 'optimizer': 'SGD', 'lr': 0.041523694467146766}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1648913598805666 Test Loss: 0.16463158158258126\n",
      "Epoch: 10 Train Loss: 0.14698056083768607 Test Loss: 0.15372300169433648\n",
      "Epoch: 20 Train Loss: 0.13499574412703513 Test Loss: 0.1389701442120555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:50:02,747]\u001b[0m Trial 40 finished with value: 0.672185430463576 and parameters: {'hidden_size': 419, 'activation': 'LeakyReLU', 'dropout': 0.29459811397614344, 'optimizer': 'Adagrad', 'lr': 0.02912671125789223}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18984497755169868 Test Loss: 0.17767954465394584\n",
      "Epoch: 10 Train Loss: 0.16646081633865834 Test Loss: 0.15955592186663287\n",
      "Epoch: 20 Train Loss: 0.14931973178684713 Test Loss: 0.14579293323448672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:51:32,260]\u001b[0m Trial 41 finished with value: 0.6552006552006553 and parameters: {'hidden_size': 477, 'activation': 'LeakyReLU', 'dropout': 0.3906776652553482, 'optimizer': 'Adagrad', 'lr': 0.04849056497764621}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18583688229620457 Test Loss: 0.17097916195805843\n",
      "Epoch: 10 Train Loss: 0.16445767771601677 Test Loss: 0.15413014574077563\n",
      "Epoch: 20 Train Loss: 0.14927834729850292 Test Loss: 0.14356138053150794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:53:00,087]\u001b[0m Trial 42 finished with value: 0.6666666666666666 and parameters: {'hidden_size': 509, 'activation': 'LeakyReLU', 'dropout': 0.42625416612909184, 'optimizer': 'Adagrad', 'lr': 0.04833043705403257}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.19166150408685206 Test Loss: 0.18541694812167187\n",
      "Epoch: 10 Train Loss: 0.17141384508609772 Test Loss: 0.16183256716155014\n",
      "Epoch: 20 Train Loss: 0.15484005686044694 Test Loss: 0.15041207810179494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:54:25,446]\u001b[0m Trial 43 finished with value: 0.6693037974683543 and parameters: {'hidden_size': 482, 'activation': 'LeakyReLU', 'dropout': 0.3840529786873052, 'optimizer': 'Adagrad', 'lr': 0.05624253020976008}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.375486296081543 Test Loss: 0.3787992097699223\n",
      "Epoch: 10 Train Loss: 0.37547930550575254 Test Loss: 0.37877622865640315\n",
      "Epoch: 20 Train Loss: 0.3754497169494629 Test Loss: 0.3788657203649941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:55:52,990]\u001b[0m Trial 44 finished with value: 0.2079806529625151 and parameters: {'hidden_size': 455, 'activation': 'Sigmoid', 'dropout': 0.4593501679225262, 'optimizer': 'Adagrad', 'lr': 0.04980970020175159}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 16.179796242025574 Test Loss: 5.586929398817947\n",
      "Epoch: 10 Train Loss: 58.69196857321655 Test Loss: 24.20049948890369\n",
      "Epoch: 20 Train Loss: 21.690502935732585 Test Loss: 19.290503797439722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:57:13,056]\u001b[0m Trial 45 finished with value: 0.3068432671081678 and parameters: {'hidden_size': 438, 'activation': 'LeakyReLU', 'dropout': 0.35649200950405996, 'optimizer': 'Adam', 'lr': 0.04163830401578311}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:58:35,360]\u001b[0m Trial 46 finished with value: 0.0 and parameters: {'hidden_size': 345, 'activation': 'ReLU', 'dropout': 0.41733477899414717, 'optimizer': 'Adagrad', 'lr': 0.06851921809544585}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17640026969611644 Test Loss: 0.17582640143486258\n",
      "Epoch: 10 Train Loss: 0.1581274539321661 Test Loss: 0.1547116772494853\n",
      "Epoch: 20 Train Loss: 0.1388755073800683 Test Loss: 0.14405434775335815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 19:59:54,252]\u001b[0m Trial 47 finished with value: 0.6661129568106312 and parameters: {'hidden_size': 307, 'activation': 'LeakyReLU', 'dropout': 0.330078963778457, 'optimizer': 'Adagrad', 'lr': 0.027983056014323816}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.21292135998606682 Test Loss: 0.1963520263568662\n",
      "Epoch: 10 Train Loss: 0.19524480585455894 Test Loss: 0.18398792633471397\n",
      "Epoch: 20 Train Loss: 0.17421757292151452 Test Loss: 0.16567048451866204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:01:11,563]\u001b[0m Trial 48 finished with value: 0.6006768189509306 and parameters: {'hidden_size': 32, 'activation': 'LeakyReLU', 'dropout': 0.3936649235976811, 'optimizer': 'Adagrad', 'lr': 0.03417014289088771}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2505803886413574 Test Loss: 0.2556235404155506\n",
      "Epoch: 10 Train Loss: 0.24938625204563142 Test Loss: 0.25673467587358273\n",
      "Epoch: 20 Train Loss: 0.2479117891073227 Test Loss: 0.2535325752470059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:02:20,416]\u001b[0m Trial 49 finished with value: 0.24824355971896955 and parameters: {'hidden_size': 97, 'activation': 'Tanh', 'dropout': 0.3530936839563701, 'optimizer': 'SGD', 'lr': 0.03780939636990053}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.19714885615706443 Test Loss: 0.18799343386206763\n",
      "Epoch: 10 Train Loss: 0.17332919884622097 Test Loss: 0.16287272995986496\n",
      "Epoch: 20 Train Loss: 0.15399577224850655 Test Loss: 0.14562877938270377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:03:45,120]\u001b[0m Trial 50 finished with value: 0.6357504215851603 and parameters: {'hidden_size': 382, 'activation': 'LeakyReLU', 'dropout': 0.43640646914459613, 'optimizer': 'Adagrad', 'lr': 0.050963410918527415}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17797917882204056 Test Loss: 0.1705863549412725\n",
      "Epoch: 10 Train Loss: 0.1712837386071682 Test Loss: 0.15286524342700317\n",
      "Epoch: 20 Train Loss: 0.1429672563865781 Test Loss: 0.14130294178954708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:05:07,965]\u001b[0m Trial 51 finished with value: 0.6661224489795918 and parameters: {'hidden_size': 400, 'activation': 'LeakyReLU', 'dropout': 0.3701997934183322, 'optimizer': 'Adagrad', 'lr': 0.038004513078287935}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1831542995661497 Test Loss: 0.17367946664793804\n",
      "Epoch: 10 Train Loss: 0.16175256407856942 Test Loss: 0.15617988984020184\n",
      "Epoch: 20 Train Loss: 0.14553965773284436 Test Loss: 0.14375612589295583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:06:27,974]\u001b[0m Trial 52 finished with value: 0.6634066829665851 and parameters: {'hidden_size': 355, 'activation': 'LeakyReLU', 'dropout': 0.3767986364342218, 'optimizer': 'Adagrad', 'lr': 0.044379335989819815}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17821588849425316 Test Loss: 0.17147685273791463\n",
      "Epoch: 10 Train Loss: 0.1596000389277935 Test Loss: 0.15003658463946357\n",
      "Epoch: 20 Train Loss: 0.14444925932884217 Test Loss: 0.1393804964892114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:07:50,344]\u001b[0m Trial 53 finished with value: 0.6688470973017171 and parameters: {'hidden_size': 410, 'activation': 'LeakyReLU', 'dropout': 0.4956110900388672, 'optimizer': 'Adagrad', 'lr': 0.03961114521092228}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18555786348879338 Test Loss: 0.1751275620521448\n",
      "Epoch: 10 Train Loss: 0.16348395366370677 Test Loss: 0.15883918215458195\n",
      "Epoch: 20 Train Loss: 0.14567581128180027 Test Loss: 0.14518343038952197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:09:13,185]\u001b[0m Trial 54 finished with value: 0.6634692246203038 and parameters: {'hidden_size': 382, 'activation': 'LeakyReLU', 'dropout': 0.3974026327047054, 'optimizer': 'Adagrad', 'lr': 0.04592376317239496}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1801356980830431 Test Loss: 0.16921820935492699\n",
      "Epoch: 10 Train Loss: 0.15579656659066676 Test Loss: 0.15286606072355954\n",
      "Epoch: 20 Train Loss: 0.1432881726205349 Test Loss: 0.14069523997961902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:10:32,400]\u001b[0m Trial 55 finished with value: 0.6655764513491413 and parameters: {'hidden_size': 265, 'activation': 'LeakyReLU', 'dropout': 0.348642447501102, 'optimizer': 'Adagrad', 'lr': 0.05706455470972746}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:11:47,669]\u001b[0m Trial 56 finished with value: 0.0 and parameters: {'hidden_size': 493, 'activation': 'ReLU', 'dropout': 0.320772972073332, 'optimizer': 'Adam', 'lr': 0.03190022845175551}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18416224879026413 Test Loss: 0.1703880671590281\n",
      "Epoch: 10 Train Loss: 0.16938868933320045 Test Loss: 0.15795206981964005\n",
      "Epoch: 20 Train Loss: 0.14686183540821077 Test Loss: 0.14407995724068662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:12:38,583]\u001b[0m Trial 57 finished with value: 0.6666666666666667 and parameters: {'hidden_size': 437, 'activation': 'LeakyReLU', 'dropout': 0.4086148325016189, 'optimizer': 'Adagrad', 'lr': 0.05175840617397719}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.3754552656173706 Test Loss: 0.37879020042312794\n",
      "Epoch: 10 Train Loss: 0.3753868632793427 Test Loss: 0.378873029455971\n",
      "Epoch: 20 Train Loss: 0.3753626026153564 Test Loss: 0.37875967046704156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:13:31,626]\u001b[0m Trial 58 finished with value: 0.2079806529625151 and parameters: {'hidden_size': 467, 'activation': 'Sigmoid', 'dropout': 0.3073807022773344, 'optimizer': 'Adagrad', 'lr': 0.03967387131945451}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17892839817404746 Test Loss: 0.17059879967222769\n",
      "Epoch: 10 Train Loss: 0.16261769824028016 Test Loss: 0.154761089720189\n",
      "Epoch: 20 Train Loss: 0.14655293874144554 Test Loss: 0.1445124834216536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:14:15,788]\u001b[0m Trial 59 finished with value: 0.6688311688311689 and parameters: {'hidden_size': 328, 'activation': 'LeakyReLU', 'dropout': 0.3436500921588305, 'optimizer': 'Adagrad', 'lr': 0.0449442788733455}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.24463613455295563 Test Loss: 0.2516857164736373\n",
      "Epoch: 10 Train Loss: 0.24187320482730865 Test Loss: 0.2488806826142838\n",
      "Epoch: 20 Train Loss: 0.23925193045139312 Test Loss: 0.24587609392766374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:15:05,118]\u001b[0m Trial 60 finished with value: 0.3449023861171367 and parameters: {'hidden_size': 391, 'activation': 'Tanh', 'dropout': 0.37216561069921494, 'optimizer': 'Adagrad', 'lr': 0.026867456281515004}. Best is trial 23 with value: 0.6841686555290375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17162289758771657 Test Loss: 0.16971739602926822\n",
      "Epoch: 10 Train Loss: 0.1507460921227932 Test Loss: 0.14817527732172142\n",
      "Epoch: 20 Train Loss: 0.13466738068908454 Test Loss: 0.1378405963519987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:15:49,852]\u001b[0m Trial 61 finished with value: 0.6855345911949686 and parameters: {'hidden_size': 362, 'activation': 'LeakyReLU', 'dropout': 0.28145014395190415, 'optimizer': 'Adagrad', 'lr': 0.036340892485313414}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16620176150500773 Test Loss: 0.16302495571180656\n",
      "Epoch: 10 Train Loss: 0.14835769391655923 Test Loss: 0.1472917133793473\n",
      "Epoch: 20 Train Loss: 0.13481052856445314 Test Loss: 0.14064284346807307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:16:36,759]\u001b[0m Trial 62 finished with value: 0.6758732737611698 and parameters: {'hidden_size': 358, 'activation': 'LeakyReLU', 'dropout': 0.27956641935479576, 'optimizer': 'Adagrad', 'lr': 0.036222259401514294}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16649231101721526 Test Loss: 0.1647786993426256\n",
      "Epoch: 10 Train Loss: 0.1519858393535018 Test Loss: 0.15696517688433487\n",
      "Epoch: 20 Train Loss: 0.1384142584055662 Test Loss: 0.1393151850805591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:17:26,720]\u001b[0m Trial 63 finished with value: 0.66557107641742 and parameters: {'hidden_size': 421, 'activation': 'LeakyReLU', 'dropout': 0.24324311526025522, 'optimizer': 'Adagrad', 'lr': 0.04330981069156888}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.164620153978467 Test Loss: 0.16479302598788334\n",
      "Epoch: 10 Train Loss: 0.14582577086091042 Test Loss: 0.1523473576074258\n",
      "Epoch: 20 Train Loss: 0.13556483983397483 Test Loss: 0.13930396309580667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:18:11,759]\u001b[0m Trial 64 finished with value: 0.6737357259380099 and parameters: {'hidden_size': 282, 'activation': 'LeakyReLU', 'dropout': 0.2918093331596979, 'optimizer': 'Adagrad', 'lr': 0.033170101936134254}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16685639202594757 Test Loss: 0.1599627891704202\n",
      "Epoch: 10 Train Loss: 0.15470868617296218 Test Loss: 0.1561032146834337\n",
      "Epoch: 20 Train Loss: 0.14082261680364608 Test Loss: 0.14350557667069352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:18:56,078]\u001b[0m Trial 65 finished with value: 0.66612641815235 and parameters: {'hidden_size': 311, 'activation': 'LeakyReLU', 'dropout': 0.3128400034425369, 'optimizer': 'Adagrad', 'lr': 0.04902469143315541}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 59.01192819069228 Test Loss: 14.550508696352813\n",
      "Epoch: 10 Train Loss: 27.2675814832834 Test Loss: 28.817867668280112\n",
      "Epoch: 20 Train Loss: 86.90389498557408 Test Loss: 21.887393354226987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:19:45,678]\u001b[0m Trial 66 finished with value: 0.3662851196670135 and parameters: {'hidden_size': 371, 'activation': 'LeakyReLU', 'dropout': 0.33499197974459305, 'optimizer': 'Adam', 'lr': 0.040218908791216305}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.21378069430589675 Test Loss: 0.21248261985211328\n",
      "Epoch: 10 Train Loss: 0.1975427987664938 Test Loss: 0.20104201526021043\n",
      "Epoch: 20 Train Loss: 0.1701537650078535 Test Loss: 0.1674846113977817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:20:26,053]\u001b[0m Trial 67 finished with value: 0.5834797891036907 and parameters: {'hidden_size': 344, 'activation': 'LeakyReLU', 'dropout': 0.27459827907186035, 'optimizer': 'SGD', 'lr': 0.035893368517668466}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:21:17,268]\u001b[0m Trial 68 finished with value: 0.0 and parameters: {'hidden_size': 392, 'activation': 'ReLU', 'dropout': 0.310521653932999, 'optimizer': 'Adagrad', 'lr': 0.04282156540204318}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1798266450881958 Test Loss: 0.18060097557763322\n",
      "Epoch: 10 Train Loss: 0.15596346160173416 Test Loss: 0.15383168705664693\n",
      "Epoch: 20 Train Loss: 0.14123984888643026 Test Loss: 0.14659752349515026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:22:04,747]\u001b[0m Trial 69 finished with value: 0.6771159874608149 and parameters: {'hidden_size': 361, 'activation': 'LeakyReLU', 'dropout': 0.256322048652259, 'optimizer': 'Adagrad', 'lr': 0.053471147677941575}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1663516408443451 Test Loss: 0.15858137348708443\n",
      "Epoch: 10 Train Loss: 0.1464285613656044 Test Loss: 0.1449464660840103\n",
      "Epoch: 20 Train Loss: 0.13631528497487305 Test Loss: 0.1360130524768616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:22:50,155]\u001b[0m Trial 70 finished with value: 0.6841269841269841 and parameters: {'hidden_size': 334, 'activation': 'LeakyReLU', 'dropout': 0.28587653022789933, 'optimizer': 'Adagrad', 'lr': 0.04667089930624001}. Best is trial 61 with value: 0.6855345911949686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17121684206724166 Test Loss: 0.16305291230757588\n",
      "Epoch: 10 Train Loss: 0.15286296633780003 Test Loss: 0.1473432454569176\n",
      "Epoch: 20 Train Loss: 0.1372377168789506 Test Loss: 0.1398169211448191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:23:33,903]\u001b[0m Trial 71 finished with value: 0.6858029480217223 and parameters: {'hidden_size': 333, 'activation': 'LeakyReLU', 'dropout': 0.29427575072038453, 'optimizer': 'Adagrad', 'lr': 0.04626833189334275}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16656836327910424 Test Loss: 0.16369546832034762\n",
      "Epoch: 10 Train Loss: 0.15506417187899352 Test Loss: 0.14953659202891606\n",
      "Epoch: 20 Train Loss: 0.13733841791898013 Test Loss: 0.14145682534327902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:24:15,709]\u001b[0m Trial 72 finished with value: 0.6688311688311689 and parameters: {'hidden_size': 293, 'activation': 'LeakyReLU', 'dropout': 0.29268163923549706, 'optimizer': 'Adagrad', 'lr': 0.04809657725635445}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16497808482646942 Test Loss: 0.16639222012469754\n",
      "Epoch: 10 Train Loss: 0.2170554997548461 Test Loss: 0.15931831005686958\n",
      "Epoch: 20 Train Loss: 0.14278665154874326 Test Loss: 0.14565622679793988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:24:58,478]\u001b[0m Trial 73 finished with value: 0.6742301458670988 and parameters: {'hidden_size': 327, 'activation': 'LeakyReLU', 'dropout': 0.27494038187171205, 'optimizer': 'Adagrad', 'lr': 0.04686217293102095}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1610948667228222 Test Loss: 0.15853531134371368\n",
      "Epoch: 10 Train Loss: 0.14574864732921122 Test Loss: 0.14165529424842363\n",
      "Epoch: 20 Train Loss: 0.13569135152697565 Test Loss: 0.14178324801424821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:25:40,412]\u001b[0m Trial 74 finished with value: 0.6809210526315789 and parameters: {'hidden_size': 318, 'activation': 'LeakyReLU', 'dropout': 0.2600645186382447, 'optimizer': 'Adagrad', 'lr': 0.043067479948599885}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1669611263036728 Test Loss: 0.16564375615586488\n",
      "Epoch: 10 Train Loss: 0.15094519494175912 Test Loss: 0.1477331430755389\n",
      "Epoch: 20 Train Loss: 0.13759429905712606 Test Loss: 0.13684439186018688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:26:22,851]\u001b[0m Trial 75 finished with value: 0.6797488226059654 and parameters: {'hidden_size': 337, 'activation': 'LeakyReLU', 'dropout': 0.2511960944424192, 'optimizer': 'Adagrad', 'lr': 0.044228604435051985}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1672345408514142 Test Loss: 0.16265278826125515\n",
      "Epoch: 10 Train Loss: 0.15574818014800548 Test Loss: 0.14941198829882824\n",
      "Epoch: 20 Train Loss: 0.14212561753690242 Test Loss: 0.14489238749380215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:27:03,388]\u001b[0m Trial 76 finished with value: 0.6688311688311689 and parameters: {'hidden_size': 312, 'activation': 'LeakyReLU', 'dropout': 0.3009368942166796, 'optimizer': 'Adagrad', 'lr': 0.04079015356195699}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.37546227488517764 Test Loss: 0.37879451623739907\n",
      "Epoch: 10 Train Loss: 0.3754369607448578 Test Loss: 0.37867683238876515\n",
      "Epoch: 20 Train Loss: 0.3735312605857849 Test Loss: 0.37677691462702645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:27:46,214]\u001b[0m Trial 77 finished with value: 0.2866817155756208 and parameters: {'hidden_size': 293, 'activation': 'Sigmoid', 'dropout': 0.2654066349590117, 'optimizer': 'Adagrad', 'lr': 0.036506662620641624}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16408718069791794 Test Loss: 0.15905483966223158\n",
      "Epoch: 10 Train Loss: 0.14945060195177792 Test Loss: 0.14645568298074765\n",
      "Epoch: 20 Train Loss: 0.13386054908037184 Test Loss: 0.14090103065422455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:28:27,882]\u001b[0m Trial 78 finished with value: 0.6857597454256167 and parameters: {'hidden_size': 269, 'activation': 'LeakyReLU', 'dropout': 0.23125304510699957, 'optimizer': 'Adagrad', 'lr': 0.03125315067140177}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2438359954595566 Test Loss: 0.24995376479130582\n",
      "Epoch: 10 Train Loss: 0.23829799151420594 Test Loss: 0.24625247626449354\n",
      "Epoch: 20 Train Loss: 0.23540111339092254 Test Loss: 0.2441139974818824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:29:09,407]\u001b[0m Trial 79 finished with value: 0.36929460580912865 and parameters: {'hidden_size': 227, 'activation': 'Tanh', 'dropout': 0.22320602251240337, 'optimizer': 'Adagrad', 'lr': 0.024899840976604908}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.21355003461539745 Test Loss: 0.2139476645357026\n",
      "Epoch: 10 Train Loss: 0.2019422278344631 Test Loss: 0.19999480443878676\n",
      "Epoch: 20 Train Loss: 0.1748439190775156 Test Loss: 0.1783875032497671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:29:46,606]\u001b[0m Trial 80 finished with value: 0.538955087076077 and parameters: {'hidden_size': 261, 'activation': 'LeakyReLU', 'dropout': 0.28701097609016196, 'optimizer': 'SGD', 'lr': 0.03245113718522662}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16665902360379695 Test Loss: 0.16757341683767854\n",
      "Epoch: 10 Train Loss: 0.15455740455389022 Test Loss: 0.1521795050511821\n",
      "Epoch: 20 Train Loss: 0.13498400060236454 Test Loss: 0.14033645445617815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:30:28,066]\u001b[0m Trial 81 finished with value: 0.680952380952381 and parameters: {'hidden_size': 234, 'activation': 'LeakyReLU', 'dropout': 0.26139488238185127, 'optimizer': 'Adagrad', 'lr': 0.030430063369536173}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1647990777105093 Test Loss: 0.15933129455620487\n",
      "Epoch: 10 Train Loss: 0.14849439663290978 Test Loss: 0.14847549483977474\n",
      "Epoch: 20 Train Loss: 0.13520527094900608 Test Loss: 0.14102009126839166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:31:09,152]\u001b[0m Trial 82 finished with value: 0.6748166259168705 and parameters: {'hidden_size': 232, 'activation': 'LeakyReLU', 'dropout': 0.2375922984705613, 'optimizer': 'Adagrad', 'lr': 0.03013867856189694}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18833558475077153 Test Loss: 0.18805655682334504\n",
      "Epoch: 10 Train Loss: 0.16825954172611238 Test Loss: 0.16844256588826165\n",
      "Epoch: 20 Train Loss: 0.1473134086102247 Test Loss: 0.14890698511927083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:31:50,308]\u001b[0m Trial 83 finished with value: 0.633276740237691 and parameters: {'hidden_size': 240, 'activation': 'LeakyReLU', 'dropout': 0.28082141013314355, 'optimizer': 'Adagrad', 'lr': 0.03049111662491619}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16445471512079238 Test Loss: 0.16388759404992143\n",
      "Epoch: 10 Train Loss: 0.15020552956461908 Test Loss: 0.14886024094427736\n",
      "Epoch: 20 Train Loss: 0.14191376812458037 Test Loss: 0.1410316128593188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:32:31,860]\u001b[0m Trial 84 finished with value: 0.6816000000000001 and parameters: {'hidden_size': 213, 'activation': 'LeakyReLU', 'dropout': 0.325074348008256, 'optimizer': 'Adagrad', 'lr': 0.034578810775405595}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18211925099492074 Test Loss: 0.17500098557851185\n",
      "Epoch: 10 Train Loss: 0.16435099256187677 Test Loss: 0.15991792402352198\n",
      "Epoch: 20 Train Loss: 0.14810101914703847 Test Loss: 0.1488736254481462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:33:13,536]\u001b[0m Trial 85 finished with value: 0.6423236514522821 and parameters: {'hidden_size': 167, 'activation': 'LeakyReLU', 'dropout': 0.3299192180624173, 'optimizer': 'Adagrad', 'lr': 0.03389173586568453}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.7877113772648848 Test Loss: 0.7206207225190795\n",
      "Epoch: 10 Train Loss: 2.4954816491600034 Test Loss: 1.2226037750165093\n",
      "Epoch: 20 Train Loss: 11.497346990024965 Test Loss: 3.6529618995634245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:33:54,228]\u001b[0m Trial 86 finished with value: 0.24584717607973422 and parameters: {'hidden_size': 207, 'activation': 'LeakyReLU', 'dropout': 0.31764791226221123, 'optimizer': 'Adam', 'lr': 0.03882573751977558}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.19933010048270225 Test Loss: 0.1907294485182427\n",
      "Epoch: 10 Train Loss: 0.17249580229520797 Test Loss: 0.16609875249643677\n",
      "Epoch: 20 Train Loss: 0.15267943675518036 Test Loss: 0.14924860384446173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:34:35,407]\u001b[0m Trial 87 finished with value: 0.6229508196721312 and parameters: {'hidden_size': 186, 'activation': 'LeakyReLU', 'dropout': 0.2954213766836378, 'optimizer': 'Adagrad', 'lr': 0.03527347333765196}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6930781664848328 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:35:15,878]\u001b[0m Trial 88 finished with value: 0.0 and parameters: {'hidden_size': 133, 'activation': 'ReLU', 'dropout': 0.30549218054850685, 'optimizer': 'Adagrad', 'lr': 0.04711095619818223}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18814067311286925 Test Loss: 0.18119088848963522\n",
      "Epoch: 10 Train Loss: 0.1623877553910017 Test Loss: 0.15567731866821313\n",
      "Epoch: 20 Train Loss: 0.14827424167990685 Test Loss: 0.1442281230927085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:35:57,304]\u001b[0m Trial 89 finished with value: 0.6573770491803278 and parameters: {'hidden_size': 269, 'activation': 'LeakyReLU', 'dropout': 0.3342996202681483, 'optimizer': 'Adagrad', 'lr': 0.037865048595932226}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16876239298284054 Test Loss: 0.17962809804434213\n",
      "Epoch: 10 Train Loss: 0.15276117363274097 Test Loss: 0.15181085604805344\n",
      "Epoch: 20 Train Loss: 0.13588376411795616 Test Loss: 0.13788510657275638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:36:43,090]\u001b[0m Trial 90 finished with value: 0.6784850926672039 and parameters: {'hidden_size': 374, 'activation': 'LeakyReLU', 'dropout': 0.31750944930904557, 'optimizer': 'Adagrad', 'lr': 0.041509593216484314}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17966980915665626 Test Loss: 0.17658691422436565\n",
      "Epoch: 10 Train Loss: 0.1573054933130741 Test Loss: 0.15685790332670982\n",
      "Epoch: 20 Train Loss: 0.14103784573227168 Test Loss: 0.14653290705844618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:37:24,802]\u001b[0m Trial 91 finished with value: 0.6408746846089151 and parameters: {'hidden_size': 214, 'activation': 'LeakyReLU', 'dropout': 0.2711226024654458, 'optimizer': 'Adagrad', 'lr': 0.028110847920904677}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16886847610771655 Test Loss: 0.16523789417462798\n",
      "Epoch: 10 Train Loss: 0.149122147706151 Test Loss: 0.14825559352723935\n",
      "Epoch: 20 Train Loss: 0.13960189379155635 Test Loss: 0.14073456057939476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:38:06,333]\u001b[0m Trial 92 finished with value: 0.6661251015434606 and parameters: {'hidden_size': 243, 'activation': 'LeakyReLU', 'dropout': 0.24581476041385616, 'optimizer': 'Adagrad', 'lr': 0.031677932375728364}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18088166385889054 Test Loss: 0.17622323336597448\n",
      "Epoch: 10 Train Loss: 0.1552758242100477 Test Loss: 0.1562615338974772\n",
      "Epoch: 20 Train Loss: 0.14088278161883355 Test Loss: 0.1427011575323705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:38:48,357]\u001b[0m Trial 93 finished with value: 0.6579163248564397 and parameters: {'hidden_size': 281, 'activation': 'LeakyReLU', 'dropout': 0.2819817211471494, 'optimizer': 'Adagrad', 'lr': 0.03437181526017415}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18396284722983838 Test Loss: 0.18697826436366707\n",
      "Epoch: 10 Train Loss: 0.16568815287947655 Test Loss: 0.1651960736313186\n",
      "Epoch: 20 Train Loss: 0.14910535559356214 Test Loss: 0.1538343405136809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:39:29,905]\u001b[0m Trial 94 finished with value: 0.6067415730337079 and parameters: {'hidden_size': 255, 'activation': 'LeakyReLU', 'dropout': 0.3028158920542138, 'optimizer': 'Adagrad', 'lr': 0.020336616129767428}. Best is trial 71 with value: 0.6858029480217223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1671620376586914 Test Loss: 0.16446616656828328\n",
      "Epoch: 10 Train Loss: 0.15159779690206052 Test Loss: 0.14755082546998136\n",
      "Epoch: 20 Train Loss: 0.1345478650033474 Test Loss: 0.14583279425129533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:40:16,664]\u001b[0m Trial 95 finished with value: 0.6947535771065183 and parameters: {'hidden_size': 407, 'activation': 'LeakyReLU', 'dropout': 0.2636990567426021, 'optimizer': 'Adagrad', 'lr': 0.05014724648042993}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.37550504364967346 Test Loss: 0.37881323123892274\n",
      "Epoch: 10 Train Loss: 0.37500378379821775 Test Loss: 0.3780649929953078\n",
      "Epoch: 20 Train Loss: 0.37407998805046083 Test Loss: 0.37721974000382347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:41:01,419]\u001b[0m Trial 96 finished with value: 0.2766439909297052 and parameters: {'hidden_size': 337, 'activation': 'Sigmoid', 'dropout': 0.2885043012211519, 'optimizer': 'Adagrad', 'lr': 0.04538214522553866}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16234317575991153 Test Loss: 0.15912893439491335\n",
      "Epoch: 10 Train Loss: 0.14909413098692895 Test Loss: 0.14525728706663218\n",
      "Epoch: 20 Train Loss: 0.13638040899187326 Test Loss: 0.1383431682321496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:41:48,170]\u001b[0m Trial 97 finished with value: 0.6845425867507886 and parameters: {'hidden_size': 411, 'activation': 'LeakyReLU', 'dropout': 0.25145839230700434, 'optimizer': 'Adagrad', 'lr': 0.05144582641664263}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.168145226110518 Test Loss: 0.1660621997575981\n",
      "Epoch: 10 Train Loss: 0.15187235593795775 Test Loss: 0.15091407441269286\n",
      "Epoch: 20 Train Loss: 0.13467821608930827 Test Loss: 0.13986117417177263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:42:34,897]\u001b[0m Trial 98 finished with value: 0.6791530944625407 and parameters: {'hidden_size': 413, 'activation': 'LeakyReLU', 'dropout': 0.2202880204806995, 'optimizer': 'Adagrad', 'lr': 0.050721459880535585}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.32906952266097067 Test Loss: 0.8465510442876778\n",
      "Epoch: 10 Train Loss: 0.2011598809748888 Test Loss: 0.17828038146201605\n",
      "Epoch: 20 Train Loss: 0.15795420958995818 Test Loss: 0.15198013650628325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:43:12,536]\u001b[0m Trial 99 finished with value: 0.6240276577355229 and parameters: {'hidden_size': 444, 'activation': 'LeakyReLU', 'dropout': 0.2509571244716295, 'optimizer': 'SGD', 'lr': 0.05383727625768929}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2505790315389633 Test Loss: 0.2567280015815942\n",
      "Epoch: 10 Train Loss: 0.24652683470249176 Test Loss: 0.25315227019139375\n",
      "Epoch: 20 Train Loss: 0.24467274191379548 Test Loss: 0.252014604144203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:44:00,521]\u001b[0m Trial 100 finished with value: 0.2079806529625151 and parameters: {'hidden_size': 430, 'activation': 'Tanh', 'dropout': 0.26665377152566333, 'optimizer': 'Adagrad', 'lr': 0.0596168561936753}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17917562525570394 Test Loss: 0.16929118338817606\n",
      "Epoch: 10 Train Loss: 0.15743439745903015 Test Loss: 0.1573959490546165\n",
      "Epoch: 20 Train Loss: 0.14129688190966844 Test Loss: 0.1439783142480892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:44:46,084]\u001b[0m Trial 101 finished with value: 0.6693100713719271 and parameters: {'hidden_size': 384, 'activation': 'LeakyReLU', 'dropout': 0.3278870038752343, 'optimizer': 'Adagrad', 'lr': 0.04959880037501786}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16646390537321568 Test Loss: 0.16038652685598825\n",
      "Epoch: 10 Train Loss: 0.1494682885825634 Test Loss: 0.15240249322197688\n",
      "Epoch: 20 Train Loss: 0.1367563669860363 Test Loss: 0.13973469272874794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:45:32,545]\u001b[0m Trial 102 finished with value: 0.6725521669341894 and parameters: {'hidden_size': 403, 'activation': 'LeakyReLU', 'dropout': 0.23697911169350136, 'optimizer': 'Adagrad', 'lr': 0.0405071248899421}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1778133388876915 Test Loss: 0.16945224110120402\n",
      "Epoch: 10 Train Loss: 0.1589661908507347 Test Loss: 0.157487082845582\n",
      "Epoch: 20 Train Loss: 0.14513515174388886 Test Loss: 0.1449513209287446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:46:17,763]\u001b[0m Trial 103 finished with value: 0.6483333333333333 and parameters: {'hidden_size': 366, 'activation': 'LeakyReLU', 'dropout': 0.2871748360291444, 'optimizer': 'Adagrad', 'lr': 0.04424066119931121}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16783119609057903 Test Loss: 0.16355745575298516\n",
      "Epoch: 10 Train Loss: 0.15152765452861786 Test Loss: 0.14776367618562505\n",
      "Epoch: 20 Train Loss: 0.1353891115397215 Test Loss: 0.1395913713608687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:47:00,889]\u001b[0m Trial 104 finished with value: 0.6870967741935483 and parameters: {'hidden_size': 348, 'activation': 'LeakyReLU', 'dropout': 0.27493949441372645, 'optimizer': 'Adagrad', 'lr': 0.047301090869044465}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17337726839780807 Test Loss: 0.17232181112796735\n",
      "Epoch: 10 Train Loss: 0.15633416374623776 Test Loss: 0.15627057718249937\n",
      "Epoch: 20 Train Loss: 0.13993587519973516 Test Loss: 0.1428496077859078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:47:44,351]\u001b[0m Trial 105 finished with value: 0.6838407494145199 and parameters: {'hidden_size': 333, 'activation': 'LeakyReLU', 'dropout': 0.27446577336630873, 'optimizer': 'Adagrad', 'lr': 0.05248916633604474}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 6.757916561766321 Test Loss: 6.9527507100623245\n",
      "Epoch: 10 Train Loss: 27.098872256738307 Test Loss: 7.312037058293629\n",
      "Epoch: 20 Train Loss: 30.236182157281867 Test Loss: 5.116843431557234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:48:28,592]\u001b[0m Trial 106 finished with value: 0.33160621761658027 and parameters: {'hidden_size': 352, 'activation': 'LeakyReLU', 'dropout': 0.25481092316350756, 'optimizer': 'Adam', 'lr': 0.05185963577554882}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16488672761023043 Test Loss: 0.15740993873070414\n",
      "Epoch: 10 Train Loss: 0.14471656626462936 Test Loss: 0.1506858377720411\n",
      "Epoch: 20 Train Loss: 0.13278962147682905 Test Loss: 0.13963585245473603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:49:11,513]\u001b[0m Trial 107 finished with value: 0.6856690419635787 and parameters: {'hidden_size': 335, 'activation': 'LeakyReLU', 'dropout': 0.26692685145010236, 'optimizer': 'Adagrad', 'lr': 0.04677842625056355}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17366209889352321 Test Loss: 0.16930516145099847\n",
      "Epoch: 10 Train Loss: 0.15293874231278895 Test Loss: 0.15018777117525903\n",
      "Epoch: 20 Train Loss: 0.13796054730564355 Test Loss: 0.13785023213670658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:49:54,933]\u001b[0m Trial 108 finished with value: 0.6911877394636016 and parameters: {'hidden_size': 341, 'activation': 'LeakyReLU', 'dropout': 0.2743077279056552, 'optimizer': 'Adagrad', 'lr': 0.05426922933461811}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1621828076928854 Test Loss: 0.16050902903437042\n",
      "Epoch: 10 Train Loss: 0.15159707072675227 Test Loss: 0.1464969276334531\n",
      "Epoch: 20 Train Loss: 0.14197158857882022 Test Loss: 0.1389219039194167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:50:37,160]\u001b[0m Trial 109 finished with value: 0.6688364524003254 and parameters: {'hidden_size': 317, 'activation': 'LeakyReLU', 'dropout': 0.27344044488844377, 'optimizer': 'Adagrad', 'lr': 0.047513440207546984}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:51:18,880]\u001b[0m Trial 110 finished with value: 0.0 and parameters: {'hidden_size': 300, 'activation': 'ReLU', 'dropout': 0.24367921835959633, 'optimizer': 'Adagrad', 'lr': 0.054462527926380476}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17078134211599827 Test Loss: 0.167986127259299\n",
      "Epoch: 10 Train Loss: 0.15087796706408263 Test Loss: 0.15110746926416796\n",
      "Epoch: 20 Train Loss: 0.13609090881943703 Test Loss: 0.13876150557979608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:52:01,637]\u001b[0m Trial 111 finished with value: 0.6945288753799393 and parameters: {'hidden_size': 340, 'activation': 'LeakyReLU', 'dropout': 0.2669270243958962, 'optimizer': 'Adagrad', 'lr': 0.051316412325308}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16686704076826572 Test Loss: 0.1615918781727362\n",
      "Epoch: 10 Train Loss: 0.1473911425590515 Test Loss: 0.14949811501101182\n",
      "Epoch: 20 Train Loss: 0.13354992795586587 Test Loss: 0.13917239094242312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:52:44,818]\u001b[0m Trial 112 finished with value: 0.6764227642276422 and parameters: {'hidden_size': 345, 'activation': 'LeakyReLU', 'dropout': 0.2648604246124048, 'optimizer': 'Adagrad', 'lr': 0.05684937194200315}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16153277563750743 Test Loss: 0.1571859504027774\n",
      "Epoch: 10 Train Loss: 0.1497872705310583 Test Loss: 0.14820061887676914\n",
      "Epoch: 20 Train Loss: 0.13425857974290847 Test Loss: 0.13866111587364072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:53:26,820]\u001b[0m Trial 113 finished with value: 0.6705587989991659 and parameters: {'hidden_size': 324, 'activation': 'LeakyReLU', 'dropout': 0.25485429880243676, 'optimizer': 'Adagrad', 'lr': 0.050432818136313784}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18393637946844102 Test Loss: 0.17895869676249856\n",
      "Epoch: 10 Train Loss: 0.15520371405780314 Test Loss: 0.1550722182177888\n",
      "Epoch: 20 Train Loss: 0.1404275370284915 Test Loss: 0.14432390282353083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:54:10,628]\u001b[0m Trial 114 finished with value: 0.673015873015873 and parameters: {'hidden_size': 350, 'activation': 'LeakyReLU', 'dropout': 0.2812077285047782, 'optimizer': 'Adagrad', 'lr': 0.046817530782490374}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1708109291613102 Test Loss: 0.16647180089483055\n",
      "Epoch: 10 Train Loss: 0.15229623309075832 Test Loss: 0.1488893126039364\n",
      "Epoch: 20 Train Loss: 0.1369332728266716 Test Loss: 0.1383647124815625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:54:55,364]\u001b[0m Trial 115 finished with value: 0.691397000789266 and parameters: {'hidden_size': 362, 'activation': 'LeakyReLU', 'dropout': 0.23253426640767388, 'optimizer': 'Adagrad', 'lr': 0.055647834140059055}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17618156221807002 Test Loss: 0.17158025828080056\n",
      "Epoch: 10 Train Loss: 0.15709333466887473 Test Loss: 0.1539391473518869\n",
      "Epoch: 20 Train Loss: 0.14225266353785992 Test Loss: 0.14226745765882368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:55:40,943]\u001b[0m Trial 116 finished with value: 0.6901408450704225 and parameters: {'hidden_size': 365, 'activation': 'LeakyReLU', 'dropout': 0.21249041809296346, 'optimizer': 'Adagrad', 'lr': 0.055065051390755744}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.15368211498260498 Test Loss: 0.15438282025007966\n",
      "Epoch: 10 Train Loss: 0.13968773435354231 Test Loss: 0.14313022003839382\n",
      "Epoch: 20 Train Loss: 0.12855346247106791 Test Loss: 0.1417107146899826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:56:26,578]\u001b[0m Trial 117 finished with value: 0.6851704996034893 and parameters: {'hidden_size': 364, 'activation': 'LeakyReLU', 'dropout': 0.2181757030157638, 'optimizer': 'Adagrad', 'lr': 0.055037469758922784}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1725390833556652 Test Loss: 0.16665221750141143\n",
      "Epoch: 10 Train Loss: 0.15698244526684285 Test Loss: 0.1521005991655893\n",
      "Epoch: 20 Train Loss: 0.14563654076606036 Test Loss: 0.14441367382772816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:57:11,684]\u001b[0m Trial 118 finished with value: 0.6644951140065147 and parameters: {'hidden_size': 366, 'activation': 'LeakyReLU', 'dropout': 0.21353008721246702, 'optimizer': 'Adagrad', 'lr': 0.055734791238091295}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1699182019263506 Test Loss: 0.1722417840847192\n",
      "Epoch: 10 Train Loss: 0.1563366297096014 Test Loss: 0.15635102601668324\n",
      "Epoch: 20 Train Loss: 0.1441126849323511 Test Loss: 0.1435078129279442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:57:57,182]\u001b[0m Trial 119 finished with value: 0.662251655629139 and parameters: {'hidden_size': 359, 'activation': 'LeakyReLU', 'dropout': 0.20671394987600322, 'optimizer': 'Adagrad', 'lr': 0.0545806447253904}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16643481428325177 Test Loss: 0.16700943405873858\n",
      "Epoch: 10 Train Loss: 0.15093541784882544 Test Loss: 0.14986643505196412\n",
      "Epoch: 20 Train Loss: 0.13820164753496647 Test Loss: 0.13963075823629625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:58:42,623]\u001b[0m Trial 120 finished with value: 0.671556642216789 and parameters: {'hidden_size': 377, 'activation': 'LeakyReLU', 'dropout': 0.23320360059607526, 'optimizer': 'Adagrad', 'lr': 0.0577966449740041}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16189726634919643 Test Loss: 0.16157358431349547\n",
      "Epoch: 10 Train Loss: 0.14489804423153402 Test Loss: 0.14468224084796236\n",
      "Epoch: 20 Train Loss: 0.13385956370085478 Test Loss: 0.13944158313004448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 20:59:24,832]\u001b[0m Trial 121 finished with value: 0.6856240126382307 and parameters: {'hidden_size': 344, 'activation': 'LeakyReLU', 'dropout': 0.22830513824866344, 'optimizer': 'Adagrad', 'lr': 0.05242477504915238}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16632495749294757 Test Loss: 0.15834518448232462\n",
      "Epoch: 10 Train Loss: 0.14903477709889412 Test Loss: 0.14848555016298645\n",
      "Epoch: 20 Train Loss: 0.13602595717012883 Test Loss: 0.13832706848558146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:00:11,384]\u001b[0m Trial 122 finished with value: 0.6753883892068684 and parameters: {'hidden_size': 398, 'activation': 'LeakyReLU', 'dropout': 0.22737766729396033, 'optimizer': 'Adagrad', 'lr': 0.05243029731652496}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17431721341907977 Test Loss: 0.17226204883081084\n",
      "Epoch: 10 Train Loss: 0.1555799194008112 Test Loss: 0.15224092129986888\n",
      "Epoch: 20 Train Loss: 0.14589668622910976 Test Loss: 0.14537698729112505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:00:54,747]\u001b[0m Trial 123 finished with value: 0.6468646864686469 and parameters: {'hidden_size': 343, 'activation': 'LeakyReLU', 'dropout': 0.1874103525202211, 'optimizer': 'Adagrad', 'lr': 0.058560906344073675}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16340266308486462 Test Loss: 0.16443971469224736\n",
      "Epoch: 10 Train Loss: 0.14803879636228084 Test Loss: 0.14762979438796212\n",
      "Epoch: 20 Train Loss: 0.1317486542955041 Test Loss: 0.13648600819202278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:01:39,630]\u001b[0m Trial 124 finished with value: 0.6901408450704225 and parameters: {'hidden_size': 357, 'activation': 'LeakyReLU', 'dropout': 0.238948340610657, 'optimizer': 'Adagrad', 'lr': 0.06066706596905659}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.205583266967535 Test Loss: 0.19575701720607927\n",
      "Epoch: 10 Train Loss: 0.17716226031184196 Test Loss: 0.16900702950339347\n",
      "Epoch: 20 Train Loss: 0.15842430548667907 Test Loss: 0.15558271753354766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:02:23,182]\u001b[0m Trial 125 finished with value: 0.5978835978835979 and parameters: {'hidden_size': 352, 'activation': 'LeakyReLU', 'dropout': 0.2380280182767591, 'optimizer': 'Adagrad', 'lr': 0.0546823888398606}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.37565757641792297 Test Loss: 0.37884997921629837\n",
      "Epoch: 10 Train Loss: 0.37489716806411744 Test Loss: 0.3781976889307126\n",
      "Epoch: 20 Train Loss: 0.3732700243473053 Test Loss: 0.3768334407775928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:03:11,501]\u001b[0m Trial 126 finished with value: 0.30204962243797195 and parameters: {'hidden_size': 363, 'activation': 'Sigmoid', 'dropout': 0.2171269759181452, 'optimizer': 'Adagrad', 'lr': 0.06184997360449622}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: nan Test Loss: nan\n",
      "Epoch: 10 Train Loss: nan Test Loss: nan\n",
      "Epoch: 20 Train Loss: nan Test Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:03:49,430]\u001b[0m Trial 127 finished with value: 0.19001218026796587 and parameters: {'hidden_size': 382, 'activation': 'LeakyReLU', 'dropout': 0.20606655701386759, 'optimizer': 'SGD', 'lr': 0.056333406146349255}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16337874242067338 Test Loss: 0.156627976505187\n",
      "Epoch: 10 Train Loss: 0.14768761971890926 Test Loss: 0.14432515343799948\n",
      "Epoch: 20 Train Loss: 0.13948093767762185 Test Loss: 0.13903455771862888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:04:31,135]\u001b[0m Trial 128 finished with value: 0.6677341873498799 and parameters: {'hidden_size': 329, 'activation': 'LeakyReLU', 'dropout': 0.2292405579821523, 'optimizer': 'Adagrad', 'lr': 0.060044444071151004}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2494818432569504 Test Loss: 0.2546385155318263\n",
      "Epoch: 10 Train Loss: 0.2465402756690979 Test Loss: 0.254509887042137\n",
      "Epoch: 20 Train Loss: 0.24392123243808747 Test Loss: 0.2513425479681728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:05:12,907]\u001b[0m Trial 129 finished with value: 0.3200859291084855 and parameters: {'hidden_size': 308, 'activation': 'Tanh', 'dropout': 0.24307101362995576, 'optimizer': 'Adagrad', 'lr': 0.050183782167260785}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 23.291815809134558 Test Loss: 7.77171238374492\n",
      "Epoch: 10 Train Loss: 16.753126630061224 Test Loss: 8.500655269909428\n",
      "Epoch: 20 Train Loss: 81.8825215727508 Test Loss: 26.689583211661148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:05:56,960]\u001b[0m Trial 130 finished with value: 0.3794683776351971 and parameters: {'hidden_size': 343, 'activation': 'LeakyReLU', 'dropout': 0.19679935068103688, 'optimizer': 'Adam', 'lr': 0.04889223839341088}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17511143988370895 Test Loss: 0.17183778670649177\n",
      "Epoch: 10 Train Loss: 0.15439094327390193 Test Loss: 0.15108011038706134\n",
      "Epoch: 20 Train Loss: 0.1392484034642577 Test Loss: 0.1381707381183347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:06:42,891]\u001b[0m Trial 131 finished with value: 0.6889952153110048 and parameters: {'hidden_size': 374, 'activation': 'LeakyReLU', 'dropout': 0.24789672370840923, 'optimizer': 'Adagrad', 'lr': 0.052639123523121174}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1762269740641117 Test Loss: 0.17059030110081927\n",
      "Epoch: 10 Train Loss: 0.15525849367380143 Test Loss: 0.15171796511323116\n",
      "Epoch: 20 Train Loss: 0.14109060117453337 Test Loss: 0.14196846193184678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:07:28,366]\u001b[0m Trial 132 finished with value: 0.6688051323175621 and parameters: {'hidden_size': 370, 'activation': 'LeakyReLU', 'dropout': 0.2241800193287501, 'optimizer': 'Adagrad', 'lr': 0.053786426756606484}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17307189795225858 Test Loss: 0.16937999133639536\n",
      "Epoch: 10 Train Loss: 0.157923761805892 Test Loss: 0.15251812163276224\n",
      "Epoch: 20 Train Loss: 0.14151729573756455 Test Loss: 0.13913724203103076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:08:12,691]\u001b[0m Trial 133 finished with value: 0.6752 and parameters: {'hidden_size': 355, 'activation': 'LeakyReLU', 'dropout': 0.23828595883918025, 'optimizer': 'Adagrad', 'lr': 0.05596526356137954}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1885963739812374 Test Loss: 0.18759528830195196\n",
      "Epoch: 10 Train Loss: 0.158737267690897 Test Loss: 0.15901023661271452\n",
      "Epoch: 20 Train Loss: 0.1451876093506813 Test Loss: 0.14651960238052633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:08:58,778]\u001b[0m Trial 134 finished with value: 0.6590538336052203 and parameters: {'hidden_size': 385, 'activation': 'LeakyReLU', 'dropout': 0.213677088392127, 'optimizer': 'Adagrad', 'lr': 0.05866799099900858}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17506685710549355 Test Loss: 0.1679767900810074\n",
      "Epoch: 10 Train Loss: 0.15356734375953673 Test Loss: 0.14756903620049977\n",
      "Epoch: 20 Train Loss: 0.13963625865876675 Test Loss: 0.14029986200669703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:09:41,748]\u001b[0m Trial 135 finished with value: 0.6844166014095537 and parameters: {'hidden_size': 338, 'activation': 'LeakyReLU', 'dropout': 0.2590381908199699, 'optimizer': 'Adagrad', 'lr': 0.06472433912258992}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1625210859492421 Test Loss: 0.15407395950807168\n",
      "Epoch: 10 Train Loss: 0.15179418665915728 Test Loss: 0.14456919983576852\n",
      "Epoch: 20 Train Loss: 0.13298846779763698 Test Loss: 0.137469036900364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:10:27,093]\u001b[0m Trial 136 finished with value: 0.6936236391912909 and parameters: {'hidden_size': 376, 'activation': 'LeakyReLU', 'dropout': 0.24811739974139232, 'optimizer': 'Adagrad', 'lr': 0.052637231712921034}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.20854987240433692 Test Loss: 0.1967190812809018\n",
      "Epoch: 10 Train Loss: 0.18311183920502663 Test Loss: 0.1687346689712506\n",
      "Epoch: 20 Train Loss: 0.16994293709397315 Test Loss: 0.15312848992931385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:11:08,156]\u001b[0m Trial 137 finished with value: 0.6246764452113892 and parameters: {'hidden_size': 59, 'activation': 'LeakyReLU', 'dropout': 0.2494542769887768, 'optimizer': 'Adagrad', 'lr': 0.05243876032977873}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16994385353028774 Test Loss: 0.16342230798742072\n",
      "Epoch: 10 Train Loss: 0.15132780163884163 Test Loss: 0.14866529169459694\n",
      "Epoch: 20 Train Loss: 0.13593604224026204 Test Loss: 0.14366345144451237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:11:53,493]\u001b[0m Trial 138 finished with value: 0.6884226884226884 and parameters: {'hidden_size': 377, 'activation': 'LeakyReLU', 'dropout': 0.26762369264150876, 'optimizer': 'Adagrad', 'lr': 0.04885768948603383}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1640484571635723 Test Loss: 0.16150068533353912\n",
      "Epoch: 10 Train Loss: 0.15196090920120478 Test Loss: 0.1472092117911901\n",
      "Epoch: 20 Train Loss: 0.13641229286789894 Test Loss: 0.1371275945998038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:12:40,660]\u001b[0m Trial 139 finished with value: 0.691397000789266 and parameters: {'hidden_size': 391, 'activation': 'LeakyReLU', 'dropout': 0.266070446868385, 'optimizer': 'Adagrad', 'lr': 0.05034688924743683}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6953960469245911 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:13:28,678]\u001b[0m Trial 140 finished with value: 0.0 and parameters: {'hidden_size': 392, 'activation': 'ReLU', 'dropout': 0.2685512352639801, 'optimizer': 'Adagrad', 'lr': 0.04884196272186011}. Best is trial 95 with value: 0.6947535771065183.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1645168954104185 Test Loss: 0.17360421935149942\n",
      "Epoch: 10 Train Loss: 0.15270375573933123 Test Loss: 0.15065601518669258\n",
      "Epoch: 20 Train Loss: 0.13795625087171792 Test Loss: 0.13885278657031136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:14:14,389]\u001b[0m Trial 141 finished with value: 0.6949152542372882 and parameters: {'hidden_size': 377, 'activation': 'LeakyReLU', 'dropout': 0.232280303261473, 'optimizer': 'Adagrad', 'lr': 0.05074755406045694}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17147745912969112 Test Loss: 0.17009754897877813\n",
      "Epoch: 10 Train Loss: 0.15572507828772067 Test Loss: 0.15425142553001167\n",
      "Epoch: 20 Train Loss: 0.14197621903717517 Test Loss: 0.14239555594627373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:14:58,986]\u001b[0m Trial 142 finished with value: 0.6746987951807228 and parameters: {'hidden_size': 376, 'activation': 'LeakyReLU', 'dropout': 0.26114903836692055, 'optimizer': 'Adagrad', 'lr': 0.05031263568944889}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17750622646212577 Test Loss: 0.17108954621342043\n",
      "Epoch: 10 Train Loss: 0.15136982954740524 Test Loss: 0.152829378581466\n",
      "Epoch: 20 Train Loss: 0.1366866957642138 Test Loss: 0.13907946312960726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:15:45,293]\u001b[0m Trial 143 finished with value: 0.6804123711340206 and parameters: {'hidden_size': 397, 'activation': 'LeakyReLU', 'dropout': 0.23997581104883245, 'optimizer': 'Adagrad', 'lr': 0.0486215803756692}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17252443111538887 Test Loss: 0.16910350263213958\n",
      "Epoch: 10 Train Loss: 0.15275237827599047 Test Loss: 0.15034452004554555\n",
      "Epoch: 20 Train Loss: 0.1394464222252369 Test Loss: 0.13892918761474446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:16:30,563]\u001b[0m Trial 144 finished with value: 0.6715686274509803 and parameters: {'hidden_size': 376, 'activation': 'LeakyReLU', 'dropout': 0.25246316432234633, 'optimizer': 'Adagrad', 'lr': 0.045899812105408694}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1705170482829213 Test Loss: 0.16970056406082437\n",
      "Epoch: 10 Train Loss: 0.1522539416387677 Test Loss: 0.15397907912838288\n",
      "Epoch: 20 Train Loss: 0.1375995044797659 Test Loss: 0.1403103412364047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:17:17,224]\u001b[0m Trial 145 finished with value: 0.6796116504854369 and parameters: {'hidden_size': 383, 'activation': 'LeakyReLU', 'dropout': 0.27290224355035975, 'optimizer': 'Adagrad', 'lr': 0.050897255490122285}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1672018492102623 Test Loss: 0.16617880209375874\n",
      "Epoch: 10 Train Loss: 0.1494172192007303 Test Loss: 0.14941690053148105\n",
      "Epoch: 20 Train Loss: 0.13688449852615595 Test Loss: 0.13842595310899586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:18:03,636]\u001b[0m Trial 146 finished with value: 0.6842105263157895 and parameters: {'hidden_size': 408, 'activation': 'LeakyReLU', 'dropout': 0.24677907748171685, 'optimizer': 'Adagrad', 'lr': 0.05744615026981139}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17053709525465965 Test Loss: 0.16325483909739663\n",
      "Epoch: 10 Train Loss: 0.1478843365907669 Test Loss: 0.14937675069755735\n",
      "Epoch: 20 Train Loss: 0.1403727353796363 Test Loss: 0.14315320308596943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:18:50,606]\u001b[0m Trial 147 finished with value: 0.6748166259168705 and parameters: {'hidden_size': 423, 'activation': 'LeakyReLU', 'dropout': 0.2638455757441688, 'optimizer': 'Adagrad', 'lr': 0.04329836124422794}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17112193121016026 Test Loss: 0.16972091739860395\n",
      "Epoch: 10 Train Loss: 0.15291534217894076 Test Loss: 0.14940849721979219\n",
      "Epoch: 20 Train Loss: 0.1355089014917612 Test Loss: 0.13870735502185913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:19:33,700]\u001b[0m Trial 148 finished with value: 0.6863527533918596 and parameters: {'hidden_size': 390, 'activation': 'LeakyReLU', 'dropout': 0.23392134472778575, 'optimizer': 'Adagrad', 'lr': 0.047874811440285873}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.15884375859797 Test Loss: 0.156959459215355\n",
      "Epoch: 10 Train Loss: 0.14924735024869443 Test Loss: 0.1468904926992072\n",
      "Epoch: 20 Train Loss: 0.13449106366187333 Test Loss: 0.1389402656580884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:20:18,391]\u001b[0m Trial 149 finished with value: 0.694136291600634 and parameters: {'hidden_size': 392, 'activation': 'LeakyReLU', 'dropout': 0.232299422047246, 'optimizer': 'Adagrad', 'lr': 0.0531830768691149}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17400880582332612 Test Loss: 0.17688042086700853\n",
      "Epoch: 10 Train Loss: 0.15315032900869846 Test Loss: 0.15253827802408426\n",
      "Epoch: 20 Train Loss: 0.13752612056285143 Test Loss: 0.13871921877415416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:21:06,331]\u001b[0m Trial 150 finished with value: 0.6836248012718602 and parameters: {'hidden_size': 389, 'activation': 'LeakyReLU', 'dropout': 0.24199361502165437, 'optimizer': 'Adagrad', 'lr': 0.05329635448490223}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.175574921259284 Test Loss: 0.16415513422899544\n",
      "Epoch: 10 Train Loss: 0.158543287101388 Test Loss: 0.1508621543514938\n",
      "Epoch: 20 Train Loss: 0.14313615182042122 Test Loss: 0.14018720993623376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:21:56,086]\u001b[0m Trial 151 finished with value: 0.6725806451612902 and parameters: {'hidden_size': 403, 'activation': 'LeakyReLU', 'dropout': 0.2324699711905974, 'optimizer': 'Adagrad', 'lr': 0.05533959593387272}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17320478965640068 Test Loss: 0.1644661240041637\n",
      "Epoch: 10 Train Loss: 0.1538685123294592 Test Loss: 0.1529829522636466\n",
      "Epoch: 20 Train Loss: 0.14025804380476475 Test Loss: 0.14253279056173926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:22:43,981]\u001b[0m Trial 152 finished with value: 0.6699107866991079 and parameters: {'hidden_size': 369, 'activation': 'LeakyReLU', 'dropout': 0.22455692996731758, 'optimizer': 'Adagrad', 'lr': 0.048410066948129944}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17399389939308166 Test Loss: 0.1657221539201923\n",
      "Epoch: 10 Train Loss: 0.15187386010289192 Test Loss: 0.15160475945034727\n",
      "Epoch: 20 Train Loss: 0.13879819514751435 Test Loss: 0.14398044043669875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:23:33,598]\u001b[0m Trial 153 finished with value: 0.672566371681416 and parameters: {'hidden_size': 392, 'activation': 'LeakyReLU', 'dropout': 0.25335956435889456, 'optimizer': 'Adagrad', 'lr': 0.051195896538979505}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16031066184937953 Test Loss: 0.15586738994779487\n",
      "Epoch: 10 Train Loss: 0.1472311115309596 Test Loss: 0.1440011988373134\n",
      "Epoch: 20 Train Loss: 0.13400428108870982 Test Loss: 0.13970672198758718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:24:19,232]\u001b[0m Trial 154 finished with value: 0.6882399368587214 and parameters: {'hidden_size': 355, 'activation': 'LeakyReLU', 'dropout': 0.20522633854865535, 'optimizer': 'Adagrad', 'lr': 0.05301617091721737}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1845727873146534 Test Loss: 0.17567001427181614\n",
      "Epoch: 10 Train Loss: 0.16268888320028782 Test Loss: 0.15553646939940535\n",
      "Epoch: 20 Train Loss: 0.14654468555152417 Test Loss: 0.1420909307789974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:25:08,845]\u001b[0m Trial 155 finished with value: 0.6566164154103852 and parameters: {'hidden_size': 375, 'activation': 'LeakyReLU', 'dropout': 0.20260977967005384, 'optimizer': 'Adagrad', 'lr': 0.052969069191369504}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.3754822455406189 Test Loss: 0.3788106411981126\n",
      "Epoch: 10 Train Loss: 0.3754500287055969 Test Loss: 0.3788841713350802\n",
      "Epoch: 20 Train Loss: 0.3754311673164368 Test Loss: 0.3787704425307509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:25:59,078]\u001b[0m Trial 156 finished with value: 0.2079806529625151 and parameters: {'hidden_size': 356, 'activation': 'Sigmoid', 'dropout': 0.19487204431834843, 'optimizer': 'Adagrad', 'lr': 0.044716260887757465}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.20382558570802212 Test Loss: 0.2012324081704068\n",
      "Epoch: 10 Train Loss: 0.17647530717849733 Test Loss: 0.17782817486994945\n",
      "Epoch: 20 Train Loss: 0.1557263768851757 Test Loss: 0.15190922340955407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:26:40,155]\u001b[0m Trial 157 finished with value: 0.6101141924959217 and parameters: {'hidden_size': 413, 'activation': 'LeakyReLU', 'dropout': 0.18774448293692736, 'optimizer': 'SGD', 'lr': 0.04991663378607206}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16811122308373452 Test Loss: 0.158471043224628\n",
      "Epoch: 10 Train Loss: 0.15216207479685545 Test Loss: 0.15034318374642452\n",
      "Epoch: 20 Train Loss: 0.13935427750349044 Test Loss: 0.13879429560285597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:27:26,989]\u001b[0m Trial 158 finished with value: 0.6709781729991916 and parameters: {'hidden_size': 352, 'activation': 'LeakyReLU', 'dropout': 0.2350988734071236, 'optimizer': 'Adagrad', 'lr': 0.05715447833549634}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 59.395433013175335 Test Loss: 11.11533699582179\n",
      "Epoch: 10 Train Loss: 21.76837282811369 Test Loss: 11.673888532212748\n",
      "Epoch: 20 Train Loss: 69.56234978338806 Test Loss: 74.70812820093319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:28:16,240]\u001b[0m Trial 159 finished with value: 0.26255707762557073 and parameters: {'hidden_size': 364, 'activation': 'LeakyReLU', 'dropout': 0.20872936418059979, 'optimizer': 'Adam', 'lr': 0.053936133034118476}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.2512306871652603 Test Loss: 0.25771600950640233\n",
      "Epoch: 10 Train Loss: 0.251227867937088 Test Loss: 0.2583154035738101\n",
      "Epoch: 20 Train Loss: 0.2500128297805786 Test Loss: 0.2555992702325693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:29:05,593]\u001b[0m Trial 160 finished with value: 0.22700119474313019 and parameters: {'hidden_size': 397, 'activation': 'Tanh', 'dropout': 0.2186319566777005, 'optimizer': 'Adagrad', 'lr': 0.04821095665908434}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16354491781294345 Test Loss: 0.1759731394384568\n",
      "Epoch: 10 Train Loss: 0.14610068300366402 Test Loss: 0.14502597599031444\n",
      "Epoch: 20 Train Loss: 0.1336006197065115 Test Loss: 0.1363478260525404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:29:53,519]\u001b[0m Trial 161 finished with value: 0.6774454324979788 and parameters: {'hidden_size': 379, 'activation': 'LeakyReLU', 'dropout': 0.22992686678544055, 'optimizer': 'Adagrad', 'lr': 0.05151884278897972}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1704999809205532 Test Loss: 0.16569153036767492\n",
      "Epoch: 10 Train Loss: 0.15219872114658356 Test Loss: 0.15053640202449534\n",
      "Epoch: 20 Train Loss: 0.1393857601597905 Test Loss: 0.13943578863439088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:30:38,773]\u001b[0m Trial 162 finished with value: 0.6737357259380099 and parameters: {'hidden_size': 370, 'activation': 'LeakyReLU', 'dropout': 0.24562621989877287, 'optimizer': 'Adagrad', 'lr': 0.06055618096712669}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.19393902602791785 Test Loss: 0.18161673285067081\n",
      "Epoch: 10 Train Loss: 0.1697205598473549 Test Loss: 0.1635020405839617\n",
      "Epoch: 20 Train Loss: 0.15288267884552478 Test Loss: 0.15385299277143738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:31:25,036]\u001b[0m Trial 163 finished with value: 0.6550079491255962 and parameters: {'hidden_size': 389, 'activation': 'LeakyReLU', 'dropout': 0.21250575800182847, 'optimizer': 'Adagrad', 'lr': 0.05753963512395693}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17366897248029708 Test Loss: 0.16861675901058765\n",
      "Epoch: 10 Train Loss: 0.16087801266312599 Test Loss: 0.15175484253551824\n",
      "Epoch: 20 Train Loss: 0.14563095782548188 Test Loss: 0.14316569812024554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:32:10,233]\u001b[0m Trial 164 finished with value: 0.6778309409888357 and parameters: {'hidden_size': 358, 'activation': 'LeakyReLU', 'dropout': 0.27828171959743286, 'optimizer': 'Adagrad', 'lr': 0.05530717314902452}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1710916193783283 Test Loss: 0.16579929986200964\n",
      "Epoch: 10 Train Loss: 0.15229898602962494 Test Loss: 0.14714146861895777\n",
      "Epoch: 20 Train Loss: 0.13977156798392534 Test Loss: 0.14279896452630195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:32:53,858]\u001b[0m Trial 165 finished with value: 0.6719492868462758 and parameters: {'hidden_size': 348, 'activation': 'LeakyReLU', 'dropout': 0.2554880794953066, 'optimizer': 'Adagrad', 'lr': 0.04685053465184726}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1714802629262209 Test Loss: 0.19443843837160937\n",
      "Epoch: 10 Train Loss: 0.15143057563453913 Test Loss: 0.1525838031543615\n",
      "Epoch: 20 Train Loss: 0.13777739490568638 Test Loss: 0.14306789343527998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:33:40,535]\u001b[0m Trial 166 finished with value: 0.6736000000000001 and parameters: {'hidden_size': 419, 'activation': 'LeakyReLU', 'dropout': 0.16843444366267063, 'optimizer': 'Adagrad', 'lr': 0.05290199986702069}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17514400035738945 Test Loss: 0.1690674755043877\n",
      "Epoch: 10 Train Loss: 0.1573827197164297 Test Loss: 0.1489864189665729\n",
      "Epoch: 20 Train Loss: 0.14082663630992173 Test Loss: 0.1391093505802341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:34:27,062]\u001b[0m Trial 167 finished with value: 0.6850202429149798 and parameters: {'hidden_size': 383, 'activation': 'LeakyReLU', 'dropout': 0.26219870966767667, 'optimizer': 'Adagrad', 'lr': 0.05879131868714282}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1598701961249113 Test Loss: 0.1575112494821556\n",
      "Epoch: 10 Train Loss: 0.1435014343082905 Test Loss: 0.14957257331060336\n",
      "Epoch: 20 Train Loss: 0.13053981834948064 Test Loss: 0.1366791408389997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:35:13,673]\u001b[0m Trial 168 finished with value: 0.6865203761755486 and parameters: {'hidden_size': 402, 'activation': 'LeakyReLU', 'dropout': 0.22412498861559904, 'optimizer': 'Adagrad', 'lr': 0.05032420967736595}. Best is trial 141 with value: 0.6949152542372882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.15315626100301744 Test Loss: 0.14980550072849178\n",
      "Epoch: 10 Train Loss: 0.14066762942671776 Test Loss: 0.14170081313318625\n",
      "Epoch: 20 Train Loss: 0.12910225616693496 Test Loss: 0.1351592534968552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:36:00,604]\u001b[0m Trial 169 finished with value: 0.6973180076628352 and parameters: {'hidden_size': 404, 'activation': 'LeakyReLU', 'dropout': 0.22080808632699706, 'optimizer': 'Adagrad', 'lr': 0.05101708122077196}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1732230337366462 Test Loss: 0.17376551939585147\n",
      "Epoch: 10 Train Loss: 0.15541579828858376 Test Loss: 0.1501301388068797\n",
      "Epoch: 20 Train Loss: 0.1373060986429453 Test Loss: 0.1403482726182991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:36:46,294]\u001b[0m Trial 170 finished with value: 0.6858924395947 and parameters: {'hidden_size': 404, 'activation': 'LeakyReLU', 'dropout': 0.21900193061673984, 'optimizer': 'Adagrad', 'lr': 0.04975420651871135}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.15778915604054927 Test Loss: 0.15659226134371834\n",
      "Epoch: 10 Train Loss: 0.14689116273522376 Test Loss: 0.14994440958820307\n",
      "Epoch: 20 Train Loss: 0.1289763592019677 Test Loss: 0.13676631770218714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:37:32,573]\u001b[0m Trial 171 finished with value: 0.689873417721519 and parameters: {'hidden_size': 405, 'activation': 'LeakyReLU', 'dropout': 0.21935150818236462, 'optimizer': 'Adagrad', 'lr': 0.04970994481605959}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16688920875489713 Test Loss: 0.16726265972652754\n",
      "Epoch: 10 Train Loss: 0.15477241347432136 Test Loss: 0.15412441867228133\n",
      "Epoch: 20 Train Loss: 0.13898689069002867 Test Loss: 0.13833758874108998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:38:19,242]\u001b[0m Trial 172 finished with value: 0.6848 and parameters: {'hidden_size': 421, 'activation': 'LeakyReLU', 'dropout': 0.20366508617511914, 'optimizer': 'Adagrad', 'lr': 0.05086668275718486}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16994424262046814 Test Loss: 0.16262255659023414\n",
      "Epoch: 10 Train Loss: 0.15244113655388355 Test Loss: 0.14596253989365535\n",
      "Epoch: 20 Train Loss: 0.13704899502545595 Test Loss: 0.13909619900222403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:39:04,616]\u001b[0m Trial 173 finished with value: 0.682769726247987 and parameters: {'hidden_size': 400, 'activation': 'LeakyReLU', 'dropout': 0.2256215015068016, 'optimizer': 'Adagrad', 'lr': 0.05447267951769689}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17237487511634828 Test Loss: 0.16482926216035987\n",
      "Epoch: 10 Train Loss: 0.1492894804984331 Test Loss: 0.14799380910020477\n",
      "Epoch: 20 Train Loss: 0.13894635475575923 Test Loss: 0.14215435133503077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:40:31,591]\u001b[0m Trial 174 finished with value: 0.6909937888198757 and parameters: {'hidden_size': 434, 'activation': 'LeakyReLU', 'dropout': 0.23851105283191043, 'optimizer': 'Adagrad', 'lr': 0.05211814376540183}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1713420941531658 Test Loss: 0.16428074162727158\n",
      "Epoch: 10 Train Loss: 0.15506840228438376 Test Loss: 0.1514157459330254\n",
      "Epoch: 20 Train Loss: 0.141762479236722 Test Loss: 0.14617102426557113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:41:59,525]\u001b[0m Trial 175 finished with value: 0.6792452830188679 and parameters: {'hidden_size': 438, 'activation': 'LeakyReLU', 'dropout': 0.24497199396809136, 'optimizer': 'Adagrad', 'lr': 0.052214523707549816}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18220441018640995 Test Loss: 0.1788585603046722\n",
      "Epoch: 10 Train Loss: 0.1612900836750865 Test Loss: 0.1604918299463039\n",
      "Epoch: 20 Train Loss: 0.14136528340131044 Test Loss: 0.1418096442221881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:43:08,458]\u001b[0m Trial 176 finished with value: 0.6963746223564954 and parameters: {'hidden_size': 452, 'activation': 'LeakyReLU', 'dropout': 0.21482418829552805, 'optimizer': 'Adagrad', 'lr': 0.055774934204636556}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 10 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n",
      "Epoch: 20 Train Loss: 0.6931474804878235 Test Loss: 0.6931474799165329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:44:28,856]\u001b[0m Trial 177 finished with value: 0.0 and parameters: {'hidden_size': 463, 'activation': 'ReLU', 'dropout': 0.2146587120621022, 'optimizer': 'Adagrad', 'lr': 0.05582058774296722}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16824037973582745 Test Loss: 0.1681491647974942\n",
      "Epoch: 10 Train Loss: 0.1532406656652689 Test Loss: 0.1507135157149059\n",
      "Epoch: 20 Train Loss: 0.138532036010921 Test Loss: 0.13753472170390832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:45:51,964]\u001b[0m Trial 178 finished with value: 0.6918744971842317 and parameters: {'hidden_size': 412, 'activation': 'LeakyReLU', 'dropout': 0.23914355187588682, 'optimizer': 'Adagrad', 'lr': 0.05385683096539305}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.15841591170430183 Test Loss: 0.15262663638748872\n",
      "Epoch: 10 Train Loss: 0.14257102864682675 Test Loss: 0.1413846499325273\n",
      "Epoch: 20 Train Loss: 0.12952144207656383 Test Loss: 0.13616294846438562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:47:08,996]\u001b[0m Trial 179 finished with value: 0.6921850079744816 and parameters: {'hidden_size': 450, 'activation': 'LeakyReLU', 'dropout': 0.23809273832711522, 'optimizer': 'Adagrad', 'lr': 0.056150504456932544}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16359199692606927 Test Loss: 0.15629840885012294\n",
      "Epoch: 10 Train Loss: 0.14763333067297935 Test Loss: 0.1463577193252671\n",
      "Epoch: 20 Train Loss: 0.13650644467175008 Test Loss: 0.13909918381371342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:48:25,432]\u001b[0m Trial 180 finished with value: 0.6826156299840511 and parameters: {'hidden_size': 432, 'activation': 'LeakyReLU', 'dropout': 0.24038217427357456, 'optimizer': 'Adagrad', 'lr': 0.06181358980698262}. Best is trial 169 with value: 0.6973180076628352.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17387714110016822 Test Loss: 0.1657158029607881\n",
      "Epoch: 10 Train Loss: 0.15376511516571045 Test Loss: 0.14923656573548866\n",
      "Epoch: 20 Train Loss: 0.1383954999655485 Test Loss: 0.13966076932966517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:49:40,210]\u001b[0m Trial 181 finished with value: 0.6986089644513137 and parameters: {'hidden_size': 450, 'activation': 'LeakyReLU', 'dropout': 0.2091249349510601, 'optimizer': 'Adagrad', 'lr': 0.0541295872872291}. Best is trial 181 with value: 0.6986089644513137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17063160891830922 Test Loss: 0.1687706157136649\n",
      "Epoch: 10 Train Loss: 0.15149785913228989 Test Loss: 0.14863803605444895\n",
      "Epoch: 20 Train Loss: 0.1369222525179386 Test Loss: 0.139193619913853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:50:55,584]\u001b[0m Trial 182 finished with value: 0.6720779220779222 and parameters: {'hidden_size': 450, 'activation': 'LeakyReLU', 'dropout': 0.23522757978567613, 'optimizer': 'Adagrad', 'lr': 0.05627195485216134}. Best is trial 181 with value: 0.6986089644513137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17133632653057576 Test Loss: 0.17176006815899103\n",
      "Epoch: 10 Train Loss: 0.1545179167509079 Test Loss: 0.15011759208271297\n",
      "Epoch: 20 Train Loss: 0.1390737199857831 Test Loss: 0.13966162402789814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:52:10,682]\u001b[0m Trial 183 finished with value: 0.6842948717948718 and parameters: {'hidden_size': 462, 'activation': 'LeakyReLU', 'dropout': 0.2492873400382629, 'optimizer': 'Adagrad', 'lr': 0.05869839154416509}. Best is trial 181 with value: 0.6986089644513137.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16806809974610806 Test Loss: 0.1621456376065652\n",
      "Epoch: 10 Train Loss: 0.15034006265252828 Test Loss: 0.15651142086905126\n",
      "Epoch: 20 Train Loss: 0.1377179930537939 Test Loss: 0.13733717958076883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:53:29,608]\u001b[0m Trial 184 finished with value: 0.698738170347003 and parameters: {'hidden_size': 447, 'activation': 'LeakyReLU', 'dropout': 0.2188609755319821, 'optimizer': 'Adagrad', 'lr': 0.05472873098998649}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16870605740994216 Test Loss: 0.1606738826099295\n",
      "Epoch: 10 Train Loss: 0.15422775563001634 Test Loss: 0.14866327233731555\n",
      "Epoch: 20 Train Loss: 0.13891944629848002 Test Loss: 0.13756041608441372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:54:54,836]\u001b[0m Trial 185 finished with value: 0.6762820512820513 and parameters: {'hidden_size': 470, 'activation': 'LeakyReLU', 'dropout': 0.21421219561341173, 'optimizer': 'Adagrad', 'lr': 0.053993071919668144}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16468813973218202 Test Loss: 0.1602829642974721\n",
      "Epoch: 10 Train Loss: 0.14772152505517006 Test Loss: 0.14414494531080366\n",
      "Epoch: 20 Train Loss: 0.1353168724089861 Test Loss: 0.14297528623993072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:56:01,211]\u001b[0m Trial 186 finished with value: 0.6902654867256637 and parameters: {'hidden_size': 447, 'activation': 'LeakyReLU', 'dropout': 0.2204630815047897, 'optimizer': 'Adagrad', 'lr': 0.056957676417624586}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17644819487333296 Test Loss: 0.17056091924825798\n",
      "Epoch: 10 Train Loss: 0.15435062780082226 Test Loss: 0.15407800667297344\n",
      "Epoch: 20 Train Loss: 0.13801248693168164 Test Loss: 0.14246972054600143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:57:23,135]\u001b[0m Trial 187 finished with value: 0.6874003189792663 and parameters: {'hidden_size': 443, 'activation': 'LeakyReLU', 'dropout': 0.22216802981982708, 'optimizer': 'Adagrad', 'lr': 0.06030008891525084}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1833554044932127 Test Loss: 0.17978429676482852\n",
      "Epoch: 10 Train Loss: 0.163307775837183 Test Loss: 0.1639083537656945\n",
      "Epoch: 20 Train Loss: 0.14576154704093933 Test Loss: 0.1443256898559987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:58:31,842]\u001b[0m Trial 188 finished with value: 0.6546938775510204 and parameters: {'hidden_size': 441, 'activation': 'LeakyReLU', 'dropout': 0.20296273748015958, 'optimizer': 'SGD', 'lr': 0.05714773173226536}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.37602890701293945 Test Loss: 0.3793845667054478\n",
      "Epoch: 10 Train Loss: 0.3757615910053253 Test Loss: 0.379050501428854\n",
      "Epoch: 20 Train Loss: 0.37568825826644897 Test Loss: 0.3789101243971255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 21:59:43,997]\u001b[0m Trial 189 finished with value: 0.2079806529625151 and parameters: {'hidden_size': 430, 'activation': 'Sigmoid', 'dropout': 0.19443379615843676, 'optimizer': 'Adagrad', 'lr': 0.055513494614227936}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16661200427412987 Test Loss: 0.16169336122779038\n",
      "Epoch: 10 Train Loss: 0.14987334685474635 Test Loss: 0.1497134535005108\n",
      "Epoch: 20 Train Loss: 0.13721521892547608 Test Loss: 0.14094899330859462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:00:48,253]\u001b[0m Trial 190 finished with value: 0.6809864757358791 and parameters: {'hidden_size': 451, 'activation': 'LeakyReLU', 'dropout': 0.23065880958165386, 'optimizer': 'Adagrad', 'lr': 0.0583918345508164}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16657169981598854 Test Loss: 0.1605809135868336\n",
      "Epoch: 10 Train Loss: 0.1496220475718379 Test Loss: 0.1552210119419014\n",
      "Epoch: 20 Train Loss: 0.13683389914035798 Test Loss: 0.1368579163302343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:02:03,655]\u001b[0m Trial 191 finished with value: 0.6845093268450932 and parameters: {'hidden_size': 453, 'activation': 'LeakyReLU', 'dropout': 0.2199785035208119, 'optimizer': 'Adagrad', 'lr': 0.05372149238992072}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.1725514240682125 Test Loss: 0.17163700154557016\n",
      "Epoch: 10 Train Loss: 0.1519681423664093 Test Loss: 0.16262340219542623\n",
      "Epoch: 20 Train Loss: 0.138801724088192 Test Loss: 0.13889404058980104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:03:22,802]\u001b[0m Trial 192 finished with value: 0.685126582278481 and parameters: {'hidden_size': 482, 'activation': 'LeakyReLU', 'dropout': 0.23526307258128845, 'optimizer': 'Adagrad', 'lr': 0.05580919319654463}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16685813244283199 Test Loss: 0.16374470328632446\n",
      "Epoch: 10 Train Loss: 0.14951186825633048 Test Loss: 0.14630927388279583\n",
      "Epoch: 20 Train Loss: 0.13571263853907586 Test Loss: 0.13985161177409342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:04:08,707]\u001b[0m Trial 193 finished with value: 0.6848436246992783 and parameters: {'hidden_size': 426, 'activation': 'LeakyReLU', 'dropout': 0.21318640538918818, 'optimizer': 'Adagrad', 'lr': 0.05204840124551665}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.18311760911345482 Test Loss: 0.17368027645225723\n",
      "Epoch: 10 Train Loss: 0.1620102045506239 Test Loss: 0.15885513865005094\n",
      "Epoch: 20 Train Loss: 0.1415592531144619 Test Loss: 0.14563663494877352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:05:31,612]\u001b[0m Trial 194 finished with value: 0.6517783291976841 and parameters: {'hidden_size': 414, 'activation': 'LeakyReLU', 'dropout': 0.2415592239899434, 'optimizer': 'Adagrad', 'lr': 0.06332628152884508}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17057794546186925 Test Loss: 0.16681800593440524\n",
      "Epoch: 10 Train Loss: 0.153661590385437 Test Loss: 0.14963076428507274\n",
      "Epoch: 20 Train Loss: 0.1399947969019413 Test Loss: 0.13997098357794574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:06:50,319]\u001b[0m Trial 195 finished with value: 0.6567656765676567 and parameters: {'hidden_size': 470, 'activation': 'LeakyReLU', 'dropout': 0.22490554570464275, 'optimizer': 'Adagrad', 'lr': 0.05481758522932586}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16488735791444778 Test Loss: 0.15869934276674694\n",
      "Epoch: 10 Train Loss: 0.14614178779572248 Test Loss: 0.14415998703922137\n",
      "Epoch: 20 Train Loss: 0.13538251168429852 Test Loss: 0.1376951122507691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:08:16,311]\u001b[0m Trial 196 finished with value: 0.6871069182389937 and parameters: {'hidden_size': 448, 'activation': 'LeakyReLU', 'dropout': 0.2555757119934896, 'optimizer': 'Adagrad', 'lr': 0.05754634822064231}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.17426999523937703 Test Loss: 0.16716095723045138\n",
      "Epoch: 10 Train Loss: 0.14952355950474738 Test Loss: 0.1466701556854069\n",
      "Epoch: 20 Train Loss: 0.1342390373274684 Test Loss: 0.13660044506930125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:09:37,898]\u001b[0m Trial 197 finished with value: 0.6951124903025602 and parameters: {'hidden_size': 429, 'activation': 'LeakyReLU', 'dropout': 0.2092281015352514, 'optimizer': 'Adagrad', 'lr': 0.05185042882392827}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.26842803242206575 Test Loss: 0.2750909773115152\n",
      "Epoch: 10 Train Loss: 0.2684280369520187 Test Loss: 0.2754903358106796\n",
      "Epoch: 20 Train Loss: 0.2684280343055725 Test Loss: 0.27549034366592434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:10:57,768]\u001b[0m Trial 198 finished with value: 0.0 and parameters: {'hidden_size': 432, 'activation': 'Tanh', 'dropout': 0.18203720234157192, 'optimizer': 'Adam', 'lr': 0.06005681644367762}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Train Loss: 0.16294684230685233 Test Loss: 0.15893994612149157\n",
      "Epoch: 10 Train Loss: 0.1479995720297098 Test Loss: 0.14700700679478554\n",
      "Epoch: 20 Train Loss: 0.1329086385399103 Test Loss: 0.13888307400166797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-26 22:12:13,361]\u001b[0m Trial 199 finished with value: 0.6715328467153284 and parameters: {'hidden_size': 458, 'activation': 'LeakyReLU', 'dropout': 0.20748605048046426, 'optimizer': 'Adagrad', 'lr': 0.05141024874293361}. Best is trial 184 with value: 0.698738170347003.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def objective(trial):\n",
    "    epochs = 25\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 512)\n",
    "    activation = trial.suggest_categorical('activation', ['ReLU', 'LeakyReLU', 'Tanh', 'Sigmoid'])\n",
    "    dropout = trial.suggest_float('dropout', 0, 0.5)\n",
    "    model = Model(hidden_size=hidden_size, activation=getattr(nn, activation)(), dropout=dropout).to(device)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'Adagrad', 'SGD'])\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-1)\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    train_losses, test_losses, train_f1_scores, test_f1_scores = train(loss, optimizer, model, train_dataloader, test_dataloader, device, epochs)\n",
    "    return max(test_f1_scores)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_size': 447,\n",
       " 'activation': 'LeakyReLU',\n",
       " 'dropout': 0.2188609755319821,\n",
       " 'optimizer': 'Adagrad',\n",
       " 'lr': 0.05472873098998649}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 Train Loss: 0.13392574403434993 Test Loss: 0.13833707363341755\n",
      "Epoch: 40 Train Loss: 0.12104908499270678 Test Loss: 0.13152654697529423\n",
      "Epoch: 80 Train Loss: 0.10789525332301855 Test Loss: 0.1339011269475753\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "model = Model(hidden_size=study.best_params['hidden_size'], activation=getattr(nn, study.best_params['activation'])()).to(device)\n",
    "optimizer = getattr(torch.optim, study.best_params['optimizer'])(model.parameters(), lr=study.best_params['lr'])\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train_losses, test_losses, train_f1_scores, test_f1_scores = train(loss, optimizer, model, train_dataloader, test_dataloader, epochs=epochs, save_best=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_losses, label='train')\n",
    "plt.plot(range(epochs), test_losses, label='test')\n",
    "plt.legend()\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_f1_scores, label='train')\n",
    "plt.plot(range(epochs), test_f1_scores, label='test')\n",
    "plt.legend()\n",
    "plt.title('F1 Score Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model achieved at epoch 94 with F1 score 0.707740916271722\n"
     ]
    }
   ],
   "source": [
    "print(f'Best model achieved at epoch {np.argmax(test_f1_scores)} with F1 score {np.max(test_f1_scores)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = BaselineDataset()\n",
    "test_set = BaselineDataset(path=TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(torch.vstack(train_set.data).numpy(), label=train_set.target)\n",
    "dtest = xgb.DMatrix(torch.vstack(test_set.data).numpy(), label=test_set.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 12:37:08,014]\u001b[0m A new study created in memory with name: no-name-6991b5c1-a06c-4294-8ffa-ec66497484f8\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:08,797]\u001b[0m Trial 0 finished with value: 0.672978 and parameters: {'max_depth': 6, 'eta': 0.019398710310971956, 'gamma': 0.0278367935408146, 'alpha': 0.06437350628872666, 'lambda': 0.04640652003940772, 'subsample': 0.6098177641574065, 'sampling_method': 'uniform'}. Best is trial 0 with value: 0.672978.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:09,310]\u001b[0m Trial 1 finished with value: 0.659686 and parameters: {'max_depth': 3, 'eta': 0.02734503742396819, 'gamma': 0.00329052174322656, 'alpha': 0.09260136046301892, 'lambda': 0.04890020437861617, 'subsample': 0.6942280156792708, 'sampling_method': 'gradient_based'}. Best is trial 0 with value: 0.672978.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:09,900]\u001b[0m Trial 2 finished with value: 0.71346 and parameters: {'max_depth': 5, 'eta': 0.08302025409399177, 'gamma': 0.07458985062194029, 'alpha': 0.06450998980283751, 'lambda': 0.07141379523561849, 'subsample': 0.623894638020468, 'sampling_method': 'uniform'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:10,615]\u001b[0m Trial 3 finished with value: 0.692953 and parameters: {'max_depth': 7, 'eta': 0.03667955049747989, 'gamma': 0.013762335939168514, 'alpha': 0.0333978379153678, 'lambda': 0.03782125960495111, 'subsample': 0.6549697119102965, 'sampling_method': 'gradient_based'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:11,505]\u001b[0m Trial 4 finished with value: 0.705298 and parameters: {'max_depth': 10, 'eta': 0.09095706453013386, 'gamma': 0.07203514537196061, 'alpha': 0.030516989027225706, 'lambda': 0.053971787394282225, 'subsample': 0.8304667910549091, 'sampling_method': 'uniform'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:12,014]\u001b[0m Trial 5 finished with value: 0.687606 and parameters: {'max_depth': 3, 'eta': 0.0685310578442154, 'gamma': 0.05934206928801159, 'alpha': 0.09777287168115849, 'lambda': 0.06129472408380026, 'subsample': 0.987807305646985, 'sampling_method': 'uniform'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:12,821]\u001b[0m Trial 6 finished with value: 0.665517 and parameters: {'max_depth': 9, 'eta': 0.0066284545745434525, 'gamma': 0.005554645819794324, 'alpha': 0.02198199126519096, 'lambda': 0.020064224040274505, 'subsample': 0.521523102871819, 'sampling_method': 'uniform'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:13,366]\u001b[0m Trial 7 finished with value: 0.687822 and parameters: {'max_depth': 4, 'eta': 0.039333955650408176, 'gamma': 0.05077101406236176, 'alpha': 0.06220726253457973, 'lambda': 0.05983230503561513, 'subsample': 0.9238208662509473, 'sampling_method': 'gradient_based'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:14,077]\u001b[0m Trial 8 finished with value: 0.663778 and parameters: {'max_depth': 8, 'eta': 0.006877740578715164, 'gamma': 0.09535418540746746, 'alpha': 0.05716659062989254, 'lambda': 0.0797530833804983, 'subsample': 0.7549422841689267, 'sampling_method': 'gradient_based'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:14,591]\u001b[0m Trial 9 finished with value: 0.661445 and parameters: {'max_depth': 3, 'eta': 0.03260242320131962, 'gamma': 0.038085234116091965, 'alpha': 0.06491452956862599, 'lambda': 0.028790796243156072, 'subsample': 0.9103475118216462, 'sampling_method': 'uniform'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:15,199]\u001b[0m Trial 10 finished with value: 0.707256 and parameters: {'max_depth': 5, 'eta': 0.06577080978975815, 'gamma': 0.0796633211923864, 'alpha': 0.003744097724099074, 'lambda': 0.09769506976046916, 'subsample': 0.5009300480721894, 'sampling_method': 'uniform'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:15,798]\u001b[0m Trial 11 finished with value: 0.702341 and parameters: {'max_depth': 5, 'eta': 0.065377130191858, 'gamma': 0.08199740955356394, 'alpha': 0.0006458617285201931, 'lambda': 0.0943183762755427, 'subsample': 0.508654958219781, 'sampling_method': 'uniform'}. Best is trial 2 with value: 0.71346.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:16,392]\u001b[0m Trial 12 finished with value: 0.719472 and parameters: {'max_depth': 5, 'eta': 0.0979869878565909, 'gamma': 0.06855496594286332, 'alpha': 0.04339970574061897, 'lambda': 0.09806582073677783, 'subsample': 0.5936227561996894, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:17,054]\u001b[0m Trial 13 finished with value: 0.707921 and parameters: {'max_depth': 6, 'eta': 0.09958506103472509, 'gamma': 0.0639032176108052, 'alpha': 0.044245837401587704, 'lambda': 0.08032926155682278, 'subsample': 0.6099196047699422, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:17,664]\u001b[0m Trial 14 finished with value: 0.71464 and parameters: {'max_depth': 5, 'eta': 0.08583296672571332, 'gamma': 0.09399387561861056, 'alpha': 0.08031366316077407, 'lambda': 0.00271423864416228, 'subsample': 0.5823344794462069, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:18,383]\u001b[0m Trial 15 finished with value: 0.712059 and parameters: {'max_depth': 7, 'eta': 0.09901153451750097, 'gamma': 0.0975615940293189, 'alpha': 0.08063857705198568, 'lambda': 0.0003656833469489807, 'subsample': 0.5575775129253996, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:18,952]\u001b[0m Trial 16 finished with value: 0.708054 and parameters: {'max_depth': 4, 'eta': 0.0807821780999572, 'gamma': 0.08709744874494071, 'alpha': 0.07888521152399952, 'lambda': 0.0034255466589666744, 'subsample': 0.569326894918462, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:19,519]\u001b[0m Trial 17 finished with value: 0.698816 and parameters: {'max_depth': 4, 'eta': 0.0546799512443035, 'gamma': 0.09877952277684672, 'alpha': 0.05003459984738187, 'lambda': 0.015538088263736675, 'subsample': 0.6856581939580998, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:20,184]\u001b[0m Trial 18 finished with value: 0.711948 and parameters: {'max_depth': 6, 'eta': 0.08129607692954174, 'gamma': 0.08659557967368585, 'alpha': 0.07539679995412349, 'lambda': 0.038552301168403844, 'subsample': 0.7234312207034148, 'sampling_method': 'gradient_based'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:20,961]\u001b[0m Trial 19 finished with value: 0.707054 and parameters: {'max_depth': 8, 'eta': 0.09161601089936816, 'gamma': 0.06658319395087056, 'alpha': 0.09023792138558318, 'lambda': 0.011245535281661403, 'subsample': 0.5772544776131814, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:21,594]\u001b[0m Trial 20 finished with value: 0.706078 and parameters: {'max_depth': 5, 'eta': 0.07523594417851079, 'gamma': 0.07315976193568964, 'alpha': 0.04540773575917715, 'lambda': 0.024712351115366904, 'subsample': 0.6627527220401445, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:22,184]\u001b[0m Trial 21 finished with value: 0.717481 and parameters: {'max_depth': 5, 'eta': 0.0851153307332589, 'gamma': 0.0753925852103341, 'alpha': 0.07115848907797798, 'lambda': 0.07093082596864941, 'subsample': 0.6286675045596624, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:22,760]\u001b[0m Trial 22 finished with value: 0.708924 and parameters: {'max_depth': 4, 'eta': 0.09026624681324874, 'gamma': 0.08772353276170797, 'alpha': 0.070961632383589, 'lambda': 0.08822270326829286, 'subsample': 0.6326517131036372, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:23,368]\u001b[0m Trial 23 finished with value: 0.709091 and parameters: {'max_depth': 5, 'eta': 0.09946348151437048, 'gamma': 0.056392393762395146, 'alpha': 0.08227410799555519, 'lambda': 0.07161509087001051, 'subsample': 0.5618469367177995, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:24,108]\u001b[0m Trial 24 finished with value: 0.705394 and parameters: {'max_depth': 6, 'eta': 0.055148624840847996, 'gamma': 0.06644894472374592, 'alpha': 0.07311531612470284, 'lambda': 0.08923847338487625, 'subsample': 0.5966892481894057, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:24,930]\u001b[0m Trial 25 finished with value: 0.708023 and parameters: {'max_depth': 7, 'eta': 0.07336068558482804, 'gamma': 0.08043414420811044, 'alpha': 0.08647386784437525, 'lambda': 0.09672212628366222, 'subsample': 0.5456544037436681, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:25,538]\u001b[0m Trial 26 finished with value: 0.707358 and parameters: {'max_depth': 4, 'eta': 0.08755537974148181, 'gamma': 0.0897048594115195, 'alpha': 0.056004376904491136, 'lambda': 0.06307965696223114, 'subsample': 0.6347282704434399, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:26,174]\u001b[0m Trial 27 finished with value: 0.712625 and parameters: {'max_depth': 5, 'eta': 0.0769370658675035, 'gamma': 0.07400541442910373, 'alpha': 0.07273306405694277, 'lambda': 0.09949858020590668, 'subsample': 0.5378218173535151, 'sampling_method': 'gradient_based'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:26,892]\u001b[0m Trial 28 finished with value: 0.716735 and parameters: {'max_depth': 6, 'eta': 0.08585450140604885, 'gamma': 0.050237275857905134, 'alpha': 0.09926158182510496, 'lambda': 0.03159988558017488, 'subsample': 0.5915508810467247, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:27,606]\u001b[0m Trial 29 finished with value: 0.715686 and parameters: {'max_depth': 6, 'eta': 0.09456558143349214, 'gamma': 0.04232157941778196, 'alpha': 0.09423268006992676, 'lambda': 0.03712856525406752, 'subsample': 0.6022465647949438, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:28,329]\u001b[0m Trial 30 finished with value: 0.717907 and parameters: {'max_depth': 6, 'eta': 0.08552456817515772, 'gamma': 0.05296820528088893, 'alpha': 0.09740126387562104, 'lambda': 0.044166704660213794, 'subsample': 0.661562323935473, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:29,036]\u001b[0m Trial 31 finished with value: 0.708986 and parameters: {'max_depth': 6, 'eta': 0.08416067643424516, 'gamma': 0.053447339175931266, 'alpha': 0.09825546428431713, 'lambda': 0.042245074343944075, 'subsample': 0.6458350978826704, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:29,809]\u001b[0m Trial 32 finished with value: 0.718033 and parameters: {'max_depth': 7, 'eta': 0.09351045164844285, 'gamma': 0.04520955228858793, 'alpha': 0.09998655251643221, 'lambda': 0.04828818104527001, 'subsample': 0.6850552225784006, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:30,649]\u001b[0m Trial 33 finished with value: 0.709942 and parameters: {'max_depth': 8, 'eta': 0.09516922076140676, 'gamma': 0.06009099989349248, 'alpha': 0.0905452217359191, 'lambda': 0.048186279475534194, 'subsample': 0.689735793476052, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:31,396]\u001b[0m Trial 34 finished with value: 0.708986 and parameters: {'max_depth': 7, 'eta': 0.09191799649898298, 'gamma': 0.04501417385050668, 'alpha': 0.08710068264225376, 'lambda': 0.052651160785863446, 'subsample': 0.7154076590979627, 'sampling_method': 'gradient_based'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:32,138]\u001b[0m Trial 35 finished with value: 0.708402 and parameters: {'max_depth': 7, 'eta': 0.08028776847756351, 'gamma': 0.032433577871943814, 'alpha': 0.09156396119987, 'lambda': 0.04596508828810309, 'subsample': 0.6718313973724446, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:32,978]\u001b[0m Trial 36 finished with value: 0.706468 and parameters: {'max_depth': 9, 'eta': 0.09442838366080843, 'gamma': 0.056059786930771606, 'alpha': 0.09881179150442684, 'lambda': 0.053696448313872186, 'subsample': 0.624910877863062, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:33,690]\u001b[0m Trial 37 finished with value: 0.708882 and parameters: {'max_depth': 7, 'eta': 0.08732227217136312, 'gamma': 0.04491356980218724, 'alpha': 0.08630510681773304, 'lambda': 0.06988354352959503, 'subsample': 0.6414201784607568, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:34,537]\u001b[0m Trial 38 finished with value: 0.703642 and parameters: {'max_depth': 8, 'eta': 0.07173652274350549, 'gamma': 0.0691317086688168, 'alpha': 0.09257075411150138, 'lambda': 0.058323937607562104, 'subsample': 0.6632109942777789, 'sampling_method': 'gradient_based'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:35,259]\u001b[0m Trial 39 finished with value: 0.714286 and parameters: {'max_depth': 6, 'eta': 0.07799349824286347, 'gamma': 0.061685314137802524, 'alpha': 0.06913314127726113, 'lambda': 0.0475228049153916, 'subsample': 0.7071059212337075, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:36,115]\u001b[0m Trial 40 finished with value: 0.70462 and parameters: {'max_depth': 9, 'eta': 0.08964817713010075, 'gamma': 0.02567086884519821, 'alpha': 0.08473953162276353, 'lambda': 0.06597073691532306, 'subsample': 0.7528429341533086, 'sampling_method': 'uniform'}. Best is trial 12 with value: 0.719472.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:36,768]\u001b[0m Trial 41 finished with value: 0.720588 and parameters: {'max_depth': 6, 'eta': 0.08342851842224507, 'gamma': 0.047523847714503915, 'alpha': 0.09903834456886614, 'lambda': 0.03250384788986177, 'subsample': 0.6128586192887734, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:37,376]\u001b[0m Trial 42 finished with value: 0.705394 and parameters: {'max_depth': 5, 'eta': 0.0831266104050504, 'gamma': 0.04909771739823525, 'alpha': 0.09526781845531754, 'lambda': 0.05785007916866025, 'subsample': 0.61298093956239, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:38,024]\u001b[0m Trial 43 finished with value: 0.720588 and parameters: {'max_depth': 6, 'eta': 0.0954751513323222, 'gamma': 0.058752150622844515, 'alpha': 0.09427698129786995, 'lambda': 0.0518117523524804, 'subsample': 0.6630847350034406, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:38,741]\u001b[0m Trial 44 finished with value: 0.713115 and parameters: {'max_depth': 7, 'eta': 0.09547127285324683, 'gamma': 0.05673901552371764, 'alpha': 0.0953753952814414, 'lambda': 0.042962560716968905, 'subsample': 0.6758312077395867, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:39,391]\u001b[0m Trial 45 finished with value: 0.718241 and parameters: {'max_depth': 6, 'eta': 0.09734821481680735, 'gamma': 0.06182458812380499, 'alpha': 0.09457868749815011, 'lambda': 0.0526759590035194, 'subsample': 0.660957653004137, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:40,041]\u001b[0m Trial 46 finished with value: 0.712531 and parameters: {'max_depth': 6, 'eta': 0.09973825832836085, 'gamma': 0.06280204657958383, 'alpha': 0.089794866910284, 'lambda': 0.05243147978929062, 'subsample': 0.7289565997350194, 'sampling_method': 'gradient_based'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:40,752]\u001b[0m Trial 47 finished with value: 0.716271 and parameters: {'max_depth': 7, 'eta': 0.09445271265579133, 'gamma': 0.06005829006187488, 'alpha': 0.09479699731214646, 'lambda': 0.03267818669138471, 'subsample': 0.6924137507391711, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:41,416]\u001b[0m Trial 48 finished with value: 0.715807 and parameters: {'max_depth': 6, 'eta': 0.09243685706900884, 'gamma': 0.06860310828548953, 'alpha': 0.07860099401027414, 'lambda': 0.055603386636219644, 'subsample': 0.6151660938911309, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:42,198]\u001b[0m Trial 49 finished with value: 0.706173 and parameters: {'max_depth': 8, 'eta': 0.08935313432052852, 'gamma': 0.06377214031474264, 'alpha': 0.08387685114508432, 'lambda': 0.038778879386049736, 'subsample': 0.7737815321027016, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:42,739]\u001b[0m Trial 50 finished with value: 0.701843 and parameters: {'max_depth': 3, 'eta': 0.09989020008128088, 'gamma': 0.04773971711297127, 'alpha': 0.09920020260721889, 'lambda': 0.05052371148268026, 'subsample': 0.6511187921394811, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:43,400]\u001b[0m Trial 51 finished with value: 0.716735 and parameters: {'max_depth': 6, 'eta': 0.08822026272858302, 'gamma': 0.05275170967664461, 'alpha': 0.0993134322929915, 'lambda': 0.04298064143354813, 'subsample': 0.6616779091307786, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:44,019]\u001b[0m Trial 52 finished with value: 0.712284 and parameters: {'max_depth': 5, 'eta': 0.09595135140557298, 'gamma': 0.04026815288806865, 'alpha': 0.08831632755443783, 'lambda': 0.06252864180405208, 'subsample': 0.5871154372173654, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:44,686]\u001b[0m Trial 53 finished with value: 0.708299 and parameters: {'max_depth': 6, 'eta': 0.08210529529787763, 'gamma': 0.05367783264352776, 'alpha': 0.09356668236835648, 'lambda': 0.05004705548598048, 'subsample': 0.6794246396085767, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:45,403]\u001b[0m Trial 54 finished with value: 0.712059 and parameters: {'max_depth': 7, 'eta': 0.0900297133890245, 'gamma': 0.058326162713819914, 'alpha': 0.0954168965291054, 'lambda': 0.027705451284424896, 'subsample': 0.6492120188747659, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:46,015]\u001b[0m Trial 55 finished with value: 0.71723 and parameters: {'max_depth': 5, 'eta': 0.0962420575808664, 'gamma': 0.04737509775507963, 'alpha': 0.09007862801551059, 'lambda': 0.03576377311643976, 'subsample': 0.7030924451140341, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:46,682]\u001b[0m Trial 56 finished with value: 0.715807 and parameters: {'max_depth': 6, 'eta': 0.0853199361528387, 'gamma': 0.051239750028808616, 'alpha': 0.08379131814883137, 'lambda': 0.05676222821469732, 'subsample': 0.605734592147886, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:47,319]\u001b[0m Trial 57 finished with value: 0.709091 and parameters: {'max_depth': 5, 'eta': 0.07884138026932527, 'gamma': 0.03781760767265524, 'alpha': 0.09620324594751513, 'lambda': 0.023941989899062478, 'subsample': 0.6216091932735947, 'sampling_method': 'gradient_based'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:48,325]\u001b[0m Trial 58 finished with value: 0.713001 and parameters: {'max_depth': 10, 'eta': 0.09214260408895578, 'gamma': 0.06551226244196946, 'alpha': 0.0998139184788594, 'lambda': 0.07730176255700419, 'subsample': 0.5814638909916334, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:48,912]\u001b[0m Trial 59 finished with value: 0.710109 and parameters: {'max_depth': 4, 'eta': 0.0981762721819843, 'gamma': 0.07095693653549624, 'alpha': 0.09187006275488079, 'lambda': 0.04497818078517738, 'subsample': 0.6610401761434628, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:49,641]\u001b[0m Trial 60 finished with value: 0.712171 and parameters: {'max_depth': 7, 'eta': 0.0824998399555437, 'gamma': 0.0566703406614101, 'alpha': 0.076998255328039, 'lambda': 0.059799091699110365, 'subsample': 0.6366891823561367, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:50,303]\u001b[0m Trial 61 finished with value: 0.710963 and parameters: {'max_depth': 5, 'eta': 0.08622572951026809, 'gamma': 0.07381764343785528, 'alpha': 0.08219563998881806, 'lambda': 0.04860600707803847, 'subsample': 0.6307902845474144, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:50,993]\u001b[0m Trial 62 finished with value: 0.716639 and parameters: {'max_depth': 6, 'eta': 0.09263437341911981, 'gamma': 0.07643034790193355, 'alpha': 0.08894227138552689, 'lambda': 0.05505537688153553, 'subsample': 0.6066284638065458, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:51,649]\u001b[0m Trial 63 finished with value: 0.712739 and parameters: {'max_depth': 5, 'eta': 0.07594230253889737, 'gamma': 0.07765218232399322, 'alpha': 0.08022724996607332, 'lambda': 0.0849858734012398, 'subsample': 0.5651658642790205, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:52,283]\u001b[0m Trial 64 finished with value: 0.710526 and parameters: {'max_depth': 5, 'eta': 0.08888798569345645, 'gamma': 0.06870799467597957, 'alpha': 0.09632981655398187, 'lambda': 0.09292095809246086, 'subsample': 0.6773370426078568, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:52,968]\u001b[0m Trial 65 finished with value: 0.713706 and parameters: {'max_depth': 6, 'eta': 0.09687087832665363, 'gamma': 0.06093482904136839, 'alpha': 0.08590373449639552, 'lambda': 0.040263982439487776, 'subsample': 0.6514088101322945, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:53,556]\u001b[0m Trial 66 finished with value: 0.706276 and parameters: {'max_depth': 4, 'eta': 0.08433718171479743, 'gamma': 0.06350803775541011, 'alpha': 0.0925596535507954, 'lambda': 0.04466074313226268, 'subsample': 0.6261995526556061, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:54,280]\u001b[0m Trial 67 finished with value: 0.717695 and parameters: {'max_depth': 6, 'eta': 0.07017250011023204, 'gamma': 0.054641604306719646, 'alpha': 0.0881415434562674, 'lambda': 0.0408473665689302, 'subsample': 0.5934217589410444, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:55,021]\u001b[0m Trial 68 finished with value: 0.705688 and parameters: {'max_depth': 7, 'eta': 0.06750365719706712, 'gamma': 0.05385100432302573, 'alpha': 0.0881596127836133, 'lambda': 0.03376435101226334, 'subsample': 0.5958626350659905, 'sampling_method': 'uniform'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:55,704]\u001b[0m Trial 69 finished with value: 0.718494 and parameters: {'max_depth': 6, 'eta': 0.09224599608031105, 'gamma': 0.049997037524408844, 'alpha': 0.09749858450995512, 'lambda': 0.039910231392048, 'subsample': 0.5764796425316302, 'sampling_method': 'gradient_based'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:56,394]\u001b[0m Trial 70 finished with value: 0.719083 and parameters: {'max_depth': 6, 'eta': 0.09765798080372665, 'gamma': 0.051278419982984234, 'alpha': 0.09740048518215254, 'lambda': 0.037970292943640765, 'subsample': 0.5426790206643539, 'sampling_method': 'gradient_based'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:57,075]\u001b[0m Trial 71 finished with value: 0.715807 and parameters: {'max_depth': 6, 'eta': 0.09693837898786958, 'gamma': 0.05109468853569139, 'alpha': 0.09646442443672566, 'lambda': 0.03630950901965663, 'subsample': 0.549616417586723, 'sampling_method': 'gradient_based'}. Best is trial 41 with value: 0.720588.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:57,770]\u001b[0m Trial 72 finished with value: 0.722359 and parameters: {'max_depth': 6, 'eta': 0.0926822554290707, 'gamma': 0.05830643334114811, 'alpha': 0.09990643040310486, 'lambda': 0.03927107985332941, 'subsample': 0.5725550975367891, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:58,520]\u001b[0m Trial 73 finished with value: 0.715102 and parameters: {'max_depth': 7, 'eta': 0.09263074319293543, 'gamma': 0.04392205001691498, 'alpha': 0.09302243641677813, 'lambda': 0.028969276915744073, 'subsample': 0.5309388825794814, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:59,207]\u001b[0m Trial 74 finished with value: 0.716393 and parameters: {'max_depth': 6, 'eta': 0.09753881155627372, 'gamma': 0.05972655744382062, 'alpha': 0.09918246841220059, 'lambda': 0.03925471745179904, 'subsample': 0.5695010710321531, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:37:59,936]\u001b[0m Trial 75 finished with value: 0.715686 and parameters: {'max_depth': 7, 'eta': 0.093566789426442, 'gamma': 0.047257256357573614, 'alpha': 0.09263538155602968, 'lambda': 0.033831571077265414, 'subsample': 0.519687248983916, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:00,616]\u001b[0m Trial 76 finished with value: 0.713936 and parameters: {'max_depth': 6, 'eta': 0.09957086247768385, 'gamma': 0.05055379357319149, 'alpha': 0.09647503831138725, 'lambda': 0.047243336125589425, 'subsample': 0.553121272350082, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:01,256]\u001b[0m Trial 77 finished with value: 0.706369 and parameters: {'max_depth': 5, 'eta': 0.09086782131760598, 'gamma': 0.05880336960482699, 'alpha': 0.09156343837425915, 'lambda': 0.04093609016115057, 'subsample': 0.5759955665455139, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:01,919]\u001b[0m Trial 78 finished with value: 0.714873 and parameters: {'max_depth': 6, 'eta': 0.08772035788223398, 'gamma': 0.05675757243718372, 'alpha': 0.09431688598173318, 'lambda': 0.036823455801173625, 'subsample': 0.5577433690564766, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:02,655]\u001b[0m Trial 79 finished with value: 0.716049 and parameters: {'max_depth': 7, 'eta': 0.09470775056780463, 'gamma': 0.0644333674541952, 'alpha': 0.09946970529336281, 'lambda': 0.03064238058699536, 'subsample': 0.5388630005629739, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:03,327]\u001b[0m Trial 80 finished with value: 0.716858 and parameters: {'max_depth': 6, 'eta': 0.09066704034719539, 'gamma': 0.04901339482397096, 'alpha': 0.09693089359438507, 'lambda': 0.05167115815520226, 'subsample': 0.5039468005008255, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:04,011]\u001b[0m Trial 81 finished with value: 0.719083 and parameters: {'max_depth': 6, 'eta': 0.09563084493972712, 'gamma': 0.052364891209388066, 'alpha': 0.09724373840621259, 'lambda': 0.043486767954276036, 'subsample': 0.5834327643847453, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:04,683]\u001b[0m Trial 82 finished with value: 0.716858 and parameters: {'max_depth': 6, 'eta': 0.09684519859399582, 'gamma': 0.05581209658500519, 'alpha': 0.09018797134249826, 'lambda': 0.04537739557044653, 'subsample': 0.5854473500971022, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:05,349]\u001b[0m Trial 83 finished with value: 0.720588 and parameters: {'max_depth': 6, 'eta': 0.0998446340606063, 'gamma': 0.060797729524799664, 'alpha': 0.09403379634326074, 'lambda': 0.04204814997487894, 'subsample': 0.5708015069964303, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:06,012]\u001b[0m Trial 84 finished with value: 0.711948 and parameters: {'max_depth': 6, 'eta': 0.09987797432007035, 'gamma': 0.061976348919373425, 'alpha': 0.08655767869034697, 'lambda': 0.04157241015321509, 'subsample': 0.5722579951676958, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:06,644]\u001b[0m Trial 85 finished with value: 0.71464 and parameters: {'max_depth': 5, 'eta': 0.0974387001754804, 'gamma': 0.0671345999517441, 'alpha': 0.09421265841302941, 'lambda': 0.034733830406041145, 'subsample': 0.5437030335671246, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:07,301]\u001b[0m Trial 86 finished with value: 0.719342 and parameters: {'max_depth': 6, 'eta': 0.09426355220952308, 'gamma': 0.052302169035599345, 'alpha': 0.09675394053637412, 'lambda': 0.03884884501358225, 'subsample': 0.6010791400979235, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:07,957]\u001b[0m Trial 87 finished with value: 0.721044 and parameters: {'max_depth': 6, 'eta': 0.09322396954938136, 'gamma': 0.051733518830669865, 'alpha': 0.09691650989218455, 'lambda': 0.03842122686143527, 'subsample': 0.599878124843862, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:08,644]\u001b[0m Trial 88 finished with value: 0.716858 and parameters: {'max_depth': 6, 'eta': 0.09471116293403985, 'gamma': 0.057968966210556146, 'alpha': 0.09077614949629345, 'lambda': 0.03714109907255731, 'subsample': 0.6028158557713216, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:09,289]\u001b[0m Trial 89 finished with value: 0.710635 and parameters: {'max_depth': 5, 'eta': 0.08870971551550293, 'gamma': 0.05416859350547644, 'alpha': 0.040836669691573374, 'lambda': 0.03184937946168026, 'subsample': 0.5589564535218895, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:09,997]\u001b[0m Trial 90 finished with value: 0.714754 and parameters: {'max_depth': 6, 'eta': 0.09040144240450447, 'gamma': 0.05293982197231509, 'alpha': 0.09761225308554146, 'lambda': 0.043042339133237975, 'subsample': 0.588941277444548, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:10,710]\u001b[0m Trial 91 finished with value: 0.716271 and parameters: {'max_depth': 6, 'eta': 0.09299942620778004, 'gamma': 0.051035397372012514, 'alpha': 0.09688221725691307, 'lambda': 0.03832735339359937, 'subsample': 0.6148497842025359, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:11,424]\u001b[0m Trial 92 finished with value: 0.711475 and parameters: {'max_depth': 6, 'eta': 0.08676169501630543, 'gamma': 0.04679009139983815, 'alpha': 0.09371734696890749, 'lambda': 0.039048113282043155, 'subsample': 0.5756196503564102, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:12,144]\u001b[0m Trial 93 finished with value: 0.715566 and parameters: {'max_depth': 6, 'eta': 0.09490549455505148, 'gamma': 0.04947643484292584, 'alpha': 0.09721359184652607, 'lambda': 0.03484963857822486, 'subsample': 0.5666584985153542, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:12,876]\u001b[0m Trial 94 finished with value: 0.716612 and parameters: {'max_depth': 6, 'eta': 0.09123378465613889, 'gamma': 0.05843534107033542, 'alpha': 0.09984883483059769, 'lambda': 0.04256426445283639, 'subsample': 0.5819911103227489, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:13,537]\u001b[0m Trial 95 finished with value: 0.715702 and parameters: {'max_depth': 5, 'eta': 0.09702538876852938, 'gamma': 0.052089896663344945, 'alpha': 0.09110246197985578, 'lambda': 0.0466017971819494, 'subsample': 0.6049210978208927, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:14,270]\u001b[0m Trial 96 finished with value: 0.713584 and parameters: {'max_depth': 6, 'eta': 0.09963320843111342, 'gamma': 0.0549230413354806, 'alpha': 0.09446085104600876, 'lambda': 0.03733474146766509, 'subsample': 0.5309182022401376, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:15,101]\u001b[0m Trial 97 finished with value: 0.711111 and parameters: {'max_depth': 7, 'eta': 0.0937110057688822, 'gamma': 0.043097075967032196, 'alpha': 0.08743083220618085, 'lambda': 0.05016917206865161, 'subsample': 0.6171032420756482, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:15,840]\u001b[0m Trial 98 finished with value: 0.713115 and parameters: {'max_depth': 6, 'eta': 0.08393651996778398, 'gamma': 0.04670621489051029, 'alpha': 0.08931171384390091, 'lambda': 0.03290226976646406, 'subsample': 0.5966554610715891, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:16,570]\u001b[0m Trial 99 finished with value: 0.716735 and parameters: {'max_depth': 6, 'eta': 0.08945032281156723, 'gamma': 0.060638216337278075, 'alpha': 0.0845572961565251, 'lambda': 0.03991632985704412, 'subsample': 0.5544293787261542, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:17,234]\u001b[0m Trial 100 finished with value: 0.711443 and parameters: {'max_depth': 5, 'eta': 0.09546305710443147, 'gamma': 0.05596620688591085, 'alpha': 0.09748845675798068, 'lambda': 0.04404178981281354, 'subsample': 0.6385601678845069, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:17,946]\u001b[0m Trial 101 finished with value: 0.71732 and parameters: {'max_depth': 6, 'eta': 0.0974826387104766, 'gamma': 0.06249043312625525, 'alpha': 0.09484023304967253, 'lambda': 0.05451138835582814, 'subsample': 0.5886108985607155, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:18,670]\u001b[0m Trial 102 finished with value: 0.720721 and parameters: {'max_depth': 6, 'eta': 0.0923024284092508, 'gamma': 0.06550178545839087, 'alpha': 0.09331171244119617, 'lambda': 0.045881764261900555, 'subsample': 0.6192266579286327, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:19,400]\u001b[0m Trial 103 finished with value: 0.714286 and parameters: {'max_depth': 6, 'eta': 0.09205964918449676, 'gamma': 0.06532490900378825, 'alpha': 0.09251728060996767, 'lambda': 0.04721986402856279, 'subsample': 0.6197657547711677, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:20,194]\u001b[0m Trial 104 finished with value: 0.714286 and parameters: {'max_depth': 7, 'eta': 0.08701530644308034, 'gamma': 0.04877466187564644, 'alpha': 0.0981670603849245, 'lambda': 0.035479012731799126, 'subsample': 0.5987527054432199, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:20,914]\u001b[0m Trial 105 finished with value: 0.712531 and parameters: {'max_depth': 6, 'eta': 0.08070235750158715, 'gamma': 0.05815588012906417, 'alpha': 0.09999998374106428, 'lambda': 0.040837592821448554, 'subsample': 0.5644383038437638, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:21,566]\u001b[0m Trial 106 finished with value: 0.711808 and parameters: {'max_depth': 5, 'eta': 0.09349670751191481, 'gamma': 0.0711113261132633, 'alpha': 0.0955785749518512, 'lambda': 0.044969103376871704, 'subsample': 0.5732758026989517, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:22,280]\u001b[0m Trial 107 finished with value: 0.714754 and parameters: {'max_depth': 6, 'eta': 0.09805560310374455, 'gamma': 0.051277608089067624, 'alpha': 0.09196065876502381, 'lambda': 0.04903311538225867, 'subsample': 0.6082970369866931, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:22,945]\u001b[0m Trial 108 finished with value: 0.713101 and parameters: {'max_depth': 5, 'eta': 0.08812582409066133, 'gamma': 0.06736034900261373, 'alpha': 0.09583063531617134, 'lambda': 0.029991543165839313, 'subsample': 0.6273373296934422, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:23,757]\u001b[0m Trial 109 finished with value: 0.721903 and parameters: {'max_depth': 7, 'eta': 0.09529492337276885, 'gamma': 0.060383133449212895, 'alpha': 0.08930139919416265, 'lambda': 0.03846254743832035, 'subsample': 0.5804840575133454, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:24,571]\u001b[0m Trial 110 finished with value: 0.707718 and parameters: {'max_depth': 7, 'eta': 0.09814622539764016, 'gamma': 0.06491040455145977, 'alpha': 0.08562372623396117, 'lambda': 0.026797460740351026, 'subsample': 0.549937381778751, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:25,377]\u001b[0m Trial 111 finished with value: 0.712059 and parameters: {'max_depth': 7, 'eta': 0.09550870358958315, 'gamma': 0.06003477203262842, 'alpha': 0.0980901689386011, 'lambda': 0.038680842722452084, 'subsample': 0.5833919749368486, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:26,130]\u001b[0m Trial 112 finished with value: 0.717781 and parameters: {'max_depth': 6, 'eta': 0.09068518917835405, 'gamma': 0.05435735287027902, 'alpha': 0.08972471775500207, 'lambda': 0.042273139618510605, 'subsample': 0.5929023318890925, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:27,011]\u001b[0m Trial 113 finished with value: 0.707921 and parameters: {'max_depth': 8, 'eta': 0.09534664720501561, 'gamma': 0.05709953562730398, 'alpha': 0.09231206538023669, 'lambda': 0.03318819929776948, 'subsample': 0.5773428634328545, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:27,733]\u001b[0m Trial 114 finished with value: 0.708986 and parameters: {'max_depth': 6, 'eta': 0.09242352241776866, 'gamma': 0.06284476165549609, 'alpha': 0.09813114478451818, 'lambda': 0.03598355298896579, 'subsample': 0.6100027180344381, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:28,448]\u001b[0m Trial 115 finished with value: 0.711948 and parameters: {'max_depth': 6, 'eta': 0.0999861156729357, 'gamma': 0.05250075983442439, 'alpha': 0.09399163579474339, 'lambda': 0.031018915120475585, 'subsample': 0.5604371612820623, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:29,220]\u001b[0m Trial 116 finished with value: 0.702791 and parameters: {'max_depth': 7, 'eta': 0.08888051151922596, 'gamma': 0.059508000525956596, 'alpha': 0.08787215742395714, 'lambda': 0.0459822250857691, 'subsample': 0.6432711011362903, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:29,921]\u001b[0m Trial 117 finished with value: 0.713816 and parameters: {'max_depth': 6, 'eta': 0.08464593337277665, 'gamma': 0.049664203633536484, 'alpha': 0.0959544898707913, 'lambda': 0.04015015826899923, 'subsample': 0.6000233700004646, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:30,644]\u001b[0m Trial 118 finished with value: 0.720528 and parameters: {'max_depth': 6, 'eta': 0.09354376595119339, 'gamma': 0.06948250458157287, 'alpha': 0.0825994180304915, 'lambda': 0.04347535383548861, 'subsample': 0.6201552320486069, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:31,636]\u001b[0m Trial 119 finished with value: 0.711002 and parameters: {'max_depth': 7, 'eta': 0.09589326137555199, 'gamma': 0.06949270533959839, 'alpha': 0.08317064966098359, 'lambda': 0.04322082824400589, 'subsample': 0.6233363460235091, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:32,435]\u001b[0m Trial 120 finished with value: 0.697402 and parameters: {'max_depth': 3, 'eta': 0.09410230252998483, 'gamma': 0.07282762589030496, 'alpha': 0.09039302259746859, 'lambda': 0.050641126737752035, 'subsample': 0.6340604530154796, 'sampling_method': 'gradient_based'}. Best is trial 72 with value: 0.722359.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:33,400]\u001b[0m Trial 121 finished with value: 0.724166 and parameters: {'max_depth': 6, 'eta': 0.09081514003358984, 'gamma': 0.06642929982914873, 'alpha': 0.0940319005665157, 'lambda': 0.03697634500529317, 'subsample': 0.6137676048529289, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:34,372]\u001b[0m Trial 122 finished with value: 0.714286 and parameters: {'max_depth': 6, 'eta': 0.09095106176768603, 'gamma': 0.0658402225365909, 'alpha': 0.0937125435398964, 'lambda': 0.03745698555478097, 'subsample': 0.6130777455670017, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:35,351]\u001b[0m Trial 123 finished with value: 0.711256 and parameters: {'max_depth': 6, 'eta': 0.09775245237212939, 'gamma': 0.07027609571635147, 'alpha': 0.08846477776822653, 'lambda': 0.04212487617466994, 'subsample': 0.5877216124479643, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:36,340]\u001b[0m Trial 124 finished with value: 0.716271 and parameters: {'max_depth': 6, 'eta': 0.08643252871502467, 'gamma': 0.06769268758135893, 'alpha': 0.09192284277915702, 'lambda': 0.03460932926531541, 'subsample': 0.6212969355093035, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:37,312]\u001b[0m Trial 125 finished with value: 0.721177 and parameters: {'max_depth': 6, 'eta': 0.0934698090777456, 'gamma': 0.061632975891999335, 'alpha': 0.09568055254519078, 'lambda': 0.04793979618950784, 'subsample': 0.5973672445370375, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:38,283]\u001b[0m Trial 126 finished with value: 0.709465 and parameters: {'max_depth': 6, 'eta': 0.0929226104192351, 'gamma': 0.06352411391047391, 'alpha': 0.0860398636013005, 'lambda': 0.04808020821492405, 'subsample': 0.6446665976060509, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:39,347]\u001b[0m Trial 127 finished with value: 0.713344 and parameters: {'max_depth': 7, 'eta': 0.08857211106511811, 'gamma': 0.06172367520079869, 'alpha': 0.09519407193428443, 'lambda': 0.06499354041922772, 'subsample': 0.6041911443671855, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:40,327]\u001b[0m Trial 128 finished with value: 0.715221 and parameters: {'max_depth': 6, 'eta': 0.09041935282551243, 'gamma': 0.07224073598885879, 'alpha': 0.08249977931462685, 'lambda': 0.05301907988195882, 'subsample': 0.6296996082039893, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:41,296]\u001b[0m Trial 129 finished with value: 0.713229 and parameters: {'max_depth': 6, 'eta': 0.0981213448383595, 'gamma': 0.0666412500744585, 'alpha': 0.09988213157686114, 'lambda': 0.032168134951478536, 'subsample': 0.5994313397343816, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:42,292]\u001b[0m Trial 130 finished with value: 0.710049 and parameters: {'max_depth': 6, 'eta': 0.08275606526539288, 'gamma': 0.06876217356528194, 'alpha': 0.09327583670401372, 'lambda': 0.09761519860873176, 'subsample': 0.5675471677511935, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:43,273]\u001b[0m Trial 131 finished with value: 0.715102 and parameters: {'max_depth': 6, 'eta': 0.09564207078187117, 'gamma': 0.06102274513232202, 'alpha': 0.09722917083969025, 'lambda': 0.03772969703156027, 'subsample': 0.5840723632273882, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:44,276]\u001b[0m Trial 132 finished with value: 0.714052 and parameters: {'max_depth': 6, 'eta': 0.09447660888254286, 'gamma': 0.056024274853078856, 'alpha': 0.09552924136580211, 'lambda': 0.04446249448812641, 'subsample': 0.6138331258705998, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:45,269]\u001b[0m Trial 133 finished with value: 0.714992 and parameters: {'max_depth': 6, 'eta': 0.09170569924397048, 'gamma': 0.06433580084037457, 'alpha': 0.08969186779288339, 'lambda': 0.0746017220820321, 'subsample': 0.5905604390789745, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:46,182]\u001b[0m Trial 134 finished with value: 0.702568 and parameters: {'max_depth': 5, 'eta': 0.09987677801727579, 'gamma': 0.05814708196855738, 'alpha': 0.09185347988044995, 'lambda': 0.04104554274067029, 'subsample': 0.5421552409567275, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:47,206]\u001b[0m Trial 135 finished with value: 0.71875 and parameters: {'max_depth': 6, 'eta': 0.09652271095850726, 'gamma': 0.055033539324170676, 'alpha': 0.09778049394712927, 'lambda': 0.08266268151700545, 'subsample': 0.5762312061233883, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:48,235]\u001b[0m Trial 136 finished with value: 0.716393 and parameters: {'max_depth': 6, 'eta': 0.09374968298695502, 'gamma': 0.07495559351911286, 'alpha': 0.0936628106998863, 'lambda': 0.044927194077199306, 'subsample': 0.6064420778481584, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:49,228]\u001b[0m Trial 137 finished with value: 0.718494 and parameters: {'max_depth': 6, 'eta': 0.08601869903904753, 'gamma': 0.060009527668404616, 'alpha': 0.09606345412279098, 'lambda': 0.0590580936470684, 'subsample': 0.6522817834856038, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:50,298]\u001b[0m Trial 138 finished with value: 0.714636 and parameters: {'max_depth': 7, 'eta': 0.08956809770933752, 'gamma': 0.06595866928716308, 'alpha': 0.09982774941334689, 'lambda': 0.05676077793120286, 'subsample': 0.5950300646351726, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:51,289]\u001b[0m Trial 139 finished with value: 0.713584 and parameters: {'max_depth': 6, 'eta': 0.09655232739027449, 'gamma': 0.06234560248422125, 'alpha': 0.09035636153954073, 'lambda': 0.09115922794235123, 'subsample': 0.6326708781848852, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:52,216]\u001b[0m Trial 140 finished with value: 0.71476 and parameters: {'max_depth': 5, 'eta': 0.09273708265235436, 'gamma': 0.05307935398328609, 'alpha': 0.06336490446782275, 'lambda': 0.04682185876581812, 'subsample': 0.563849912116117, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:53,204]\u001b[0m Trial 141 finished with value: 0.715928 and parameters: {'max_depth': 6, 'eta': 0.09559734266239392, 'gamma': 0.05542026438439531, 'alpha': 0.09791999061135258, 'lambda': 0.03880379426742666, 'subsample': 0.5783141369146154, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:54,234]\u001b[0m Trial 142 finished with value: 0.713469 and parameters: {'max_depth': 6, 'eta': 0.09794757030819248, 'gamma': 0.05820464001454815, 'alpha': 0.09786533144342813, 'lambda': 0.07966830306997877, 'subsample': 0.5564006116405842, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:55,221]\u001b[0m Trial 143 finished with value: 0.711948 and parameters: {'max_depth': 6, 'eta': 0.09405756161418824, 'gamma': 0.05391672389334535, 'alpha': 0.0949101709673865, 'lambda': 0.09568073120359229, 'subsample': 0.5747871087012426, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:56,257]\u001b[0m Trial 144 finished with value: 0.715928 and parameters: {'max_depth': 6, 'eta': 0.09778191107503195, 'gamma': 0.056703801173757604, 'alpha': 0.0965331569838678, 'lambda': 0.0891298421915781, 'subsample': 0.6143842666104882, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:57,508]\u001b[0m Trial 145 finished with value: 0.721446 and parameters: {'max_depth': 6, 'eta': 0.09069941956918952, 'gamma': 0.06443690000981783, 'alpha': 0.09307035492635335, 'lambda': 0.09494256774613358, 'subsample': 0.5975763793934404, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:38:59,001]\u001b[0m Trial 146 finished with value: 0.711002 and parameters: {'max_depth': 7, 'eta': 0.09125742146699502, 'gamma': 0.0706790632730241, 'alpha': 0.09313012371258121, 'lambda': 0.04300125141320266, 'subsample': 0.5944210284448436, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:00,095]\u001b[0m Trial 147 finished with value: 0.70903 and parameters: {'max_depth': 4, 'eta': 0.08727070898024464, 'gamma': 0.06380001750342075, 'alpha': 0.09104261783525866, 'lambda': 0.09916097759542467, 'subsample': 0.6231571808039638, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:01,441]\u001b[0m Trial 148 finished with value: 0.712059 and parameters: {'max_depth': 6, 'eta': 0.0894370623060804, 'gamma': 0.06804341930430532, 'alpha': 0.08740970647462865, 'lambda': 0.09233528727425082, 'subsample': 0.606976353782339, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:02,810]\u001b[0m Trial 149 finished with value: 0.713115 and parameters: {'max_depth': 6, 'eta': 0.09997135335774959, 'gamma': 0.0649414160851164, 'alpha': 0.05867502813328694, 'lambda': 0.036381160168019955, 'subsample': 0.589689583786464, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:04,296]\u001b[0m Trial 150 finished with value: 0.710157 and parameters: {'max_depth': 6, 'eta': 0.061790841638670456, 'gamma': 0.06187720786175111, 'alpha': 0.06754820200493446, 'lambda': 0.09931372202764842, 'subsample': 0.5459744219017953, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:05,719]\u001b[0m Trial 151 finished with value: 0.716981 and parameters: {'max_depth': 6, 'eta': 0.09680277914472984, 'gamma': 0.05966466453929532, 'alpha': 0.09998819597077996, 'lambda': 0.09538865247055092, 'subsample': 0.5682453152625065, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:07,020]\u001b[0m Trial 152 finished with value: 0.716981 and parameters: {'max_depth': 6, 'eta': 0.09357052185636992, 'gamma': 0.051748301318217935, 'alpha': 0.09445412439400279, 'lambda': 0.08258104932954816, 'subsample': 0.5846704740068153, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:08,285]\u001b[0m Trial 153 finished with value: 0.712418 and parameters: {'max_depth': 6, 'eta': 0.09597671906351654, 'gamma': 0.04503431289117461, 'alpha': 0.09770042016508879, 'lambda': 0.040759696043568265, 'subsample': 0.6010435092613005, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:09,548]\u001b[0m Trial 154 finished with value: 0.714169 and parameters: {'max_depth': 6, 'eta': 0.09160480549967816, 'gamma': 0.0576994952591341, 'alpha': 0.09248607731907083, 'lambda': 0.08639202240260707, 'subsample': 0.5766372533117956, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:11,303]\u001b[0m Trial 155 finished with value: 0.712757 and parameters: {'max_depth': 6, 'eta': 0.07936731541125555, 'gamma': 0.05416658027896984, 'alpha': 0.09626499870275401, 'lambda': 0.09405808105945034, 'subsample': 0.6167905866011161, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:12,365]\u001b[0m Trial 156 finished with value: 0.721633 and parameters: {'max_depth': 6, 'eta': 0.09430545578011831, 'gamma': 0.048398257341817685, 'alpha': 0.0892583297781144, 'lambda': 0.0903423800605083, 'subsample': 0.6413568216788099, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:13,326]\u001b[0m Trial 157 finished with value: 0.717781 and parameters: {'max_depth': 6, 'eta': 0.09343676301455496, 'gamma': 0.049833515656336355, 'alpha': 0.08878490907905756, 'lambda': 0.049255968563795716, 'subsample': 0.6387949563394035, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:14,218]\u001b[0m Trial 158 finished with value: 0.712033 and parameters: {'max_depth': 5, 'eta': 0.08799671972978139, 'gamma': 0.04809081003785327, 'alpha': 0.08427889396413488, 'lambda': 0.03373332735590122, 'subsample': 0.6315159610116469, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:15,178]\u001b[0m Trial 159 finished with value: 0.716516 and parameters: {'max_depth': 6, 'eta': 0.08480850055805415, 'gamma': 0.04686825633407781, 'alpha': 0.09072305216885436, 'lambda': 0.06106387172467082, 'subsample': 0.6229400595162602, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:16,209]\u001b[0m Trial 160 finished with value: 0.709465 and parameters: {'max_depth': 7, 'eta': 0.09056245454878843, 'gamma': 0.06807562029276845, 'alpha': 0.08055524456383067, 'lambda': 0.09633946772078522, 'subsample': 0.6727845310093421, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:17,183]\u001b[0m Trial 161 finished with value: 0.722772 and parameters: {'max_depth': 6, 'eta': 0.09636355122128555, 'gamma': 0.05187146247694667, 'alpha': 0.09402901045305026, 'lambda': 0.09743399447044984, 'subsample': 0.601232211226774, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:18,149]\u001b[0m Trial 162 finished with value: 0.714873 and parameters: {'max_depth': 6, 'eta': 0.09545411993215827, 'gamma': 0.05182841181949032, 'alpha': 0.09483606961356769, 'lambda': 0.0975843357954588, 'subsample': 0.6115912150979896, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:19,166]\u001b[0m Trial 163 finished with value: 0.714992 and parameters: {'max_depth': 6, 'eta': 0.09808384030029214, 'gamma': 0.04528508939126857, 'alpha': 0.07370167399823563, 'lambda': 0.09363410723872587, 'subsample': 0.6007254976760112, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:20,186]\u001b[0m Trial 164 finished with value: 0.716858 and parameters: {'max_depth': 6, 'eta': 0.09246053143449463, 'gamma': 0.0413988859834815, 'alpha': 0.09229257013326854, 'lambda': 0.09094155458188678, 'subsample': 0.6432267438610751, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:21,144]\u001b[0m Trial 165 finished with value: 0.714519 and parameters: {'max_depth': 6, 'eta': 0.09413499450345572, 'gamma': 0.049041858386934443, 'alpha': 0.051125537382250716, 'lambda': 0.09445611968684457, 'subsample': 0.5897469877175899, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:22,108]\u001b[0m Trial 166 finished with value: 0.71615 and parameters: {'max_depth': 6, 'eta': 0.07388890814735112, 'gamma': 0.06577300339061154, 'alpha': 0.08691846744941441, 'lambda': 0.09936897626786566, 'subsample': 0.608817673915008, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:23,110]\u001b[0m Trial 167 finished with value: 0.713229 and parameters: {'max_depth': 6, 'eta': 0.09866318533895385, 'gamma': 0.06064278347550925, 'alpha': 0.09383049848147751, 'lambda': 0.03801770963618288, 'subsample': 0.6221171117327882, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:24,075]\u001b[0m Trial 168 finished with value: 0.723856 and parameters: {'max_depth': 6, 'eta': 0.09512043703913156, 'gamma': 0.056273685988384975, 'alpha': 0.08894804185020548, 'lambda': 0.035350335819841344, 'subsample': 0.6542076183752967, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:25,071]\u001b[0m Trial 169 finished with value: 0.715102 and parameters: {'max_depth': 6, 'eta': 0.09139291669109592, 'gamma': 0.06328497130672965, 'alpha': 0.089690329321617, 'lambda': 0.034703468776696805, 'subsample': 0.6601509912114015, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:25,971]\u001b[0m Trial 170 finished with value: 0.712986 and parameters: {'max_depth': 5, 'eta': 0.08959572657370121, 'gamma': 0.07154285972075035, 'alpha': 0.08494333496720817, 'lambda': 0.06859335291548023, 'subsample': 0.6545101905234116, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:26,941]\u001b[0m Trial 171 finished with value: 0.705012 and parameters: {'max_depth': 6, 'eta': 0.09507906718772735, 'gamma': 0.05276757105324478, 'alpha': 0.08875208753954267, 'lambda': 0.04193757607866272, 'subsample': 0.6363311026323129, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:27,903]\u001b[0m Trial 172 finished with value: 0.717073 and parameters: {'max_depth': 6, 'eta': 0.09651739781832906, 'gamma': 0.056049946491027916, 'alpha': 0.041879304906997504, 'lambda': 0.03919824978624322, 'subsample': 0.5976521423628841, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:28,880]\u001b[0m Trial 173 finished with value: 0.718494 and parameters: {'max_depth': 6, 'eta': 0.0935177936101928, 'gamma': 0.05088621400513992, 'alpha': 0.09617400219308597, 'lambda': 0.02883462004800466, 'subsample': 0.6656048710504048, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:29,862]\u001b[0m Trial 174 finished with value: 0.718033 and parameters: {'max_depth': 6, 'eta': 0.09870250015332066, 'gamma': 0.05750133656258525, 'alpha': 0.09283463901755691, 'lambda': 0.03613670526088796, 'subsample': 0.5847940216802017, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:30,840]\u001b[0m Trial 175 finished with value: 0.714052 and parameters: {'max_depth': 6, 'eta': 0.09608230231098637, 'gamma': 0.059215016444763895, 'alpha': 0.07585357742083655, 'lambda': 0.044126433512790345, 'subsample': 0.5178866674076028, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:31,801]\u001b[0m Trial 176 finished with value: 0.714052 and parameters: {'max_depth': 6, 'eta': 0.09201146019139703, 'gamma': 0.061798861843125115, 'alpha': 0.09820433077741716, 'lambda': 0.03242740223435704, 'subsample': 0.6126386009275856, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:32,761]\u001b[0m Trial 177 finished with value: 0.708299 and parameters: {'max_depth': 6, 'eta': 0.09993291006888146, 'gamma': 0.04797596880770599, 'alpha': 0.09116748400222517, 'lambda': 0.05176653511197438, 'subsample': 0.646894923282023, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:33,822]\u001b[0m Trial 178 finished with value: 0.698333 and parameters: {'max_depth': 7, 'eta': 0.047704430830510326, 'gamma': 0.054196148635172456, 'alpha': 0.09503908396826727, 'lambda': 0.09690565879744267, 'subsample': 0.6298619033177173, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:34,775]\u001b[0m Trial 179 finished with value: 0.720263 and parameters: {'max_depth': 6, 'eta': 0.09396238123079571, 'gamma': 0.06377500308448827, 'alpha': 0.07933542547663776, 'lambda': 0.04552792122601612, 'subsample': 0.5615548371868455, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:35,732]\u001b[0m Trial 180 finished with value: 0.708778 and parameters: {'max_depth': 6, 'eta': 0.08825731887041868, 'gamma': 0.06411504743125679, 'alpha': 0.07826526783933116, 'lambda': 0.040476854125325326, 'subsample': 0.5300257720737693, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:36,686]\u001b[0m Trial 181 finished with value: 0.715928 and parameters: {'max_depth': 6, 'eta': 0.09460003083961221, 'gamma': 0.06923349996673347, 'alpha': 0.0882025883451055, 'lambda': 0.046448024040705575, 'subsample': 0.5535843097390694, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:37,639]\u001b[0m Trial 182 finished with value: 0.718494 and parameters: {'max_depth': 6, 'eta': 0.09242735025953305, 'gamma': 0.06633635138005904, 'alpha': 0.08172923502259812, 'lambda': 0.045112834925136215, 'subsample': 0.5672638643242086, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:38,592]\u001b[0m Trial 183 finished with value: 0.716049 and parameters: {'max_depth': 6, 'eta': 0.09738300051219444, 'gamma': 0.06152634675398509, 'alpha': 0.07983898717418868, 'lambda': 0.042562241566965434, 'subsample': 0.5961502921060808, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:39,544]\u001b[0m Trial 184 finished with value: 0.723716 and parameters: {'max_depth': 6, 'eta': 0.09430483911391926, 'gamma': 0.05942974558835273, 'alpha': 0.08634128801403547, 'lambda': 0.04845016701987787, 'subsample': 0.5804880395316765, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:40,500]\u001b[0m Trial 185 finished with value: 0.710204 and parameters: {'max_depth': 6, 'eta': 0.08996619371087385, 'gamma': 0.059852144397300376, 'alpha': 0.0859632024628439, 'lambda': 0.04931524694326916, 'subsample': 0.6051631841030948, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:41,452]\u001b[0m Trial 186 finished with value: 0.715686 and parameters: {'max_depth': 6, 'eta': 0.09381455228302045, 'gamma': 0.06348087024803208, 'alpha': 0.085293398778057, 'lambda': 0.07251522790238162, 'subsample': 0.5655757988099409, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:42,409]\u001b[0m Trial 187 finished with value: 0.716393 and parameters: {'max_depth': 6, 'eta': 0.09095471580138353, 'gamma': 0.057769566194460546, 'alpha': 0.08347031944925243, 'lambda': 0.03765450198189151, 'subsample': 0.5814463695636551, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:43,704]\u001b[0m Trial 188 finished with value: 0.697521 and parameters: {'max_depth': 10, 'eta': 0.0948705847737521, 'gamma': 0.06722965732798925, 'alpha': 0.09097962653020066, 'lambda': 0.053528684260202866, 'subsample': 0.6183261299375955, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:44,661]\u001b[0m Trial 189 finished with value: 0.709836 and parameters: {'max_depth': 6, 'eta': 0.0810442767945126, 'gamma': 0.06534034839885336, 'alpha': 0.08704926347392115, 'lambda': 0.04633078153644358, 'subsample': 0.552872921195746, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:45,690]\u001b[0m Trial 190 finished with value: 0.712644 and parameters: {'max_depth': 7, 'eta': 0.08658513925047437, 'gamma': 0.0558238605142115, 'alpha': 0.0817759690775707, 'lambda': 0.0874442322889015, 'subsample': 0.697781950170367, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:46,652]\u001b[0m Trial 191 finished with value: 0.71615 and parameters: {'max_depth': 6, 'eta': 0.07699387962019405, 'gamma': 0.05219407808198226, 'alpha': 0.0935562796315884, 'lambda': 0.047715849602646694, 'subsample': 0.5841614296744332, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:47,610]\u001b[0m Trial 192 finished with value: 0.714873 and parameters: {'max_depth': 6, 'eta': 0.09653917405734022, 'gamma': 0.05976922432831443, 'alpha': 0.09804339127615798, 'lambda': 0.04347977269303931, 'subsample': 0.5963802257764035, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:48,569]\u001b[0m Trial 193 finished with value: 0.715566 and parameters: {'max_depth': 6, 'eta': 0.09274041544741538, 'gamma': 0.05100749094960987, 'alpha': 0.09592627199865336, 'lambda': 0.09031593145071638, 'subsample': 0.573992092011657, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:49,762]\u001b[0m Trial 194 finished with value: 0.710635 and parameters: {'max_depth': 9, 'eta': 0.09819751743409835, 'gamma': 0.06250099180176502, 'alpha': 0.03528390650314092, 'lambda': 0.0395319201898343, 'subsample': 0.5911772588184054, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:50,725]\u001b[0m Trial 195 finished with value: 0.710049 and parameters: {'max_depth': 6, 'eta': 0.09534307541871329, 'gamma': 0.05440537502294761, 'alpha': 0.09393714138936532, 'lambda': 0.05065241859078014, 'subsample': 0.6875978140147619, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:51,679]\u001b[0m Trial 196 finished with value: 0.716393 and parameters: {'max_depth': 6, 'eta': 0.09410996971414146, 'gamma': 0.05745903935081515, 'alpha': 0.089629704018866, 'lambda': 0.03582316307174854, 'subsample': 0.5601209473261277, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:52,637]\u001b[0m Trial 197 finished with value: 0.714169 and parameters: {'max_depth': 6, 'eta': 0.09685084564103834, 'gamma': 0.0738302342819893, 'alpha': 0.09970747111834907, 'lambda': 0.09226714728040021, 'subsample': 0.6067078326957336, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:53,593]\u001b[0m Trial 198 finished with value: 0.721365 and parameters: {'max_depth': 6, 'eta': 0.09140968556217229, 'gamma': 0.06963205101214381, 'alpha': 0.09651936641292999, 'lambda': 0.07634185684401111, 'subsample': 0.538416298727503, 'sampling_method': 'gradient_based'}. Best is trial 121 with value: 0.724166.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 12:39:54,556]\u001b[0m Trial 199 finished with value: 0.719672 and parameters: {'max_depth': 6, 'eta': 0.08962058131836795, 'gamma': 0.06624859956497588, 'alpha': 0.09241319394554501, 'lambda': 0.0890258514336126, 'subsample': 0.5510939721125317, 'sampling_method': 'uniform'}. Best is trial 121 with value: 0.724166.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def f1_calculator(pred, data):\n",
    "    labels = data.get_label()\n",
    "    pred = pred > 0.5\n",
    "    return 'f1', f1_score(labels, pred)\n",
    "\n",
    "\n",
    "def objective_2(trial):\n",
    "    evals_results = {}\n",
    "    param = {'objective': 'binary:logistic', 'tree_method': 'gpu_hist', 'verbosity': 0}\n",
    "    param['max_depth'] = trial.suggest_int('max_depth', 3, 10)\n",
    "    param['eta'] = trial.suggest_float('eta', 0, 1e-1)\n",
    "    param['gamma'] = trial.suggest_float('gamma', 0, 1e-1)\n",
    "    param['alpha'] = trial.suggest_float('alpha', 0, 1e-1)\n",
    "    param['lambda'] = trial.suggest_float('lambda', 0, 1e-1)\n",
    "    param['subsamplea'] = trial.suggest_float('subsample', 0.5, 1)\n",
    "    param['sampling_method'] = trial.suggest_categorical('sampling_method', ['uniform', 'gradient_based'])\n",
    "    num_rounds = 100\n",
    "    bst = xgb.train(param, dtrain, num_rounds, evals=[(dtest, 'test')], feval=f1_calculator, verbose_eval=False, evals_result=evals_results)\n",
    "    return evals_results['test']['f1'][-1]\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_2, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'eta': 0.09081514003358984,\n",
       " 'gamma': 0.06642929982914873,\n",
       " 'alpha': 0.0940319005665157,\n",
       " 'lambda': 0.03697634500529317,\n",
       " 'subsample': 0.6137676048529289,\n",
       " 'sampling_method': 'gradient_based'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals_results = {}\n",
    "param = {'objective': 'binary:logistic', 'tree_method': 'gpu_hist', 'verbosity': 0}\n",
    "param['max_depth'] = study.best_params['max_depth']\n",
    "param['eta'] = study.best_params['eta']\n",
    "param['gamma'] = study.best_params['gamma']\n",
    "param['alpha'] = study.best_params['alpha']\n",
    "param['lambda'] = study.best_params['lambda']\n",
    "param['subsamplea'] = study.best_params['subsample']\n",
    "param['sampling_method'] = study.best_params['sampling_method']\n",
    "num_rounds = 100\n",
    "bst = xgb.train(param, dtrain, num_rounds, evals=[(dtrain, 'train'), (dtest, 'test')], verbose_eval=False, feval=f1_calculator, evals_result=evals_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(num_rounds), evals_results['train']['logloss'], label='train')\n",
    "plt.plot(range(num_rounds), evals_results['test']['logloss'], label='test')\n",
    "plt.legend()\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(num_rounds), evals_results['train']['f1'], label='train')\n",
    "plt.plot(range(num_rounds), evals_results['test']['f1'], label='test')\n",
    "plt.legend()\n",
    "plt.title('F1 Score Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7335968379446641"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [1 if item > 0.5 else 0 for item in bst.predict(dtest)]\n",
    "f1_score(test_set.target, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst.save_model('xgb.model')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, path=TRAIN_PATH, pad_to=400, pad=True, pad_value=0):\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        for file in os.listdir(path):\n",
    "            df = pd.read_csv(os.path.join(path, file), sep='|')\n",
    "            sepsis_index = df[df['SepsisLabel'] == 1].first_valid_index()\n",
    "            df = df.drop('SepsisLabel', axis=1)\n",
    "            if sepsis_index is not None:\n",
    "                df = df.iloc[:sepsis_index+1]\n",
    "                self.targets.append(1)\n",
    "            else:\n",
    "                self.targets.append(0)\n",
    "            df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "            df['time'] = df.index + 1\n",
    "            data = torch.tensor(df.values, dtype=torch.float32)\n",
    "            self.data.append(data)\n",
    "            if pad:\n",
    "                self.data[-1] = nn.functional.pad(self.data[-1], (0, 0, 0, pad_to - self.data[-1].shape[0]), value=pad_value)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_dataset = LSTMDataset()\n",
    "lstm_test_dataset = LSTMDataset(path=TEST_PATH)\n",
    "lstm_train_dataloader = DataLoader(lstm_train_dataset, batch_size=32, shuffle=True)\n",
    "lstm_test_dataloader = DataLoader(lstm_test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_dataset2 = LSTMDataset(pad=False)\n",
    "lstm_test_dataset2 = LSTMDataset(path=TEST_PATH, pad=False)\n",
    "lstm_train_dataloader2 = DataLoader(lstm_train_dataset, batch_size=1, shuffle=True)\n",
    "lstm_test_dataloader2 = DataLoader(lstm_test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_dataset3 = LSTMDataset(pad=False)\n",
    "lstm_test_dataset3 = LSTMDataset(path=TEST_PATH, pad=False)\n",
    "lstm_train_dataloader3 = DataLoader(lstm_train_dataset, batch_size=32, shuffle=True)\n",
    "lstm_test_dataloader3 = DataLoader(lstm_test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_size=40, in_channels=400, out_channels=40, hidden_size=128, num_layers=2, lstm_dropout=0.1, fc_dropout=0.1, bidirectional=True, conv_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.maxpool = nn.MaxPool1d(4)\n",
    "        self.conv = nn.Sequential(nn.Conv1d(in_channels, out_channels, 3, padding=1), self.maxpool, nn.ReLU(), nn.Dropout(conv_dropout))\n",
    "        self.lstm = nn.LSTM(int(embedding_size/4), hidden_size, num_layers, dropout=lstm_dropout, batch_first=True, bidirectional=bidirectional)\n",
    "        self.fc_dropout = nn.Dropout(fc_dropout)\n",
    "        self.fc = nn.Linear(out_channels*(int(2*hidden_size) if bidirectional else int(hidden_size)), 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.fc_dropout(out)\n",
    "        out = self.fc(out.reshape(x.shape[0], -1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:27:01,885]\u001b[0m A new study created in memory with name: no-name-842555f8-1a0d-4af0-8bd8-135e46c45dc5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.40823551415047404 Test Loss: 0.4914904064934004\n",
      "Epoch: 2 Train Loss: 0.3809345145036641 Test Loss: 0.2725357453282268\n",
      "Epoch: 3 Train Loss: 0.3606152299471454 Test Loss: 0.2817902638318059\n",
      "Epoch: 4 Train Loss: 0.34913200582235293 Test Loss: 0.3586042225717927\n",
      "Epoch: 5 Train Loss: 0.35290566140618174 Test Loss: 0.26980303098170905\n",
      "Epoch: 6 Train Loss: 0.33707730998089536 Test Loss: 0.2723569692657017\n",
      "Epoch: 7 Train Loss: 0.36083916259985416 Test Loss: 0.4884528692145222\n",
      "Epoch: 8 Train Loss: 0.34493158525236794 Test Loss: 0.3023095055283925\n",
      "Epoch: 9 Train Loss: 0.3229890532143414 Test Loss: 0.2718473630020032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:28:16,905]\u001b[0m Trial 0 finished with value: 0.0 and parameters: {'hidden_size': 130, 'num_layers': 3, 'lstm_dropout': 0.38786694720775733, 'fc_dropout': 0.32294447823078487, 'bidirectional': True, 'conv_dropout': 0.11136091475839233, 'out_channels': 7, 'lr': 0.026899494160586}. Best is trial 0 with value: 0.0.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.3543047983849887 Test Loss: 0.2650885775732918\n",
      "Epoch: 1 Train Loss: 4.939631567440793 Test Loss: 4.708147100747203\n",
      "Epoch: 2 Train Loss: 1.6919201137397486 Test Loss: 0.5401809790576207\n",
      "Epoch: 3 Train Loss: 0.7090450379818758 Test Loss: 0.5009706859588816\n",
      "Epoch: 4 Train Loss: 0.42119719973656977 Test Loss: 0.3391796201556778\n",
      "Epoch: 5 Train Loss: 0.31968295657152773 Test Loss: 0.24003794243017706\n",
      "Epoch: 6 Train Loss: 0.245183362069726 Test Loss: 0.23848140065948042\n",
      "Epoch: 7 Train Loss: 0.23981891162991523 Test Loss: 0.23813067902676976\n",
      "Epoch: 8 Train Loss: 0.24770655983686446 Test Loss: 0.2569653448491051\n",
      "Epoch: 9 Train Loss: 0.264802092140913 Test Loss: 0.2587497460480315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:29:17,323]\u001b[0m Trial 1 finished with value: 0.48195121951219505 and parameters: {'hidden_size': 114, 'num_layers': 3, 'lstm_dropout': 0.4671902374058449, 'fc_dropout': 0.19823765230877982, 'bidirectional': False, 'conv_dropout': 0.4264783017261763, 'out_channels': 32, 'lr': 0.0944706851035895}. Best is trial 1 with value: 0.48195121951219505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.26161769689917563 Test Loss: 0.24835049945373125\n",
      "Epoch: 1 Train Loss: 3.0868704090989243 Test Loss: 1.2150234831050706\n",
      "Epoch: 2 Train Loss: 1.8924855629310242 Test Loss: 1.3789579091361537\n",
      "Epoch: 3 Train Loss: 1.8648176345251515 Test Loss: 1.4271603352345599\n",
      "Epoch: 4 Train Loss: 1.798691596954213 Test Loss: 1.1881072010856848\n",
      "Epoch: 5 Train Loss: 1.775045576238282 Test Loss: 2.0824768758429504\n",
      "Epoch: 6 Train Loss: 1.627734329857097 Test Loss: 0.6734685539810981\n",
      "Epoch: 7 Train Loss: 1.6104831101080326 Test Loss: 0.901650518558404\n",
      "Epoch: 8 Train Loss: 1.6544653149071882 Test Loss: 1.592300504922105\n",
      "Epoch: 9 Train Loss: 1.3862123281143923 Test Loss: 1.8524769095186226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:30:44,160]\u001b[0m Trial 2 finished with value: 0.38047138047138046 and parameters: {'hidden_size': 205, 'num_layers': 3, 'lstm_dropout': 0.3259132593893946, 'fc_dropout': 0.4331696469110528, 'bidirectional': False, 'conv_dropout': 0.06616043655891479, 'out_channels': 26, 'lr': 0.059598793430451824}. Best is trial 1 with value: 0.48195121951219505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 1.464762717242214 Test Loss: 1.2025780774914798\n",
      "Epoch: 1 Train Loss: 1.6411326428576292 Test Loss: 0.913228414738521\n",
      "Epoch: 2 Train Loss: 1.1315820117917705 Test Loss: 0.7477426508010543\n",
      "Epoch: 3 Train Loss: 1.305202123776638 Test Loss: 0.485616859054885\n",
      "Epoch: 4 Train Loss: 1.369129712083663 Test Loss: 0.7810256108665801\n",
      "Epoch: 5 Train Loss: 1.1100608561681138 Test Loss: 0.49010798289476276\n",
      "Epoch: 6 Train Loss: 0.9439887441728457 Test Loss: 0.7366935152820159\n",
      "Epoch: 7 Train Loss: 1.3470321603673925 Test Loss: 0.6315055370327602\n",
      "Epoch: 8 Train Loss: 1.2405790479746264 Test Loss: 1.1717992835673081\n",
      "Epoch: 9 Train Loss: 1.0044318713222855 Test Loss: 0.6645784144529318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:31:50,560]\u001b[0m Trial 3 finished with value: 0.611353711790393 and parameters: {'hidden_size': 161, 'num_layers': 1, 'lstm_dropout': 0.4641082951459673, 'fc_dropout': 0.12670908493472344, 'bidirectional': True, 'conv_dropout': 0.17913477906009612, 'out_channels': 9, 'lr': 0.04837093308798692}. Best is trial 3 with value: 0.611353711790393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 1.030796121084132 Test Loss: 1.3281773799361127\n",
      "Epoch: 1 Train Loss: 1.888666980092723 Test Loss: 1.3736253756695473\n",
      "Epoch: 2 Train Loss: 2.0790212693229173 Test Loss: 1.0015395884506237\n",
      "Epoch: 3 Train Loss: 1.8251407792630496 Test Loss: 2.7906212463927345\n",
      "Epoch: 4 Train Loss: 2.1772257040516876 Test Loss: 6.177531042038061\n",
      "Epoch: 5 Train Loss: 1.995579596335549 Test Loss: 0.4757317286873677\n",
      "Epoch: 6 Train Loss: 1.7619687395020789 Test Loss: 1.0789211504353369\n",
      "Epoch: 7 Train Loss: 1.5633760454926473 Test Loss: 2.4860245244571577\n",
      "Epoch: 8 Train Loss: 1.3497380012497557 Test Loss: 0.8084017636442938\n",
      "Epoch: 9 Train Loss: 1.6045955937874732 Test Loss: 0.3359259317499606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:33:16,005]\u001b[0m Trial 4 finished with value: 0.38012958963282933 and parameters: {'hidden_size': 172, 'num_layers': 3, 'lstm_dropout': 0.3933789259592418, 'fc_dropout': 0.14816693395755726, 'bidirectional': False, 'conv_dropout': 0.37659198342109224, 'out_channels': 11, 'lr': 0.09200191538985045}. Best is trial 3 with value: 0.611353711790393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 1.1923809905618479 Test Loss: 0.3256669938162612\n",
      "Epoch: 1 Train Loss: 2.2868886216537674 Test Loss: 0.7044061877776014\n",
      "Epoch: 2 Train Loss: 0.8799415400476922 Test Loss: 0.4838709694927725\n",
      "Epoch: 3 Train Loss: 0.6559246412787088 Test Loss: 0.2768884574006588\n",
      "Epoch: 4 Train Loss: 0.4508908177866134 Test Loss: 0.2641279083340408\n",
      "Epoch: 5 Train Loss: 0.23095789457689972 Test Loss: 0.21205570908209767\n",
      "Epoch: 6 Train Loss: 0.19856405499577523 Test Loss: 0.1767048465486723\n",
      "Epoch: 7 Train Loss: 0.1882794599324465 Test Loss: 0.22479199815672427\n",
      "Epoch: 8 Train Loss: 0.18720782595872879 Test Loss: 0.17268335395537246\n",
      "Epoch: 9 Train Loss: 0.2158656439445913 Test Loss: 0.17473855130850507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:34:14,547]\u001b[0m Trial 5 finished with value: 0.5804066543438078 and parameters: {'hidden_size': 201, 'num_layers': 2, 'lstm_dropout': 0.35610750699161037, 'fc_dropout': 0.43115585149967245, 'bidirectional': False, 'conv_dropout': 0.3716417750363996, 'out_channels': 25, 'lr': 0.0517015912654446}. Best is trial 3 with value: 0.611353711790393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.20224596108272672 Test Loss: 0.1905334817406278\n",
      "Epoch: 1 Train Loss: 2.16378701760259 Test Loss: 3.4352662233879774\n",
      "Epoch: 2 Train Loss: 2.276975475774829 Test Loss: 2.0707920272551905\n",
      "Epoch: 3 Train Loss: 1.4784544657344776 Test Loss: 0.9491851468592384\n",
      "Epoch: 4 Train Loss: 1.6925020121732974 Test Loss: 0.575648312821606\n",
      "Epoch: 5 Train Loss: 1.5946991081652881 Test Loss: 0.39595890382133514\n",
      "Epoch: 6 Train Loss: 1.0697379359157166 Test Loss: 0.8756981793873828\n",
      "Epoch: 7 Train Loss: 1.077877666633939 Test Loss: 1.1735935270308206\n",
      "Epoch: 8 Train Loss: 0.8877216298877487 Test Loss: 0.41697635448631865\n",
      "Epoch: 9 Train Loss: 0.9578825549559434 Test Loss: 1.4090784347784482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:35:32,681]\u001b[0m Trial 6 finished with value: 0.5157232704402516 and parameters: {'hidden_size': 157, 'num_layers': 2, 'lstm_dropout': 0.3546881234812366, 'fc_dropout': 0.4769575415789662, 'bidirectional': False, 'conv_dropout': 0.47076410349798936, 'out_channels': 21, 'lr': 0.0687679470527466}. Best is trial 3 with value: 0.611353711790393.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.9932765719973476 Test Loss: 0.6667124438110061\n",
      "Epoch: 1 Train Loss: 0.6101307701831522 Test Loss: 0.39880341722678037\n",
      "Epoch: 2 Train Loss: 0.5717068348929641 Test Loss: 0.5271645956122266\n",
      "Epoch: 3 Train Loss: 0.6309630478403202 Test Loss: 0.4408010646315053\n",
      "Epoch: 4 Train Loss: 0.7103602639501212 Test Loss: 0.4876294848105526\n",
      "Epoch: 5 Train Loss: 0.7342725972046301 Test Loss: 0.7137862085839792\n",
      "Epoch: 6 Train Loss: 0.6888874030669367 Test Loss: 0.4967932555672234\n",
      "Epoch: 7 Train Loss: 0.857374742641523 Test Loss: 0.5532785505622905\n",
      "Epoch: 8 Train Loss: 0.9082585032376334 Test Loss: 0.47368637165699057\n",
      "Epoch: 9 Train Loss: 0.8254674056799085 Test Loss: 0.38054298866463154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:36:37,398]\u001b[0m Trial 7 finished with value: 0.6569005397070161 and parameters: {'hidden_size': 234, 'num_layers': 1, 'lstm_dropout': 0.36288005256481953, 'fc_dropout': 0.3547044517390982, 'bidirectional': True, 'conv_dropout': 0.22933337278863847, 'out_channels': 32, 'lr': 0.011935494336341699}. Best is trial 7 with value: 0.6569005397070161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.7848232138604969 Test Loss: 0.42330833816359315\n",
      "Epoch: 1 Train Loss: 0.8202360094875774 Test Loss: 0.3006380583111646\n",
      "Epoch: 2 Train Loss: 0.6310660992550066 Test Loss: 0.6651358893942356\n",
      "Epoch: 3 Train Loss: 0.8863663777242615 Test Loss: 0.3486400906706211\n",
      "Epoch: 4 Train Loss: 0.5559203247306996 Test Loss: 0.7358680390783713\n",
      "Epoch: 5 Train Loss: 0.5120208473675336 Test Loss: 0.495406528050161\n",
      "Epoch: 6 Train Loss: 0.6419409341438413 Test Loss: 0.6585195454739582\n",
      "Epoch: 7 Train Loss: 0.6272385196669802 Test Loss: 0.5425545034941046\n",
      "Epoch: 8 Train Loss: 0.5980023082666208 Test Loss: 0.4384377077192813\n",
      "Epoch: 9 Train Loss: 0.5228548488866143 Test Loss: 0.5889251991404172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:37:33,492]\u001b[0m Trial 8 finished with value: 0.6412593206296604 and parameters: {'hidden_size': 94, 'num_layers': 1, 'lstm_dropout': 0.2524665311816659, 'fc_dropout': 0.22496061426618114, 'bidirectional': False, 'conv_dropout': 0.1221302523626655, 'out_channels': 39, 'lr': 0.03305217471229315}. Best is trial 7 with value: 0.6569005397070161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.5237698559861271 Test Loss: 0.30663624647473836\n",
      "Epoch: 1 Train Loss: 7.302760675881841 Test Loss: 5.024832944138743\n",
      "Epoch: 2 Train Loss: 7.708014297936036 Test Loss: 9.608690572622866\n",
      "Epoch: 3 Train Loss: 8.067231862475529 Test Loss: 5.681612464947442\n",
      "Epoch: 4 Train Loss: 7.878426304490712 Test Loss: 9.54076457404481\n",
      "Epoch: 5 Train Loss: 7.772294423027103 Test Loss: 3.3260328602105282\n",
      "Epoch: 6 Train Loss: 8.997661643976695 Test Loss: 9.417903434735136\n",
      "Epoch: 7 Train Loss: 8.535761167094725 Test Loss: 5.152523007255773\n",
      "Epoch: 8 Train Loss: 7.281274451153929 Test Loss: 8.555549169119935\n",
      "Epoch: 9 Train Loss: 8.710979092512279 Test Loss: 4.205019459784923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:38:43,575]\u001b[0m Trial 9 finished with value: 0.5637065637065636 and parameters: {'hidden_size': 210, 'num_layers': 2, 'lstm_dropout': 0.18953210582899943, 'fc_dropout': 0.4798303692862227, 'bidirectional': False, 'conv_dropout': 0.2162074660727032, 'out_channels': 35, 'lr': 0.065671072227356}. Best is trial 7 with value: 0.6569005397070161.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 6.935195488879382 Test Loss: 2.626475264065153\n",
      "Epoch: 1 Train Loss: 0.21213193262681598 Test Loss: 0.19061496884922108\n",
      "Epoch: 2 Train Loss: 0.18408298959592356 Test Loss: 0.16265138066388643\n",
      "Epoch: 3 Train Loss: 0.18468421629266812 Test Loss: 0.18751956883389442\n",
      "Epoch: 4 Train Loss: 0.19701327529666013 Test Loss: 0.2539143907373954\n",
      "Epoch: 5 Train Loss: 0.19593130489122124 Test Loss: 0.22306436469433263\n",
      "Epoch: 6 Train Loss: 0.20689965382031833 Test Loss: 0.1587951641273908\n",
      "Epoch: 7 Train Loss: 0.18619082821141927 Test Loss: 0.1592865938427873\n",
      "Epoch: 8 Train Loss: 0.21149713233032708 Test Loss: 0.1976605097111612\n",
      "Epoch: 9 Train Loss: 0.19797521514580585 Test Loss: 0.2083415211187289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:39:42,441]\u001b[0m Trial 10 finished with value: 0.6746987951807228 and parameters: {'hidden_size': 251, 'num_layers': 1, 'lstm_dropout': 0.02178751445165944, 'fc_dropout': 0.06364165583418219, 'bidirectional': True, 'conv_dropout': 0.011419334232821404, 'out_channels': 16, 'lr': 0.005950799413117747}. Best is trial 10 with value: 0.6746987951807228.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.20351469887085258 Test Loss: 0.25576308022222344\n",
      "Epoch: 1 Train Loss: 0.18230894694961608 Test Loss: 0.16812601113192047\n",
      "Epoch: 2 Train Loss: 0.17875450203469953 Test Loss: 0.16020570953671162\n",
      "Epoch: 3 Train Loss: 0.17941480057677253 Test Loss: 0.15547773354469588\n",
      "Epoch: 4 Train Loss: 0.17343545610110742 Test Loss: 0.19600177903662616\n",
      "Epoch: 5 Train Loss: 0.17661169425747358 Test Loss: 0.19595116415706734\n",
      "Epoch: 6 Train Loss: 0.1756007564784959 Test Loss: 0.20882853869156848\n",
      "Epoch: 7 Train Loss: 0.1656415808876045 Test Loss: 0.2306511460962637\n",
      "Epoch: 8 Train Loss: 0.16566558357793837 Test Loss: 0.15562914025645477\n",
      "Epoch: 9 Train Loss: 0.17979044071878306 Test Loss: 0.22027110905883412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:40:42,056]\u001b[0m Trial 11 finished with value: 0.6779661016949153 and parameters: {'hidden_size': 255, 'num_layers': 1, 'lstm_dropout': 0.025389922354184635, 'fc_dropout': 0.002021037109234257, 'bidirectional': True, 'conv_dropout': 0.006780052614223209, 'out_channels': 16, 'lr': 0.004274849310018206}. Best is trial 11 with value: 0.6779661016949153.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18703062625019956 Test Loss: 0.19691912913561083\n",
      "Epoch: 1 Train Loss: 0.1549348551299423 Test Loss: 0.15650506938150088\n",
      "Epoch: 2 Train Loss: 0.13998879936113953 Test Loss: 0.13698813244224356\n",
      "Epoch: 3 Train Loss: 0.13700188596695662 Test Loss: 0.1397647591956412\n",
      "Epoch: 4 Train Loss: 0.135134783064574 Test Loss: 0.1441618063793586\n",
      "Epoch: 5 Train Loss: 0.13926887721568346 Test Loss: 0.13845477253793717\n",
      "Epoch: 6 Train Loss: 0.13318847493305802 Test Loss: 0.1370654985749017\n",
      "Epoch: 7 Train Loss: 0.13281043719649316 Test Loss: 0.1409928154664489\n",
      "Epoch: 8 Train Loss: 0.13391102507710456 Test Loss: 0.14933276765744763\n",
      "Epoch: 9 Train Loss: 0.13228823126107453 Test Loss: 0.14499243069142578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:41:34,878]\u001b[0m Trial 12 finished with value: 0.6994535519125684 and parameters: {'hidden_size': 38, 'num_layers': 1, 'lstm_dropout': 0.0156540989256981, 'fc_dropout': 0.015443880742001023, 'bidirectional': True, 'conv_dropout': 0.0006198405599536164, 'out_channels': 15, 'lr': 0.0019207667021480714}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13382789004892112 Test Loss: 0.13743149414777564\n",
      "Epoch: 1 Train Loss: 0.15934477254897356 Test Loss: 0.14703654147351322\n",
      "Epoch: 2 Train Loss: 0.1481441113449633 Test Loss: 0.15194961833901488\n",
      "Epoch: 3 Train Loss: 0.1484869803082198 Test Loss: 0.1416875778878935\n",
      "Epoch: 4 Train Loss: 0.14223739415183664 Test Loss: 0.1530795452354577\n",
      "Epoch: 5 Train Loss: 0.1401316632753238 Test Loss: 0.14006029312519697\n",
      "Epoch: 6 Train Loss: 0.13791299499571325 Test Loss: 0.14185836901977517\n",
      "Epoch: 7 Train Loss: 0.13959914285093547 Test Loss: 0.15674676002559665\n",
      "Epoch: 8 Train Loss: 0.13995878200232983 Test Loss: 0.14341366917085344\n",
      "Epoch: 9 Train Loss: 0.13813637177348137 Test Loss: 0.16180715366555287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:42:32,077]\u001b[0m Trial 13 finished with value: 0.6842948717948718 and parameters: {'hidden_size': 48, 'num_layers': 1, 'lstm_dropout': 0.013772617993286277, 'fc_dropout': 0.007577376985890897, 'bidirectional': True, 'conv_dropout': 0.0021024104088941597, 'out_channels': 16, 'lr': 0.002023879705761149}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13887228516414762 Test Loss: 0.1546752084531604\n",
      "Epoch: 1 Train Loss: 0.1574546200558543 Test Loss: 0.14816321311191247\n",
      "Epoch: 2 Train Loss: 0.14276412536501884 Test Loss: 0.14901252651509767\n",
      "Epoch: 3 Train Loss: 0.1382831597611308 Test Loss: 0.14741406436212146\n",
      "Epoch: 4 Train Loss: 0.1386280729562044 Test Loss: 0.14115731375285992\n",
      "Epoch: 5 Train Loss: 0.13574356535971166 Test Loss: 0.13944539678291962\n",
      "Epoch: 6 Train Loss: 0.13676294722557067 Test Loss: 0.14052496728198693\n",
      "Epoch: 7 Train Loss: 0.13591458186805247 Test Loss: 0.13807541576508706\n",
      "Epoch: 8 Train Loss: 0.13315676214694977 Test Loss: 0.1377936374580565\n",
      "Epoch: 9 Train Loss: 0.13273635865300895 Test Loss: 0.13860690626449668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:43:26,829]\u001b[0m Trial 14 finished with value: 0.6874003189792663 and parameters: {'hidden_size': 32, 'num_layers': 1, 'lstm_dropout': 0.07353625915333668, 'fc_dropout': 0.033789563037103884, 'bidirectional': True, 'conv_dropout': 0.06480659090985025, 'out_channels': 4, 'lr': 0.001490850646970063}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13158396243602039 Test Loss: 0.14047446433966532\n",
      "Epoch: 1 Train Loss: 0.2108359089627862 Test Loss: 0.18670217076334328\n",
      "Epoch: 2 Train Loss: 0.18822372756302358 Test Loss: 0.18795705962176332\n",
      "Epoch: 3 Train Loss: 0.2011060429304838 Test Loss: 0.18965033766703485\n",
      "Epoch: 4 Train Loss: 0.1826589049398899 Test Loss: 0.18473592112525203\n",
      "Epoch: 5 Train Loss: 0.18562306242436172 Test Loss: 0.17590370389243093\n",
      "Epoch: 6 Train Loss: 0.17098976441919803 Test Loss: 0.16224014695983724\n",
      "Epoch: 7 Train Loss: 0.1767192883297801 Test Loss: 0.16934903855093372\n",
      "Epoch: 8 Train Loss: 0.1744681117668748 Test Loss: 0.17202877421705678\n",
      "Epoch: 9 Train Loss: 0.16985154818296433 Test Loss: 0.16537753445581316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:44:25,669]\u001b[0m Trial 15 finished with value: 0.6698337292161519 and parameters: {'hidden_size': 45, 'num_layers': 2, 'lstm_dropout': 0.08410868989981629, 'fc_dropout': 0.08358074570318087, 'bidirectional': True, 'conv_dropout': 0.08225803456587011, 'out_channels': 1, 'lr': 0.015346356395042261}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1687646396204829 Test Loss: 0.16646484323083974\n",
      "Epoch: 1 Train Loss: 0.2002316929921508 Test Loss: 0.19993891863348767\n",
      "Epoch: 2 Train Loss: 0.21109993990920484 Test Loss: 0.3108629118037461\n",
      "Epoch: 3 Train Loss: 0.20746581734865904 Test Loss: 0.18739447193130992\n",
      "Epoch: 4 Train Loss: 0.19659336984842085 Test Loss: 0.250260780428569\n",
      "Epoch: 5 Train Loss: 0.1908262691359967 Test Loss: 0.1783203222452642\n",
      "Epoch: 6 Train Loss: 0.18939813931509852 Test Loss: 0.20711993596281486\n",
      "Epoch: 7 Train Loss: 0.18931432042289525 Test Loss: 0.1788002281857375\n",
      "Epoch: 8 Train Loss: 0.19548709443025292 Test Loss: 0.19126286788191943\n",
      "Epoch: 9 Train Loss: 0.19055104484856128 Test Loss: 0.16360461631545814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:45:20,038]\u001b[0m Trial 16 finished with value: 0.6477272727272727 and parameters: {'hidden_size': 74, 'num_layers': 1, 'lstm_dropout': 0.1169378698413977, 'fc_dropout': 0.0611710639563504, 'bidirectional': True, 'conv_dropout': 0.16324373398013808, 'out_channels': 2, 'lr': 0.019275313744957667}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18498914040252568 Test Loss: 0.1744453061651736\n",
      "Epoch: 1 Train Loss: 0.15337395413815974 Test Loss: 0.14257362469459495\n",
      "Epoch: 2 Train Loss: 0.14215372275859117 Test Loss: 0.13994476272346684\n",
      "Epoch: 3 Train Loss: 0.1375141792833805 Test Loss: 0.1375939335209874\n",
      "Epoch: 4 Train Loss: 0.1332986144974828 Test Loss: 0.13651275374114322\n",
      "Epoch: 5 Train Loss: 0.137734771938622 Test Loss: 0.14180195554138753\n",
      "Epoch: 6 Train Loss: 0.13594603653103113 Test Loss: 0.1539457487135816\n",
      "Epoch: 7 Train Loss: 0.13365834740102292 Test Loss: 0.13775638301080217\n",
      "Epoch: 8 Train Loss: 0.13182155602872372 Test Loss: 0.13462342273670072\n",
      "Epoch: 9 Train Loss: 0.13299501345306636 Test Loss: 0.13902339181556297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:46:20,111]\u001b[0m Trial 17 finished with value: 0.6949559647718174 and parameters: {'hidden_size': 34, 'num_layers': 2, 'lstm_dropout': 0.09702406491106585, 'fc_dropout': 0.16425257288383516, 'bidirectional': True, 'conv_dropout': 0.05844040636629192, 'out_channels': 6, 'lr': 0.0020038140395254363}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.134507756267488 Test Loss: 0.13531592285361724\n",
      "Epoch: 1 Train Loss: 0.23304114204347134 Test Loss: 0.1935121005954453\n",
      "Epoch: 2 Train Loss: 0.19016014986485244 Test Loss: 0.16953128541763218\n",
      "Epoch: 3 Train Loss: 0.17341846999824048 Test Loss: 0.16467389416175718\n",
      "Epoch: 4 Train Loss: 0.17585500506162643 Test Loss: 0.1767492772172244\n",
      "Epoch: 5 Train Loss: 0.1822784347018227 Test Loss: 0.19339873970221408\n",
      "Epoch: 6 Train Loss: 0.18381804067492485 Test Loss: 0.19051730834518948\n",
      "Epoch: 7 Train Loss: 0.18817566215880216 Test Loss: 0.18233278057219598\n",
      "Epoch: 8 Train Loss: 0.17754042514041066 Test Loss: 0.1646473595378593\n",
      "Epoch: 9 Train Loss: 0.1723793307237327 Test Loss: 0.16515358795706456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:46:52,568]\u001b[0m Trial 18 finished with value: 0.6053702196908055 and parameters: {'hidden_size': 71, 'num_layers': 2, 'lstm_dropout': 0.1381859536024765, 'fc_dropout': 0.13926879439358683, 'bidirectional': True, 'conv_dropout': 0.2965319573774283, 'out_channels': 13, 'lr': 0.024825281548966505}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1681841777354479 Test Loss: 0.17719998443945528\n",
      "Epoch: 1 Train Loss: 0.3543801366791129 Test Loss: 0.16553365908110865\n",
      "Epoch: 2 Train Loss: 0.17155953933298587 Test Loss: 0.17514201486929537\n",
      "Epoch: 3 Train Loss: 0.1753052459605038 Test Loss: 0.16271486874824515\n",
      "Epoch: 4 Train Loss: 0.16945379654541612 Test Loss: 0.15965934153110645\n",
      "Epoch: 5 Train Loss: 0.16810939891077578 Test Loss: 0.19538484145396243\n",
      "Epoch: 6 Train Loss: 0.1722983610495925 Test Loss: 0.1700110021954813\n",
      "Epoch: 7 Train Loss: 0.1680628883972764 Test Loss: 0.15975924793142862\n",
      "Epoch: 8 Train Loss: 0.16705696111768484 Test Loss: 0.16274177894805567\n",
      "Epoch: 9 Train Loss: 0.1811721507512033 Test Loss: 0.18475455269753077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:47:26,128]\u001b[0m Trial 19 finished with value: 0.6607717041800644 and parameters: {'hidden_size': 75, 'num_layers': 2, 'lstm_dropout': 0.1676951825444775, 'fc_dropout': 0.18465858960062698, 'bidirectional': True, 'conv_dropout': 0.049392521354280364, 'out_channels': 21, 'lr': 0.03416019862094319}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18308539181500674 Test Loss: 0.18794999378748214\n",
      "Epoch: 1 Train Loss: 0.18198697617352008 Test Loss: 0.17019157773389604\n",
      "Epoch: 2 Train Loss: 0.16623494924753904 Test Loss: 0.16370159842240545\n",
      "Epoch: 3 Train Loss: 0.16744934900403022 Test Loss: 0.15566151603437461\n",
      "Epoch: 4 Train Loss: 0.16303833018690347 Test Loss: 0.1604910465730979\n",
      "Epoch: 5 Train Loss: 0.16359122973233461 Test Loss: 0.15704635239709108\n",
      "Epoch: 6 Train Loss: 0.16479154160171747 Test Loss: 0.16486197082807844\n",
      "Epoch: 7 Train Loss: 0.16280891878902912 Test Loss: 0.16674611596063302\n",
      "Epoch: 8 Train Loss: 0.17464358419552445 Test Loss: 0.17659071071174579\n",
      "Epoch: 9 Train Loss: 0.18273443838432432 Test Loss: 0.1642601756503978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:48:05,582]\u001b[0m Trial 20 finished with value: 0.6528866714183891 and parameters: {'hidden_size': 98, 'num_layers': 2, 'lstm_dropout': 0.06302883076182575, 'fc_dropout': 0.2751573917397267, 'bidirectional': True, 'conv_dropout': 0.1376202775865623, 'out_channels': 6, 'lr': 0.012433235393812189}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18517404569685458 Test Loss: 0.16595767860631117\n",
      "Epoch: 1 Train Loss: 0.1622943287625909 Test Loss: 0.14475001722943193\n",
      "Epoch: 2 Train Loss: 0.14349918688833713 Test Loss: 0.14865434957674137\n",
      "Epoch: 3 Train Loss: 0.14127841406911612 Test Loss: 0.14612847841835727\n",
      "Epoch: 4 Train Loss: 0.14125151639953257 Test Loss: 0.14646388088671353\n",
      "Epoch: 5 Train Loss: 0.13895030131042005 Test Loss: 0.14829385432655723\n",
      "Epoch: 6 Train Loss: 0.13996993922740222 Test Loss: 0.14901044755019605\n",
      "Epoch: 7 Train Loss: 0.1413951914690435 Test Loss: 0.1477662946749181\n",
      "Epoch: 8 Train Loss: 0.1402952223956585 Test Loss: 0.1498329987683997\n",
      "Epoch: 9 Train Loss: 0.1374028864607215 Test Loss: 0.1447578118310664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:48:48,602]\u001b[0m Trial 21 finished with value: 0.6842948717948718 and parameters: {'hidden_size': 32, 'num_layers': 1, 'lstm_dropout': 0.07361401973280626, 'fc_dropout': 0.038893797141874936, 'bidirectional': True, 'conv_dropout': 0.05606188161541484, 'out_channels': 5, 'lr': 0.0019301944153665618}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13916745307594539 Test Loss: 0.14409179817409085\n",
      "Epoch: 1 Train Loss: 0.17241410509869456 Test Loss: 0.16413966448495562\n",
      "Epoch: 2 Train Loss: 0.16843192177265884 Test Loss: 0.15466408970685433\n",
      "Epoch: 3 Train Loss: 0.160018782376498 Test Loss: 0.16039992856998414\n",
      "Epoch: 4 Train Loss: 0.16442226566821336 Test Loss: 0.17252729217947338\n",
      "Epoch: 5 Train Loss: 0.15791576647311448 Test Loss: 0.16835447780180948\n",
      "Epoch: 6 Train Loss: 0.1627351623699069 Test Loss: 0.15750545684022074\n",
      "Epoch: 7 Train Loss: 0.16184559391774236 Test Loss: 0.15796272882138387\n",
      "Epoch: 8 Train Loss: 0.15545947335958482 Test Loss: 0.1603231908152469\n",
      "Epoch: 9 Train Loss: 0.1689575245216489 Test Loss: 0.1866404351870568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:49:36,078]\u001b[0m Trial 22 finished with value: 0.6624305003971406 and parameters: {'hidden_size': 32, 'num_layers': 1, 'lstm_dropout': 0.001779990236578849, 'fc_dropout': 0.11009350852073577, 'bidirectional': True, 'conv_dropout': 0.08477564997670452, 'out_channels': 4, 'lr': 0.008432196710621415}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17917122770473362 Test Loss: 0.1677672714084244\n",
      "Epoch: 1 Train Loss: 0.1555060133226216 Test Loss: 0.1481618653542508\n",
      "Epoch: 2 Train Loss: 0.14262668642625212 Test Loss: 0.15138232444945615\n",
      "Epoch: 3 Train Loss: 0.14034882673770188 Test Loss: 0.14508523261204315\n",
      "Epoch: 4 Train Loss: 0.14371752305701374 Test Loss: 0.14478618202629848\n",
      "Epoch: 5 Train Loss: 0.14184090809077024 Test Loss: 0.1429342782547394\n",
      "Epoch: 6 Train Loss: 0.13997085151299835 Test Loss: 0.1621794073735349\n",
      "Epoch: 7 Train Loss: 0.13775026429593562 Test Loss: 0.13834337608073466\n",
      "Epoch: 8 Train Loss: 0.13613384049236774 Test Loss: 0.14922189156111246\n",
      "Epoch: 9 Train Loss: 0.13541835074052214 Test Loss: 0.13707898588726125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:50:34,110]\u001b[0m Trial 23 finished with value: 0.6909667194928685 and parameters: {'hidden_size': 59, 'num_layers': 1, 'lstm_dropout': 0.10259036501449068, 'fc_dropout': 0.09100541993658842, 'bidirectional': True, 'conv_dropout': 0.03700483682891562, 'out_channels': 10, 'lr': 0.0018610891041150337}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13613420268110932 Test Loss: 0.1551453983961655\n",
      "Epoch: 1 Train Loss: 0.23226808506902308 Test Loss: 0.1689016265265001\n",
      "Epoch: 2 Train Loss: 0.15532498068809508 Test Loss: 0.15554010728820444\n",
      "Epoch: 3 Train Loss: 0.1573794867157936 Test Loss: 0.16276068138643005\n",
      "Epoch: 4 Train Loss: 0.16382519790530206 Test Loss: 0.16631026477061997\n",
      "Epoch: 5 Train Loss: 0.16862875594571233 Test Loss: 0.1511955406790534\n",
      "Epoch: 6 Train Loss: 0.15856989857852458 Test Loss: 0.16044891216812995\n",
      "Epoch: 7 Train Loss: 0.15519045994877814 Test Loss: 0.152567628110512\n",
      "Epoch: 8 Train Loss: 0.16336285930792802 Test Loss: 0.1548075652755678\n",
      "Epoch: 9 Train Loss: 0.15771741430312394 Test Loss: 0.15420081766959007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:51:37,369]\u001b[0m Trial 24 finished with value: 0.6580436540016168 and parameters: {'hidden_size': 60, 'num_layers': 2, 'lstm_dropout': 0.12175665082643866, 'fc_dropout': 0.0907078737534906, 'bidirectional': True, 'conv_dropout': 0.029896762222109283, 'out_channels': 13, 'lr': 0.017027759776956697}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1555047024704516 Test Loss: 0.16978660524605563\n",
      "Epoch: 1 Train Loss: 0.16037653522491455 Test Loss: 0.14333037976711133\n",
      "Epoch: 2 Train Loss: 0.1342346171990037 Test Loss: 0.14351629029614285\n",
      "Epoch: 3 Train Loss: 0.13131015133708715 Test Loss: 0.1362171651105197\n",
      "Epoch: 4 Train Loss: 0.1273540177553892 Test Loss: 0.13316146594385941\n",
      "Epoch: 5 Train Loss: 0.1264521044164896 Test Loss: 0.13448843098700808\n",
      "Epoch: 6 Train Loss: 0.12443760276436806 Test Loss: 0.13216636175759874\n",
      "Epoch: 7 Train Loss: 0.12212677834779025 Test Loss: 0.13410599198870765\n",
      "Epoch: 8 Train Loss: 0.12107050960958005 Test Loss: 0.1309479638255728\n",
      "Epoch: 9 Train Loss: 0.12015108617991209 Test Loss: 0.13287217326509876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:52:35,098]\u001b[0m Trial 25 finished with value: 0.6976744186046512 and parameters: {'hidden_size': 90, 'num_layers': 1, 'lstm_dropout': 0.04393704817335646, 'fc_dropout': 0.16377081996255635, 'bidirectional': True, 'conv_dropout': 0.031701266087766786, 'out_channels': 9, 'lr': 0.00017735853759312222}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11838299439549446 Test Loss: 0.13112691475060612\n",
      "Epoch: 1 Train Loss: 0.20514861845783888 Test Loss: 0.17499549230471395\n",
      "Epoch: 2 Train Loss: 0.16525098844170572 Test Loss: 0.15808478210823604\n",
      "Epoch: 3 Train Loss: 0.15726280042231083 Test Loss: 0.1518208554591805\n",
      "Epoch: 4 Train Loss: 0.15667942016869785 Test Loss: 0.20734460061020293\n",
      "Epoch: 5 Train Loss: 0.15550949306823314 Test Loss: 0.15148482020623005\n",
      "Epoch: 6 Train Loss: 0.1549940683722496 Test Loss: 0.15423647650538352\n",
      "Epoch: 7 Train Loss: 0.15833023422062398 Test Loss: 0.15110002537838185\n",
      "Epoch: 8 Train Loss: 0.16376533172130583 Test Loss: 0.16925450409063325\n",
      "Epoch: 9 Train Loss: 0.15873449837118386 Test Loss: 0.15965083669930602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:53:33,060]\u001b[0m Trial 26 finished with value: 0.6578073089700998 and parameters: {'hidden_size': 94, 'num_layers': 2, 'lstm_dropout': 0.0392998971760519, 'fc_dropout': 0.18505900219917282, 'bidirectional': True, 'conv_dropout': 0.10108643759729424, 'out_channels': 18, 'lr': 0.011062047868851359}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1619988633595407 Test Loss: 0.1620215459045368\n",
      "Epoch: 1 Train Loss: 0.2843093464098376 Test Loss: 0.2715746620440292\n",
      "Epoch: 2 Train Loss: 0.23289980241255834 Test Loss: 0.17151879418058136\n",
      "Epoch: 3 Train Loss: 0.22080751858088188 Test Loss: 0.17479090485126733\n",
      "Epoch: 4 Train Loss: 0.23462720531416126 Test Loss: 0.23792244739884053\n",
      "Epoch: 5 Train Loss: 0.24523922826882188 Test Loss: 0.17526421867334804\n",
      "Epoch: 6 Train Loss: 0.3213815313277748 Test Loss: 0.27638434669889583\n",
      "Epoch: 7 Train Loss: 0.30778303762031717 Test Loss: 0.3167946060331681\n",
      "Epoch: 8 Train Loss: 0.27060573757505046 Test Loss: 0.22484013758757457\n",
      "Epoch: 9 Train Loss: 0.2855872926875105 Test Loss: 0.21999226195943028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:54:26,989]\u001b[0m Trial 27 finished with value: 0.6475409836065574 and parameters: {'hidden_size': 117, 'num_layers': 1, 'lstm_dropout': 0.04934973028847657, 'fc_dropout': 0.15949401802561725, 'bidirectional': True, 'conv_dropout': 0.03463671313170123, 'out_channels': 9, 'lr': 0.020529457132571597}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.27170430781822213 Test Loss: 0.3462102321092634\n",
      "Epoch: 1 Train Loss: 0.19195036522746087 Test Loss: 0.15214618554297157\n",
      "Epoch: 2 Train Loss: 0.1619911053493619 Test Loss: 0.15595160885312306\n",
      "Epoch: 3 Train Loss: 0.155116413359344 Test Loss: 0.16033981361399635\n",
      "Epoch: 4 Train Loss: 0.16056927675902843 Test Loss: 0.17610574747248295\n",
      "Epoch: 5 Train Loss: 0.15227427434623242 Test Loss: 0.15161523435371943\n",
      "Epoch: 6 Train Loss: 0.1536664979211986 Test Loss: 0.15754613251136707\n",
      "Epoch: 7 Train Loss: 0.15355307165831328 Test Loss: 0.1505482008281988\n",
      "Epoch: 8 Train Loss: 0.1532596119761467 Test Loss: 0.15972445766551616\n",
      "Epoch: 9 Train Loss: 0.1520890184916556 Test Loss: 0.14668995086639264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:55:35,927]\u001b[0m Trial 28 finished with value: 0.6612772837510106 and parameters: {'hidden_size': 80, 'num_layers': 2, 'lstm_dropout': 0.043680968310254246, 'fc_dropout': 0.11437545654534942, 'bidirectional': True, 'conv_dropout': 0.001728140187536982, 'out_channels': 14, 'lr': 0.009964447979556318}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1478363943338394 Test Loss: 0.15345843145236993\n",
      "Epoch: 1 Train Loss: 0.344119755256176 Test Loss: 0.21060623110126192\n",
      "Epoch: 2 Train Loss: 0.19318593366444112 Test Loss: 0.18234279154302974\n",
      "Epoch: 3 Train Loss: 0.19499562630951406 Test Loss: 0.21060366004693526\n",
      "Epoch: 4 Train Loss: 0.18914278436601162 Test Loss: 0.16992997221601086\n",
      "Epoch: 5 Train Loss: 0.20692057226337493 Test Loss: 0.1986530192208271\n",
      "Epoch: 6 Train Loss: 0.21908485306408257 Test Loss: 0.29787888077977365\n",
      "Epoch: 7 Train Loss: 0.20910083542969077 Test Loss: 0.1693293546644834\n",
      "Epoch: 8 Train Loss: 0.4289625216339729 Test Loss: 0.8905585092181966\n",
      "Epoch: 9 Train Loss: 0.39840362411857494 Test Loss: 0.2018488840744518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:57:04,807]\u001b[0m Trial 29 finished with value: 0.6015424164524421 and parameters: {'hidden_size': 137, 'num_layers': 3, 'lstm_dropout': 0.005367179039830772, 'fc_dropout': 0.2396011426081875, 'bidirectional': True, 'conv_dropout': 0.10972639258395542, 'out_channels': 7, 'lr': 0.026810691804693754}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.3323531865359164 Test Loss: 0.3523644979449194\n",
      "Epoch: 1 Train Loss: 0.227773862802051 Test Loss: 0.17659958949485144\n",
      "Epoch: 2 Train Loss: 0.16259298351109028 Test Loss: 0.16921439793663093\n",
      "Epoch: 3 Train Loss: 0.1581154645115137 Test Loss: 0.15986903680089753\n",
      "Epoch: 4 Train Loss: 0.1575982001900673 Test Loss: 0.15679583023079097\n",
      "Epoch: 5 Train Loss: 0.15884768582805991 Test Loss: 0.16305857774512933\n",
      "Epoch: 6 Train Loss: 0.15816543142795564 Test Loss: 0.16650730337554845\n",
      "Epoch: 7 Train Loss: 0.15735788740664722 Test Loss: 0.16579738013541545\n",
      "Epoch: 8 Train Loss: 0.15997624900639057 Test Loss: 0.16509261935616074\n",
      "Epoch: 9 Train Loss: 0.15857051608115436 Test Loss: 0.1586714860099478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:58:12,407]\u001b[0m Trial 30 finished with value: 0.6577851790174855 and parameters: {'hidden_size': 52, 'num_layers': 3, 'lstm_dropout': 0.09382780131983451, 'fc_dropout': 0.27461571870455126, 'bidirectional': True, 'conv_dropout': 0.13525626689423934, 'out_channels': 25, 'lr': 0.02030250656983206}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1564827198565006 Test Loss: 0.1546245374487707\n",
      "Epoch: 1 Train Loss: 0.15602168253809215 Test Loss: 0.14206390326824814\n",
      "Epoch: 2 Train Loss: 0.1332245696902275 Test Loss: 0.13809038958134362\n",
      "Epoch: 3 Train Loss: 0.13099397196993232 Test Loss: 0.13431368259409557\n",
      "Epoch: 4 Train Loss: 0.12891690012961626 Test Loss: 0.13575455229193828\n",
      "Epoch: 5 Train Loss: 0.12718666001856327 Test Loss: 0.1316988101175513\n",
      "Epoch: 6 Train Loss: 0.12502749700844287 Test Loss: 0.1348934386508724\n",
      "Epoch: 7 Train Loss: 0.12549493409395218 Test Loss: 0.13357633124358548\n",
      "Epoch: 8 Train Loss: 0.1236436023503542 Test Loss: 0.13311759265252768\n",
      "Epoch: 9 Train Loss: 0.1229708380356431 Test Loss: 0.13175060071598607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:59:15,463]\u001b[0m Trial 31 finished with value: 0.6891447368421052 and parameters: {'hidden_size': 66, 'num_layers': 1, 'lstm_dropout': 0.10100800779988583, 'fc_dropout': 0.09204050896358552, 'bidirectional': True, 'conv_dropout': 0.045635185328953706, 'out_channels': 10, 'lr': 0.00045315430658186633}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12199307271093131 Test Loss: 0.1374501477891264\n",
      "Epoch: 1 Train Loss: 0.1738129121720791 Test Loss: 0.16862176542137616\n",
      "Epoch: 2 Train Loss: 0.17456587106771768 Test Loss: 0.1584932251503102\n",
      "Epoch: 3 Train Loss: 0.16785554580725728 Test Loss: 0.15583965304893807\n",
      "Epoch: 4 Train Loss: 0.16921217703018337 Test Loss: 0.16402686777979897\n",
      "Epoch: 5 Train Loss: 0.16678031597696244 Test Loss: 0.14616197811814544\n",
      "Epoch: 6 Train Loss: 0.16266399093251677 Test Loss: 0.18396314844182624\n",
      "Epoch: 7 Train Loss: 0.16776230821621138 Test Loss: 0.14923097757985607\n",
      "Epoch: 8 Train Loss: 0.16218851348347962 Test Loss: 0.15233953181094825\n",
      "Epoch: 9 Train Loss: 0.15930881267562508 Test Loss: 0.19301585138317184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 13:59:49,949]\u001b[0m Trial 32 finished with value: 0.6743993371996685 and parameters: {'hidden_size': 51, 'num_layers': 1, 'lstm_dropout': 0.06467118805300293, 'fc_dropout': 0.14541672117916407, 'bidirectional': True, 'conv_dropout': 0.09109920083531871, 'out_channels': 11, 'lr': 0.0057091963562176905}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16419418988805265 Test Loss: 0.15795290057127848\n",
      "Epoch: 1 Train Loss: 0.1542055526316166 Test Loss: 0.1430171345012447\n",
      "Epoch: 2 Train Loss: 0.13636566203385592 Test Loss: 0.15335871438724927\n",
      "Epoch: 3 Train Loss: 0.13295421594008802 Test Loss: 0.13942376781885807\n",
      "Epoch: 4 Train Loss: 0.13048310358971357 Test Loss: 0.13927370055129354\n",
      "Epoch: 5 Train Loss: 0.1311948342844844 Test Loss: 0.13943203693975847\n",
      "Epoch: 6 Train Loss: 0.1282271944195032 Test Loss: 0.13577858214906324\n",
      "Epoch: 7 Train Loss: 0.12483789663761855 Test Loss: 0.13680949624770652\n",
      "Epoch: 8 Train Loss: 0.1257642529733479 Test Loss: 0.14339750629073134\n",
      "Epoch: 9 Train Loss: 0.12560457315891982 Test Loss: 0.1350823265318863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:00:31,154]\u001b[0m Trial 33 finished with value: 0.6959297685554668 and parameters: {'hidden_size': 115, 'num_layers': 1, 'lstm_dropout': 0.1537461110102326, 'fc_dropout': 0.2063138157295346, 'bidirectional': True, 'conv_dropout': 0.034148452529885895, 'out_channels': 8, 'lr': 0.0005297892843404469}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12469685189574957 Test Loss: 0.13746106410071776\n",
      "Epoch: 1 Train Loss: 0.2126999075144995 Test Loss: 0.16030079190628216\n",
      "Epoch: 2 Train Loss: 0.2114743033720646 Test Loss: 0.16792710545582892\n",
      "Epoch: 3 Train Loss: 0.2028483704881277 Test Loss: 0.40196946716435467\n",
      "Epoch: 4 Train Loss: 0.19438955009304917 Test Loss: 0.1911142166903296\n",
      "Epoch: 5 Train Loss: 0.19439159865798428 Test Loss: 0.1719269336829075\n",
      "Epoch: 6 Train Loss: 0.19463355396166443 Test Loss: 0.17761712640928576\n",
      "Epoch: 7 Train Loss: 0.2016862755205482 Test Loss: 0.16395575525209355\n",
      "Epoch: 8 Train Loss: 0.19863856548210607 Test Loss: 0.20006759674213945\n",
      "Epoch: 9 Train Loss: 0.19733105899179354 Test Loss: 0.21890858873076285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:01:10,534]\u001b[0m Trial 34 finished with value: 0.6691616766467066 and parameters: {'hidden_size': 111, 'num_layers': 1, 'lstm_dropout': 0.14144613468291306, 'fc_dropout': 0.20896094632081139, 'bidirectional': True, 'conv_dropout': 0.07364057091378429, 'out_channels': 8, 'lr': 0.009986691067990017}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.19272323625697754 Test Loss: 0.16432654898697005\n",
      "Epoch: 1 Train Loss: 0.20918307926803828 Test Loss: 0.18090134868606592\n",
      "Epoch: 2 Train Loss: 0.20014348336472176 Test Loss: 0.24462495758510627\n",
      "Epoch: 3 Train Loss: 0.19373604780621825 Test Loss: 0.17973575031997774\n",
      "Epoch: 4 Train Loss: 0.18170957976374774 Test Loss: 0.19413878754400216\n",
      "Epoch: 5 Train Loss: 0.19617508711740375 Test Loss: 0.17666107599441996\n",
      "Epoch: 6 Train Loss: 0.19504938853271306 Test Loss: 0.22807608728710646\n",
      "Epoch: 7 Train Loss: 0.19720534320585428 Test Loss: 0.17952971608666612\n",
      "Epoch: 8 Train Loss: 0.18784811552437022 Test Loss: 0.1694118838412122\n",
      "Epoch: 9 Train Loss: 0.19051700984332712 Test Loss: 0.16277105094620975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:02:02,190]\u001b[0m Trial 35 finished with value: 0.6457627118644067 and parameters: {'hidden_size': 123, 'num_layers': 1, 'lstm_dropout': 0.048358382528968215, 'fc_dropout': 0.17309918556440418, 'bidirectional': True, 'conv_dropout': 0.020703337294141585, 'out_channels': 3, 'lr': 0.015679365402680324}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1913643617888447 Test Loss: 0.1854366915101132\n",
      "Epoch: 1 Train Loss: 0.1737758979521692 Test Loss: 0.17963338702821885\n",
      "Epoch: 2 Train Loss: 0.15272603137046098 Test Loss: 0.15152480838873897\n",
      "Epoch: 3 Train Loss: 0.151147291444242 Test Loss: 0.16830600842167012\n",
      "Epoch: 4 Train Loss: 0.15660405382215978 Test Loss: 0.15884775001579485\n",
      "Epoch: 5 Train Loss: 0.15212320975363255 Test Loss: 0.1505184762251263\n",
      "Epoch: 6 Train Loss: 0.14886191010475158 Test Loss: 0.1552265094646726\n",
      "Epoch: 7 Train Loss: 0.1463175395652652 Test Loss: 0.15662278205501481\n",
      "Epoch: 8 Train Loss: 0.15036603950411082 Test Loss: 0.15449363175934305\n",
      "Epoch: 9 Train Loss: 0.14651269116699694 Test Loss: 0.14615092855601455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:03:09,804]\u001b[0m Trial 36 finished with value: 0.662251655629139 and parameters: {'hidden_size': 88, 'num_layers': 3, 'lstm_dropout': 0.1802868389922722, 'fc_dropout': 0.1932110437780881, 'bidirectional': False, 'conv_dropout': 0.05985133361749816, 'out_channels': 19, 'lr': 0.0072476961639971966}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14569325554817916 Test Loss: 0.1571910115934837\n",
      "Epoch: 1 Train Loss: 0.1970832805620972 Test Loss: 0.17367251654462026\n",
      "Epoch: 2 Train Loss: 0.1868576429558918 Test Loss: 0.17506707738638638\n",
      "Epoch: 3 Train Loss: 0.18120546695669182 Test Loss: 0.15790523439288712\n",
      "Epoch: 4 Train Loss: 0.1731945006594062 Test Loss: 0.19336394173057433\n",
      "Epoch: 5 Train Loss: 0.19769507925638463 Test Loss: 0.2182453697545085\n",
      "Epoch: 6 Train Loss: 0.18543256268743424 Test Loss: 0.15228616282605706\n",
      "Epoch: 7 Train Loss: 0.1733182067193091 Test Loss: 0.16791013698465526\n",
      "Epoch: 8 Train Loss: 0.1682892060637474 Test Loss: 0.1647057223696107\n",
      "Epoch: 9 Train Loss: 0.16326218674331902 Test Loss: 0.1637550721736476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:04:12,174]\u001b[0m Trial 37 finished with value: 0.6666666666666667 and parameters: {'hidden_size': 148, 'num_layers': 1, 'lstm_dropout': 0.03373579573953274, 'fc_dropout': 0.13165067953642204, 'bidirectional': True, 'conv_dropout': 0.0291495330846214, 'out_channels': 7, 'lr': 0.007437941014875075}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1722490582536906 Test Loss: 0.15919841202898338\n",
      "Epoch: 1 Train Loss: 0.1588824094891548 Test Loss: 0.1432076166964139\n",
      "Epoch: 2 Train Loss: 0.13580520154088735 Test Loss: 0.139025783511444\n",
      "Epoch: 3 Train Loss: 0.1324023044705391 Test Loss: 0.13817386372020832\n",
      "Epoch: 4 Train Loss: 0.12917428943067788 Test Loss: 0.13646445179971073\n",
      "Epoch: 5 Train Loss: 0.1280297268792987 Test Loss: 0.1347113668995972\n",
      "Epoch: 6 Train Loss: 0.1260992558449507 Test Loss: 0.13202694561272954\n",
      "Epoch: 7 Train Loss: 0.12454628554433585 Test Loss: 0.1333204482119685\n",
      "Epoch: 8 Train Loss: 0.12302061172276735 Test Loss: 0.1328632604009427\n",
      "Epoch: 9 Train Loss: 0.1225674425676465 Test Loss: 0.13114826726361203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:05:05,640]\u001b[0m Trial 38 finished with value: 0.6883645240032547 and parameters: {'hidden_size': 105, 'num_layers': 1, 'lstm_dropout': 0.08264044742132443, 'fc_dropout': 0.16717029485230334, 'bidirectional': False, 'conv_dropout': 0.10403908418752351, 'out_channels': 12, 'lr': 0.00019486508126606025}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12176775477081538 Test Loss: 0.1371473244186074\n",
      "Epoch: 1 Train Loss: 0.2469706747194749 Test Loss: 0.16082975933679378\n",
      "Epoch: 2 Train Loss: 0.16676292918901892 Test Loss: 0.19715610689397295\n",
      "Epoch: 3 Train Loss: 0.16258900209739804 Test Loss: 0.1578211436470667\n",
      "Epoch: 4 Train Loss: 0.16793254348002373 Test Loss: 0.2767241543525988\n",
      "Epoch: 5 Train Loss: 0.1681974927822128 Test Loss: 0.17873173500574863\n",
      "Epoch: 6 Train Loss: 0.16095997956749053 Test Loss: 0.16207037633731247\n",
      "Epoch: 7 Train Loss: 0.1724143814727664 Test Loss: 0.16522490027280282\n",
      "Epoch: 8 Train Loss: 0.16888462228178977 Test Loss: 0.18952987078851025\n",
      "Epoch: 9 Train Loss: 0.18292769954018295 Test Loss: 0.16825487299230152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:06:53,114]\u001b[0m Trial 39 finished with value: 0.6514382402707277 and parameters: {'hidden_size': 182, 'num_layers': 2, 'lstm_dropout': 0.21710266502537426, 'fc_dropout': 0.20824923911428012, 'bidirectional': True, 'conv_dropout': 0.07050073008761225, 'out_channels': 14, 'lr': 0.013480781598933381}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17415776475407183 Test Loss: 0.1622114655094596\n",
      "Epoch: 1 Train Loss: 0.20024338682591916 Test Loss: 0.17736105343547112\n",
      "Epoch: 2 Train Loss: 0.17431169478073716 Test Loss: 0.16928793042422102\n",
      "Epoch: 3 Train Loss: 0.17476743473559617 Test Loss: 0.1645724321016298\n",
      "Epoch: 4 Train Loss: 0.17384682096540927 Test Loss: 0.18618016144314323\n",
      "Epoch: 5 Train Loss: 0.16807072364389897 Test Loss: 0.1601469002771206\n",
      "Epoch: 6 Train Loss: 0.17834413125813006 Test Loss: 0.17640618806163344\n",
      "Epoch: 7 Train Loss: 0.17614043204188348 Test Loss: 0.16273676854567215\n",
      "Epoch: 8 Train Loss: 0.1992932900980115 Test Loss: 0.16737919334119883\n",
      "Epoch: 9 Train Loss: 0.17928554247319697 Test Loss: 0.1802800497926843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:08:03,083]\u001b[0m Trial 40 finished with value: 0.6300000000000001 and parameters: {'hidden_size': 138, 'num_layers': 3, 'lstm_dropout': 0.13518665933001564, 'fc_dropout': 0.2549066243637193, 'bidirectional': False, 'conv_dropout': 0.1592182895089455, 'out_channels': 8, 'lr': 0.023612314325709163}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16641963539719581 Test Loss: 0.16659407525326306\n",
      "Epoch: 1 Train Loss: 0.15960040453672408 Test Loss: 0.1470835819638099\n",
      "Epoch: 2 Train Loss: 0.13570921949595213 Test Loss: 0.1392281510638067\n",
      "Epoch: 3 Train Loss: 0.13142383257597684 Test Loss: 0.13435124470807683\n",
      "Epoch: 4 Train Loss: 0.12809501944333315 Test Loss: 0.13579460373594643\n",
      "Epoch: 5 Train Loss: 0.12587451232820748 Test Loss: 0.13431232569578547\n",
      "Epoch: 6 Train Loss: 0.1227175409823656 Test Loss: 0.13279337396386998\n",
      "Epoch: 7 Train Loss: 0.12128696206212043 Test Loss: 0.1312372714292984\n",
      "Epoch: 8 Train Loss: 0.12116892536580563 Test Loss: 0.136498618621034\n",
      "Epoch: 9 Train Loss: 0.11916500272303819 Test Loss: 0.1329087683835778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:09:06,143]\u001b[0m Trial 41 finished with value: 0.6978193146417446 and parameters: {'hidden_size': 62, 'num_layers': 1, 'lstm_dropout': 0.10811056560826122, 'fc_dropout': 0.11355341841003412, 'bidirectional': True, 'conv_dropout': 0.0427267766888177, 'out_channels': 10, 'lr': 0.0002783562915090092}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11929832518696785 Test Loss: 0.12970104655280662\n",
      "Epoch: 1 Train Loss: 0.1714303750887513 Test Loss: 0.1861017319067313\n",
      "Epoch: 2 Train Loss: 0.1724843404965475 Test Loss: 0.1721266678715952\n",
      "Epoch: 3 Train Loss: 0.16683686522729696 Test Loss: 0.17217260192538175\n",
      "Epoch: 4 Train Loss: 0.16721806569378822 Test Loss: 0.16293808032934087\n",
      "Epoch: 5 Train Loss: 0.17119425873681904 Test Loss: 0.16716146154162553\n",
      "Epoch: 6 Train Loss: 0.1702007767394185 Test Loss: 0.15257937456674564\n",
      "Epoch: 7 Train Loss: 0.16366273853369057 Test Loss: 0.17416679187151143\n",
      "Epoch: 8 Train Loss: 0.1561879559226334 Test Loss: 0.1555109548563965\n",
      "Epoch: 9 Train Loss: 0.15736325299907475 Test Loss: 0.15381914871735886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:10:08,383]\u001b[0m Trial 42 finished with value: 0.6768734891216761 and parameters: {'hidden_size': 84, 'num_layers': 1, 'lstm_dropout': 0.10632514568000236, 'fc_dropout': 0.1532556254386544, 'bidirectional': True, 'conv_dropout': 0.017578839839133376, 'out_channels': 6, 'lr': 0.0058454653312892835}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16085957068894058 Test Loss: 0.15421570079347577\n",
      "Epoch: 1 Train Loss: 0.19753085986198857 Test Loss: 0.18203065061447815\n",
      "Epoch: 2 Train Loss: 0.18513195896521212 Test Loss: 0.157453594657893\n",
      "Epoch: 3 Train Loss: 0.19125687920972706 Test Loss: 0.2110605975538611\n",
      "Epoch: 4 Train Loss: 0.19037740750461818 Test Loss: 0.1620891880089292\n",
      "Epoch: 5 Train Loss: 0.1923440211989917 Test Loss: 0.20046496675453915\n",
      "Epoch: 6 Train Loss: 0.18628958594631403 Test Loss: 0.22938058889186838\n",
      "Epoch: 7 Train Loss: 0.19587316083265469 Test Loss: 0.19575025940450808\n",
      "Epoch: 8 Train Loss: 0.1974190348718781 Test Loss: 0.21206498964758108\n",
      "Epoch: 9 Train Loss: 0.18822605595858768 Test Loss: 0.20783002698606554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:11:02,089]\u001b[0m Trial 43 finished with value: 0.6513105639396345 and parameters: {'hidden_size': 64, 'num_layers': 1, 'lstm_dropout': 0.1555478298499872, 'fc_dropout': 0.12938828998656443, 'bidirectional': True, 'conv_dropout': 0.0486197657540131, 'out_channels': 10, 'lr': 0.013014515888170954}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1903341791793937 Test Loss: 0.1953622716904496\n",
      "Epoch: 1 Train Loss: 0.16049062215685844 Test Loss: 0.14266655373330506\n",
      "Epoch: 2 Train Loss: 0.13659453626722098 Test Loss: 0.1435751171139911\n",
      "Epoch: 3 Train Loss: 0.13192071188241244 Test Loss: 0.1358697182668474\n",
      "Epoch: 4 Train Loss: 0.12961318286061288 Test Loss: 0.13758742170759475\n",
      "Epoch: 5 Train Loss: 0.1250558258190751 Test Loss: 0.13472635830981664\n",
      "Epoch: 6 Train Loss: 0.12447084480673075 Test Loss: 0.13270895264316768\n",
      "Epoch: 7 Train Loss: 0.12137866113036871 Test Loss: 0.12997092398853538\n",
      "Epoch: 8 Train Loss: 0.12018456474393606 Test Loss: 0.13423236716574374\n",
      "Epoch: 9 Train Loss: 0.11807580300718545 Test Loss: 0.13190942308225762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:12:05,578]\u001b[0m Trial 44 finished with value: 0.6988727858293076 and parameters: {'hidden_size': 40, 'num_layers': 1, 'lstm_dropout': 0.05883675422116798, 'fc_dropout': 0.21348947483608194, 'bidirectional': True, 'conv_dropout': 0.0015301484046831323, 'out_channels': 12, 'lr': 0.0003342170505202173}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11718998062163591 Test Loss: 0.13170397817231597\n",
      "Epoch: 1 Train Loss: 0.21636209239661694 Test Loss: 0.17435498582645537\n",
      "Epoch: 2 Train Loss: 0.1901055554622086 Test Loss: 0.17708317176126442\n",
      "Epoch: 3 Train Loss: 0.21630473457900806 Test Loss: 0.17911391406016539\n",
      "Epoch: 4 Train Loss: 0.19790208299396328 Test Loss: 0.1741180014127074\n",
      "Epoch: 5 Train Loss: 0.20419033241624712 Test Loss: 0.2363845241449836\n",
      "Epoch: 6 Train Loss: 0.19449307934173848 Test Loss: 0.21363435749904797\n",
      "Epoch: 7 Train Loss: 0.18822601938364095 Test Loss: 0.16573505543065242\n",
      "Epoch: 8 Train Loss: 0.1992189092951361 Test Loss: 0.20684943976960837\n",
      "Epoch: 9 Train Loss: 0.20447055367766878 Test Loss: 0.21609433888221166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:13:11,723]\u001b[0m Trial 45 finished with value: 0.6734854445318648 and parameters: {'hidden_size': 126, 'num_layers': 1, 'lstm_dropout': 0.021723806117469192, 'fc_dropout': 0.2289265857341266, 'bidirectional': True, 'conv_dropout': 0.002280864898635715, 'out_channels': 15, 'lr': 0.006968986266511008}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.207402601903677 Test Loss: 0.1584588607130483\n",
      "Epoch: 1 Train Loss: 0.18327556091099978 Test Loss: 0.27975589491407604\n",
      "Epoch: 2 Train Loss: 0.17540414917729796 Test Loss: 0.17695019980922294\n",
      "Epoch: 3 Train Loss: 0.17036917236447335 Test Loss: 0.15501263773086638\n",
      "Epoch: 4 Train Loss: 0.16754326970530675 Test Loss: 0.16576480263986956\n",
      "Epoch: 5 Train Loss: 0.16210755578055977 Test Loss: 0.160325626958721\n",
      "Epoch: 6 Train Loss: 0.16164449746645987 Test Loss: 0.15132773691080154\n",
      "Epoch: 7 Train Loss: 0.16531367131359875 Test Loss: 0.16474488479927324\n",
      "Epoch: 8 Train Loss: 0.16215852976292372 Test Loss: 0.17958227104653185\n",
      "Epoch: 9 Train Loss: 0.15423387342840433 Test Loss: 0.15272394210969012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:14:15,857]\u001b[0m Trial 46 finished with value: 0.6816770186335404 and parameters: {'hidden_size': 51, 'num_layers': 1, 'lstm_dropout': 0.06093712691965927, 'fc_dropout': 0.20729020562879794, 'bidirectional': True, 'conv_dropout': 0.021975570108410412, 'out_channels': 18, 'lr': 0.005504796587127469}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1634874210909009 Test Loss: 0.14783267213251836\n",
      "Epoch: 1 Train Loss: 0.24980945785747463 Test Loss: 0.26083214451579717\n",
      "Epoch: 2 Train Loss: 0.23638223550477996 Test Loss: 0.39567435482522834\n",
      "Epoch: 3 Train Loss: 0.23660785807443316 Test Loss: 0.34260969770515853\n",
      "Epoch: 4 Train Loss: 0.20727693256102503 Test Loss: 0.17489327695637275\n",
      "Epoch: 5 Train Loss: 0.19048562489878387 Test Loss: 0.17755286027186404\n",
      "Epoch: 6 Train Loss: 0.18341280187889933 Test Loss: 0.18821564340255797\n",
      "Epoch: 7 Train Loss: 0.19400358317941427 Test Loss: 0.17842696979641914\n",
      "Epoch: 8 Train Loss: 0.20114823117306513 Test Loss: 0.1745727468734256\n",
      "Epoch: 9 Train Loss: 0.18824241545579862 Test Loss: 0.17338320406112143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:15:15,432]\u001b[0m Trial 47 finished with value: 0.6365105008077544 and parameters: {'hidden_size': 43, 'num_layers': 1, 'lstm_dropout': 0.0034902787158184456, 'fc_dropout': 0.025727768734243928, 'bidirectional': False, 'conv_dropout': 0.08287220889910969, 'out_channels': 11, 'lr': 0.030396506217536676}. Best is trial 12 with value: 0.6994535519125684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.2118179223178886 Test Loss: 0.22886299561209286\n",
      "Epoch: 1 Train Loss: 0.15542344028800725 Test Loss: 0.14317319936121994\n",
      "Epoch: 2 Train Loss: 0.1348070671290159 Test Loss: 0.1384903408896428\n",
      "Epoch: 3 Train Loss: 0.12900047628879546 Test Loss: 0.13838876820743656\n",
      "Epoch: 4 Train Loss: 0.12506675837785006 Test Loss: 0.13491786362978217\n",
      "Epoch: 5 Train Loss: 0.12248766658306122 Test Loss: 0.13113149245992636\n",
      "Epoch: 6 Train Loss: 0.11947204248011112 Test Loss: 0.14193090097829938\n",
      "Epoch: 7 Train Loss: 0.1181411380060017 Test Loss: 0.1318454971423926\n",
      "Epoch: 8 Train Loss: 0.1152567589789629 Test Loss: 0.13090041079246006\n",
      "Epoch: 9 Train Loss: 0.11157393761873245 Test Loss: 0.13185252534291045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:16:21,326]\u001b[0m Trial 48 finished with value: 0.7091875474563402 and parameters: {'hidden_size': 100, 'num_layers': 1, 'lstm_dropout': 0.037362422729387564, 'fc_dropout': 0.056950385586254704, 'bidirectional': True, 'conv_dropout': 0.03382773386464591, 'out_channels': 23, 'lr': 0.00017556097900833128}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.111707907114923 Test Loss: 0.13035070510527577\n",
      "Epoch: 1 Train Loss: 0.23831187350410618 Test Loss: 0.2592879477105425\n",
      "Epoch: 2 Train Loss: 0.23397803016761318 Test Loss: 0.3685148997546974\n",
      "Epoch: 3 Train Loss: 0.21632198498854413 Test Loss: 0.19127114524487585\n",
      "Epoch: 4 Train Loss: 0.262705092580324 Test Loss: 0.20287870097393618\n",
      "Epoch: 5 Train Loss: 0.20845931393057107 Test Loss: 0.23571833444479556\n",
      "Epoch: 6 Train Loss: 0.24790320068463553 Test Loss: 0.1798744157028084\n",
      "Epoch: 7 Train Loss: 0.2547841802783896 Test Loss: 0.29133259382062837\n",
      "Epoch: 8 Train Loss: 0.217645773834351 Test Loss: 0.1599188056348945\n",
      "Epoch: 9 Train Loss: 0.19780025022653863 Test Loss: 0.16824643623333768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:17:27,551]\u001b[0m Trial 49 finished with value: 0.6704918032786885 and parameters: {'hidden_size': 43, 'num_layers': 1, 'lstm_dropout': 0.03599986211333242, 'fc_dropout': 0.05314580800486, 'bidirectional': True, 'conv_dropout': 0.11788980991694087, 'out_channels': 23, 'lr': 0.01542671774517653}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.21375531178836246 Test Loss: 0.179010903629394\n",
      "Epoch: 1 Train Loss: 0.31139570134194017 Test Loss: 0.2125261980123794\n",
      "Epoch: 2 Train Loss: 0.2583489171931869 Test Loss: 0.3794318632940405\n",
      "Epoch: 3 Train Loss: 0.25103977435033886 Test Loss: 0.3063697020759707\n",
      "Epoch: 4 Train Loss: 0.25578026795739134 Test Loss: 0.77200695977882\n",
      "Epoch: 5 Train Loss: 0.2787263768368762 Test Loss: 0.23597674733143115\n",
      "Epoch: 6 Train Loss: 0.22349949574370984 Test Loss: 0.20401393257143993\n",
      "Epoch: 7 Train Loss: 0.2073521891250275 Test Loss: 0.20970928342864156\n",
      "Epoch: 8 Train Loss: 0.2289904410063318 Test Loss: 0.19816279027480097\n",
      "Epoch: 9 Train Loss: 0.24289247517539697 Test Loss: 0.2981897939959676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:18:34,597]\u001b[0m Trial 50 finished with value: 0.6598984771573604 and parameters: {'hidden_size': 103, 'num_layers': 1, 'lstm_dropout': 0.025497038219021537, 'fc_dropout': 0.0048964087531565975, 'bidirectional': True, 'conv_dropout': 0.002217748376646074, 'out_channels': 30, 'lr': 0.01136033723682575}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.25999681972283145 Test Loss: 0.2109825529672128\n",
      "Epoch: 1 Train Loss: 0.18634102653888984 Test Loss: 0.1647166554182292\n",
      "Epoch: 2 Train Loss: 0.1664610608831048 Test Loss: 0.16440578584615795\n",
      "Epoch: 3 Train Loss: 0.16504613695219159 Test Loss: 0.17574721942402827\n",
      "Epoch: 4 Train Loss: 0.16085341311842202 Test Loss: 0.16455899574124394\n",
      "Epoch: 5 Train Loss: 0.16741550135519356 Test Loss: 0.161659847933073\n",
      "Epoch: 6 Train Loss: 0.15705706804888322 Test Loss: 0.15513517570119506\n",
      "Epoch: 7 Train Loss: 0.1671804889932275 Test Loss: 0.16828866149432742\n",
      "Epoch: 8 Train Loss: 0.16078212311454118 Test Loss: 0.15332861631787337\n",
      "Epoch: 9 Train Loss: 0.16669153689015656 Test Loss: 0.2350246488732604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:19:35,519]\u001b[0m Trial 51 finished with value: 0.6715092816787732 and parameters: {'hidden_size': 88, 'num_layers': 1, 'lstm_dropout': 0.07668479402144668, 'fc_dropout': 0.07252890107935692, 'bidirectional': True, 'conv_dropout': 0.035908967255813884, 'out_channels': 28, 'lr': 0.004173213615759597}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16800869567301124 Test Loss: 0.16978562418252421\n",
      "Epoch: 1 Train Loss: 0.18211945650313574 Test Loss: 0.23073707908461133\n",
      "Epoch: 2 Train Loss: 0.17217397440187632 Test Loss: 0.15348313057336943\n",
      "Epoch: 3 Train Loss: 0.16641776295676827 Test Loss: 0.15716946679063307\n",
      "Epoch: 4 Train Loss: 0.16113154225349427 Test Loss: 0.17420451030486261\n",
      "Epoch: 5 Train Loss: 0.16183262379597874 Test Loss: 0.16699632590475935\n",
      "Epoch: 6 Train Loss: 0.15560361354760827 Test Loss: 0.15361866656060036\n",
      "Epoch: 7 Train Loss: 0.16814266648944468 Test Loss: 0.16656473375404604\n",
      "Epoch: 8 Train Loss: 0.16684565141156782 Test Loss: 0.15146344333006362\n",
      "Epoch: 9 Train Loss: 0.1649172426963225 Test Loss: 0.1907250328947561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:20:41,789]\u001b[0m Trial 52 finished with value: 0.6810207336523126 and parameters: {'hidden_size': 113, 'num_layers': 1, 'lstm_dropout': 0.05816627696588419, 'fc_dropout': 0.1095059479345291, 'bidirectional': True, 'conv_dropout': 0.023554703487564017, 'out_channels': 21, 'lr': 0.003989557625387199}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1666823940918781 Test Loss: 0.1686151216011911\n",
      "Epoch: 1 Train Loss: 0.2033560234746663 Test Loss: 0.2605487880770849\n",
      "Epoch: 2 Train Loss: 0.20807139484933576 Test Loss: 0.22997667261967644\n",
      "Epoch: 3 Train Loss: 0.1923287599522737 Test Loss: 0.1742854046340758\n",
      "Epoch: 4 Train Loss: 0.182628874234017 Test Loss: 0.19136631331695153\n",
      "Epoch: 5 Train Loss: 0.20258059906349518 Test Loss: 0.20112477600821457\n",
      "Epoch: 6 Train Loss: 0.1844666042807512 Test Loss: 0.24392753010693813\n",
      "Epoch: 7 Train Loss: 0.1925358294150792 Test Loss: 0.6913246141011951\n",
      "Epoch: 8 Train Loss: 0.20372116413214245 Test Loss: 0.1644339520400896\n",
      "Epoch: 9 Train Loss: 0.223416728102896 Test Loss: 0.19749959200001754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:21:42,515]\u001b[0m Trial 53 finished with value: 0.6717325227963526 and parameters: {'hidden_size': 71, 'num_layers': 1, 'lstm_dropout': 0.11821265589962815, 'fc_dropout': 0.04756469004498254, 'bidirectional': True, 'conv_dropout': 0.06776024067959562, 'out_channels': 23, 'lr': 0.00890507368005113}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.20284295043573947 Test Loss: 0.23939390857287418\n",
      "Epoch: 1 Train Loss: 0.15121411763578654 Test Loss: 0.1427869412202995\n",
      "Epoch: 2 Train Loss: 0.1359630226880312 Test Loss: 0.13796227217053833\n",
      "Epoch: 3 Train Loss: 0.13360625649914146 Test Loss: 0.13594473971012302\n",
      "Epoch: 4 Train Loss: 0.12867217392772437 Test Loss: 0.14354681427004382\n",
      "Epoch: 5 Train Loss: 0.1269794097915292 Test Loss: 0.1412556037580529\n",
      "Epoch: 6 Train Loss: 0.12775086909681557 Test Loss: 0.13874995158300898\n",
      "Epoch: 7 Train Loss: 0.12515840506106615 Test Loss: 0.13882908910459366\n",
      "Epoch: 8 Train Loss: 0.1253722312822938 Test Loss: 0.1355725930551418\n",
      "Epoch: 9 Train Loss: 0.12623767550438642 Test Loss: 0.13269510733695647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:22:42,437]\u001b[0m Trial 54 finished with value: 0.7016491754122939 and parameters: {'hidden_size': 79, 'num_layers': 1, 'lstm_dropout': 0.08797188722571098, 'fc_dropout': 0.06632523319719898, 'bidirectional': True, 'conv_dropout': 0.044753511967291215, 'out_channels': 17, 'lr': 0.0007088821271362437}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12327731590569019 Test Loss: 0.137484485649477\n",
      "Epoch: 1 Train Loss: 0.16800880868583917 Test Loss: 0.1421688758134366\n",
      "Epoch: 2 Train Loss: 0.1341697823062539 Test Loss: 0.14019407991307992\n",
      "Epoch: 3 Train Loss: 0.12967346688210965 Test Loss: 0.13533780952326405\n",
      "Epoch: 4 Train Loss: 0.12707902244329453 Test Loss: 0.13636774215668726\n",
      "Epoch: 5 Train Loss: 0.1234292676255107 Test Loss: 0.1396501958087539\n",
      "Epoch: 6 Train Loss: 0.12217244452908635 Test Loss: 0.12999972197027823\n",
      "Epoch: 7 Train Loss: 0.12025526726096869 Test Loss: 0.13177494407771304\n",
      "Epoch: 8 Train Loss: 0.12015936794131994 Test Loss: 0.13071614927270067\n",
      "Epoch: 9 Train Loss: 0.11818897730559111 Test Loss: 0.1315950416088009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:23:43,359]\u001b[0m Trial 55 finished with value: 0.6867862969004895 and parameters: {'hidden_size': 58, 'num_layers': 1, 'lstm_dropout': 0.023267519016975748, 'fc_dropout': 0.022765696544489858, 'bidirectional': True, 'conv_dropout': 0.04800657788300275, 'out_channels': 17, 'lr': 0.00011895887588777882}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11653794983923435 Test Loss: 0.1322904463601522\n",
      "Epoch: 1 Train Loss: 0.17039867988079788 Test Loss: 0.15099778316153314\n",
      "Epoch: 2 Train Loss: 0.15667551783490927 Test Loss: 0.17751271359045237\n",
      "Epoch: 3 Train Loss: 0.15170395269393921 Test Loss: 0.15411432121341792\n",
      "Epoch: 4 Train Loss: 0.1528153836708516 Test Loss: 0.15450725717077288\n",
      "Epoch: 5 Train Loss: 0.15758284421488641 Test Loss: 0.18179769539452803\n",
      "Epoch: 6 Train Loss: 0.1566323917625472 Test Loss: 0.16806626173492056\n",
      "Epoch: 7 Train Loss: 0.1525898652266711 Test Loss: 0.1573988163320068\n",
      "Epoch: 8 Train Loss: 0.1508750446356833 Test Loss: 0.15381676973566746\n",
      "Epoch: 9 Train Loss: 0.15155721245631576 Test Loss: 0.1544299004510188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:24:49,106]\u001b[0m Trial 56 finished with value: 0.6842923794712287 and parameters: {'hidden_size': 40, 'num_layers': 1, 'lstm_dropout': 0.08240810750530578, 'fc_dropout': 0.060949258871532117, 'bidirectional': True, 'conv_dropout': 0.0936248128270697, 'out_channels': 19, 'lr': 0.004170071282950627}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15560402856674047 Test Loss: 0.15793601265504434\n",
      "Epoch: 1 Train Loss: 0.18671072869310157 Test Loss: 0.23877248788303057\n",
      "Epoch: 2 Train Loss: 0.1753191801790148 Test Loss: 0.2010415803414945\n",
      "Epoch: 3 Train Loss: 0.1775035828318447 Test Loss: 0.16040307920152386\n",
      "Epoch: 4 Train Loss: 0.17181056917030366 Test Loss: 0.15116622243017053\n",
      "Epoch: 5 Train Loss: 0.17339269687188788 Test Loss: 0.15207210782403574\n",
      "Epoch: 6 Train Loss: 0.16646382879344745 Test Loss: 0.19009986683092536\n",
      "Epoch: 7 Train Loss: 0.175461730291578 Test Loss: 0.16315579267379385\n",
      "Epoch: 8 Train Loss: 0.1756607071120292 Test Loss: 0.16487027881756283\n",
      "Epoch: 9 Train Loss: 0.1646903489768505 Test Loss: 0.1614827529881328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:25:54,016]\u001b[0m Trial 57 finished with value: 0.6762048192771084 and parameters: {'hidden_size': 78, 'num_layers': 1, 'lstm_dropout': 0.05647069478284455, 'fc_dropout': 0.07697181932613387, 'bidirectional': False, 'conv_dropout': 0.017237545126794637, 'out_channels': 15, 'lr': 0.00954080200073512}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16689048543982207 Test Loss: 0.20297091873213888\n",
      "Epoch: 1 Train Loss: 0.49073008982431293 Test Loss: 0.30466679013006914\n",
      "Epoch: 2 Train Loss: 0.40351985474854735 Test Loss: 0.2556327085182541\n",
      "Epoch: 3 Train Loss: 0.41104867176856913 Test Loss: 0.5062418192218414\n",
      "Epoch: 4 Train Loss: 0.4728107340218949 Test Loss: 0.3365282024786519\n",
      "Epoch: 5 Train Loss: 0.41154151849506015 Test Loss: 0.42379741480483163\n",
      "Epoch: 6 Train Loss: 0.41382913346679745 Test Loss: 0.28691778047837485\n",
      "Epoch: 7 Train Loss: 0.4117219564006718 Test Loss: 0.5437911857259321\n",
      "Epoch: 8 Train Loss: 0.3633485769660488 Test Loss: 0.24919412605101451\n",
      "Epoch: 9 Train Loss: 0.3813856606526012 Test Loss: 0.660466732759528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:26:58,886]\u001b[0m Trial 58 finished with value: 0.6397984886649875 and parameters: {'hidden_size': 67, 'num_layers': 1, 'lstm_dropout': 0.004078666834722654, 'fc_dropout': 0.039804483155077605, 'bidirectional': True, 'conv_dropout': 0.062100778119311466, 'out_channels': 40, 'lr': 0.018444002807784295}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.3848995024272819 Test Loss: 0.3693468397496805\n",
      "Epoch: 1 Train Loss: 0.22056993262313043 Test Loss: 0.21686310935378694\n",
      "Epoch: 2 Train Loss: 0.20713737182002515 Test Loss: 0.16829813970699192\n",
      "Epoch: 3 Train Loss: 0.19996835246681002 Test Loss: 0.22504431660251376\n",
      "Epoch: 4 Train Loss: 0.2014623275184713 Test Loss: 0.19766831306514507\n",
      "Epoch: 5 Train Loss: 0.23951213949488884 Test Loss: 0.22335410171661513\n",
      "Epoch: 6 Train Loss: 0.2167455941784079 Test Loss: 0.46168240856332265\n",
      "Epoch: 7 Train Loss: 0.20754415865924675 Test Loss: 0.28245039725417315\n",
      "Epoch: 8 Train Loss: 0.19297858687248082 Test Loss: 0.19042573274580388\n",
      "Epoch: 9 Train Loss: 0.2195657475043321 Test Loss: 0.21079983186131468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:27:45,640]\u001b[0m Trial 59 finished with value: 0.6520640269587196 and parameters: {'hidden_size': 56, 'num_layers': 1, 'lstm_dropout': 0.038228867619664424, 'fc_dropout': 0.06384777690631266, 'bidirectional': True, 'conv_dropout': 0.07924574909263246, 'out_channels': 23, 'lr': 0.014337828007529628}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.19230507722664625 Test Loss: 0.18127890754812442\n",
      "Epoch: 1 Train Loss: 0.1694901973117143 Test Loss: 0.14755747608911876\n",
      "Epoch: 2 Train Loss: 0.1597518999164924 Test Loss: 0.15296267717184064\n",
      "Epoch: 3 Train Loss: 0.15885846082400532 Test Loss: 0.15954956510803475\n",
      "Epoch: 4 Train Loss: 0.15642307539507747 Test Loss: 0.180627185527753\n",
      "Epoch: 5 Train Loss: 0.1577974853489548 Test Loss: 0.15399913863537792\n",
      "Epoch: 6 Train Loss: 0.1610111794622615 Test Loss: 0.1523513289781424\n",
      "Epoch: 7 Train Loss: 0.15703701538406312 Test Loss: 0.16212979086284962\n",
      "Epoch: 8 Train Loss: 0.16065327055919915 Test Loss: 0.14535996689202305\n",
      "Epoch: 9 Train Loss: 0.15226290820389987 Test Loss: 0.14349165063101454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:28:25,639]\u001b[0m Trial 60 finished with value: 0.6948051948051949 and parameters: {'hidden_size': 90, 'num_layers': 1, 'lstm_dropout': 0.08857299382318426, 'fc_dropout': 0.10604155008519911, 'bidirectional': True, 'conv_dropout': 0.04856068298331105, 'out_channels': 12, 'lr': 0.003862778470808565}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15094231528639793 Test Loss: 0.1436436367325318\n",
      "Epoch: 1 Train Loss: 0.16211988181769849 Test Loss: 0.14397156775330963\n",
      "Epoch: 2 Train Loss: 0.13519894102811814 Test Loss: 0.1389808124615647\n",
      "Epoch: 3 Train Loss: 0.1302987176641822 Test Loss: 0.14887185797047692\n",
      "Epoch: 4 Train Loss: 0.12786724467128516 Test Loss: 0.13635140694915868\n",
      "Epoch: 5 Train Loss: 0.12510525828003882 Test Loss: 0.1361720732922038\n",
      "Epoch: 6 Train Loss: 0.12328081799298525 Test Loss: 0.13572703772626174\n",
      "Epoch: 7 Train Loss: 0.1217870699763298 Test Loss: 0.13258781533735914\n",
      "Epoch: 8 Train Loss: 0.11984387122243643 Test Loss: 0.13461112065877492\n",
      "Epoch: 9 Train Loss: 0.11774713869094848 Test Loss: 0.13511609004887815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:29:30,003]\u001b[0m Trial 61 finished with value: 0.6995230524642289 and parameters: {'hidden_size': 99, 'num_layers': 1, 'lstm_dropout': 0.07003511842189972, 'fc_dropout': 0.021397093571174544, 'bidirectional': True, 'conv_dropout': 0.03140576060567465, 'out_channels': 13, 'lr': 0.00014212320108194105}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1168957929044962 Test Loss: 0.13380517093494487\n",
      "Epoch: 1 Train Loss: 0.1682783435229212 Test Loss: 0.1524225235455476\n",
      "Epoch: 2 Train Loss: 0.15195371683668346 Test Loss: 0.14755061855866983\n",
      "Epoch: 3 Train Loss: 0.15498434743992984 Test Loss: 0.1687363556946238\n",
      "Epoch: 4 Train Loss: 0.1514857724471949 Test Loss: 0.1515637818521585\n",
      "Epoch: 5 Train Loss: 0.15469958292618394 Test Loss: 0.16186385195904646\n",
      "Epoch: 6 Train Loss: 0.1564391589961946 Test Loss: 0.14962527570954431\n",
      "Epoch: 7 Train Loss: 0.15351040578391403 Test Loss: 0.1627671549144311\n",
      "Epoch: 8 Train Loss: 0.15570627588517963 Test Loss: 0.16157865442168978\n",
      "Epoch: 9 Train Loss: 0.15261898613013328 Test Loss: 0.18093759312588995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:30:34,699]\u001b[0m Trial 62 finished with value: 0.6899841017488076 and parameters: {'hidden_size': 99, 'num_layers': 1, 'lstm_dropout': 0.06637438386186419, 'fc_dropout': 0.021689121479896798, 'bidirectional': True, 'conv_dropout': 0.016502632155269932, 'out_channels': 13, 'lr': 0.0035635186537327133}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1522472995536402 Test Loss: 0.14609894908655185\n",
      "Epoch: 1 Train Loss: 0.21086421793802873 Test Loss: 0.17201051894373026\n",
      "Epoch: 2 Train Loss: 0.18328654036857187 Test Loss: 0.1817947171223811\n",
      "Epoch: 3 Train Loss: 0.18954817961282097 Test Loss: 0.19864554022298977\n",
      "Epoch: 4 Train Loss: 0.22444303487960715 Test Loss: 0.17785944923246727\n",
      "Epoch: 5 Train Loss: 0.1943176068658242 Test Loss: 0.1747879970925875\n",
      "Epoch: 6 Train Loss: 0.1989425198268611 Test Loss: 0.16860197574947589\n",
      "Epoch: 7 Train Loss: 0.20343668019473551 Test Loss: 0.16540301692919038\n",
      "Epoch: 8 Train Loss: 0.21256583207491786 Test Loss: 0.16319391406334627\n",
      "Epoch: 9 Train Loss: 0.20407473000405799 Test Loss: 0.15802410138122286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:31:35,503]\u001b[0m Trial 63 finished with value: 0.6736334405144695 and parameters: {'hidden_size': 78, 'num_layers': 1, 'lstm_dropout': 0.018126100454590365, 'fc_dropout': 0.04533643373445782, 'bidirectional': True, 'conv_dropout': 0.0008456865699603376, 'out_channels': 16, 'lr': 0.009843462990600599}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.2014993758591707 Test Loss: 0.17071042582392693\n",
      "Epoch: 1 Train Loss: 0.1684092501938343 Test Loss: 0.14272607711200325\n",
      "Epoch: 2 Train Loss: 0.1349261442810297 Test Loss: 0.13956394457160093\n",
      "Epoch: 3 Train Loss: 0.1312212095454335 Test Loss: 0.13763115911211926\n",
      "Epoch: 4 Train Loss: 0.12716710032224654 Test Loss: 0.13894521390882353\n",
      "Epoch: 5 Train Loss: 0.12506518332511188 Test Loss: 0.1335398840387694\n",
      "Epoch: 6 Train Loss: 0.12292360554486513 Test Loss: 0.1316434237719201\n",
      "Epoch: 7 Train Loss: 0.1203620148435235 Test Loss: 0.1301498561621474\n",
      "Epoch: 8 Train Loss: 0.11922979839295149 Test Loss: 0.1313949081862268\n",
      "Epoch: 9 Train Loss: 0.11796035305708646 Test Loss: 0.13061010628676833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:32:37,751]\u001b[0m Trial 64 finished with value: 0.7003952569169961 and parameters: {'hidden_size': 40, 'num_layers': 1, 'lstm_dropout': 0.04249190089995984, 'fc_dropout': 0.011930553466763362, 'bidirectional': True, 'conv_dropout': 0.04816149120818433, 'out_channels': 36, 'lr': 0.00011476929205387238}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11610273954570294 Test Loss: 0.1283231454666335\n",
      "Epoch: 1 Train Loss: 0.19324072828860953 Test Loss: 0.16651668897071203\n",
      "Epoch: 2 Train Loss: 0.17388073721099645 Test Loss: 0.16391525451486674\n",
      "Epoch: 3 Train Loss: 0.17064601090643555 Test Loss: 0.16078718043804263\n",
      "Epoch: 4 Train Loss: 0.17090269794827326 Test Loss: 0.15497568660912614\n",
      "Epoch: 5 Train Loss: 0.17586346912657028 Test Loss: 0.1538976916668419\n",
      "Epoch: 6 Train Loss: 0.1888449917394202 Test Loss: 0.16623428583847352\n",
      "Epoch: 7 Train Loss: 0.17684028010591865 Test Loss: 0.16982284051101335\n",
      "Epoch: 8 Train Loss: 0.16923198507828638 Test Loss: 0.15956437045755906\n",
      "Epoch: 9 Train Loss: 0.1625048151045339 Test Loss: 0.16059025767268226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:33:40,963]\u001b[0m Trial 65 finished with value: 0.6734375 and parameters: {'hidden_size': 35, 'num_layers': 1, 'lstm_dropout': 0.0738009210831901, 'fc_dropout': 0.016530730556141272, 'bidirectional': True, 'conv_dropout': 0.044676443261297036, 'out_channels': 31, 'lr': 0.007503989027907003}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15786744201667607 Test Loss: 0.14820370962992072\n",
      "Epoch: 1 Train Loss: 0.1702243300922215 Test Loss: 0.19228462835315602\n",
      "Epoch: 2 Train Loss: 0.15714967762865126 Test Loss: 0.22525422799790773\n",
      "Epoch: 3 Train Loss: 0.1578660945430398 Test Loss: 0.1548064882620074\n",
      "Epoch: 4 Train Loss: 0.15291491366773843 Test Loss: 0.14350184279615982\n",
      "Epoch: 5 Train Loss: 0.15316753979958594 Test Loss: 0.15372798591852188\n",
      "Epoch: 6 Train Loss: 0.14506401366889476 Test Loss: 0.14809539074453112\n",
      "Epoch: 7 Train Loss: 0.1507100721515715 Test Loss: 0.19449809731650777\n",
      "Epoch: 8 Train Loss: 0.14971822668090462 Test Loss: 0.14796630787356688\n",
      "Epoch: 9 Train Loss: 0.15284621623717248 Test Loss: 0.17440977398181162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:34:45,924]\u001b[0m Trial 66 finished with value: 0.6780185758513934 and parameters: {'hidden_size': 40, 'num_layers': 1, 'lstm_dropout': 0.11318500651044192, 'fc_dropout': 0.0017414991583690753, 'bidirectional': True, 'conv_dropout': 0.06958860708298781, 'out_channels': 34, 'lr': 0.0036734286507244785}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15934032371640205 Test Loss: 0.16220267483750328\n",
      "Epoch: 1 Train Loss: 0.23589521261015908 Test Loss: 0.259272941527758\n",
      "Epoch: 2 Train Loss: 0.24576428174115716 Test Loss: 0.23638575791884153\n",
      "Epoch: 3 Train Loss: 0.21798367644415703 Test Loss: 0.23564124324012356\n",
      "Epoch: 4 Train Loss: 0.21253079156773164 Test Loss: 0.2488434288696127\n",
      "Epoch: 5 Train Loss: 0.20255149616940907 Test Loss: 0.1725089032390414\n",
      "Epoch: 6 Train Loss: 0.19531452781883998 Test Loss: 0.20151853315032328\n",
      "Epoch: 7 Train Loss: 0.18869623247958953 Test Loss: 0.2275884893448345\n",
      "Epoch: 8 Train Loss: 0.17917015458783134 Test Loss: 0.1614108426026262\n",
      "Epoch: 9 Train Loss: 0.19738201498966665 Test Loss: 0.21861877740723804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:35:50,303]\u001b[0m Trial 67 finished with value: 0.6583747927031509 and parameters: {'hidden_size': 48, 'num_layers': 1, 'lstm_dropout': 0.0519282701747246, 'fc_dropout': 0.03424040780710423, 'bidirectional': True, 'conv_dropout': 0.09702898070569578, 'out_channels': 35, 'lr': 0.01179063390204735}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.19325562321650797 Test Loss: 0.19866484151290248\n",
      "Epoch: 1 Train Loss: 0.16739569063819945 Test Loss: 0.17903636375400492\n",
      "Epoch: 2 Train Loss: 0.15596476020216943 Test Loss: 0.17772251677389939\n",
      "Epoch: 3 Train Loss: 0.15655640104133636 Test Loss: 0.1537635468107205\n",
      "Epoch: 4 Train Loss: 0.1611053281337023 Test Loss: 0.2555558917859492\n",
      "Epoch: 5 Train Loss: 0.14920697086174042 Test Loss: 0.1704871735383813\n",
      "Epoch: 6 Train Loss: 0.16115580693110823 Test Loss: 0.1718771225109268\n",
      "Epoch: 7 Train Loss: 0.15147707369849087 Test Loss: 0.14488516095430612\n",
      "Epoch: 8 Train Loss: 0.1600626418784261 Test Loss: 0.15791774877665427\n",
      "Epoch: 9 Train Loss: 0.1642667284213472 Test Loss: 0.20890556355940548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:36:54,898]\u001b[0m Trial 68 finished with value: 0.6633663366336634 and parameters: {'hidden_size': 65, 'num_layers': 1, 'lstm_dropout': 0.09560856670976793, 'fc_dropout': 0.01312593162051471, 'bidirectional': True, 'conv_dropout': 0.017315730495168994, 'out_channels': 38, 'lr': 0.002721900522263709}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1587651680536568 Test Loss: 0.18451561125519034\n",
      "Epoch: 1 Train Loss: 0.15441416549682618 Test Loss: 0.1471813860923623\n",
      "Epoch: 2 Train Loss: 0.13360252549946308 Test Loss: 0.13681864346297215\n",
      "Epoch: 3 Train Loss: 0.12919607833772898 Test Loss: 0.13392034260193095\n",
      "Epoch: 4 Train Loss: 0.12663981803357602 Test Loss: 0.13444059897368899\n",
      "Epoch: 5 Train Loss: 0.12235702823400497 Test Loss: 0.14739099749551413\n",
      "Epoch: 6 Train Loss: 0.11951235379949213 Test Loss: 0.13335297238260221\n",
      "Epoch: 7 Train Loss: 0.1182077900737524 Test Loss: 0.13396093824182076\n",
      "Epoch: 8 Train Loss: 0.11450762137770652 Test Loss: 0.1332063161747191\n",
      "Epoch: 9 Train Loss: 0.11267369506806135 Test Loss: 0.13891786717461607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:38:09,575]\u001b[0m Trial 69 finished with value: 0.6905537459283387 and parameters: {'hidden_size': 223, 'num_layers': 1, 'lstm_dropout': 0.015964277989246576, 'fc_dropout': 0.05296256366040739, 'bidirectional': True, 'conv_dropout': 0.044244422957489524, 'out_channels': 37, 'lr': 0.0001192954286479643}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11128953206986189 Test Loss: 0.13483454640538167\n",
      "Epoch: 1 Train Loss: 0.19358475728062913 Test Loss: 0.2676504976103103\n",
      "Epoch: 2 Train Loss: 0.18529463738920168 Test Loss: 0.15801856226731129\n",
      "Epoch: 3 Train Loss: 0.1948837643413106 Test Loss: 0.1926107531109938\n",
      "Epoch: 4 Train Loss: 0.17627532672742383 Test Loss: 0.16883954184111982\n",
      "Epoch: 5 Train Loss: 0.17721520075425506 Test Loss: 0.20848214286662187\n",
      "Epoch: 6 Train Loss: 0.23969831087788918 Test Loss: 0.1688765122111851\n",
      "Epoch: 7 Train Loss: 0.18964528974266723 Test Loss: 0.16693892817908582\n",
      "Epoch: 8 Train Loss: 0.1747889059009962 Test Loss: 0.19438248650191692\n",
      "Epoch: 9 Train Loss: 0.17268402027348057 Test Loss: 0.1762291390430956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:39:07,480]\u001b[0m Trial 70 finished with value: 0.6725380304243395 and parameters: {'hidden_size': 58, 'num_layers': 1, 'lstm_dropout': 0.036655822150697744, 'fc_dropout': 0.07636180999419048, 'bidirectional': True, 'conv_dropout': 0.05691181680022815, 'out_channels': 20, 'lr': 0.007069361229418008}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1730731011009775 Test Loss: 0.20461963828855428\n",
      "Epoch: 1 Train Loss: 0.16253840664811434 Test Loss: 0.1492270350741883\n",
      "Epoch: 2 Train Loss: 0.14871351702287794 Test Loss: 0.14769351003935544\n",
      "Epoch: 3 Train Loss: 0.15440669668014162 Test Loss: 0.14679614304544064\n",
      "Epoch: 4 Train Loss: 0.15279543219655753 Test Loss: 0.15666769810032827\n",
      "Epoch: 5 Train Loss: 0.1509162896450609 Test Loss: 0.16177662433729098\n",
      "Epoch: 6 Train Loss: 0.14982731009460987 Test Loss: 0.17810996712301486\n",
      "Epoch: 7 Train Loss: 0.1462783886782825 Test Loss: 0.14612003263478843\n",
      "Epoch: 8 Train Loss: 0.15056817023716867 Test Loss: 0.16232391419900824\n",
      "Epoch: 9 Train Loss: 0.1439532299026847 Test Loss: 0.14319278879430347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:39:48,556]\u001b[0m Trial 71 finished with value: 0.6786004882017901 and parameters: {'hidden_size': 83, 'num_layers': 1, 'lstm_dropout': 0.04373087905544124, 'fc_dropout': 0.028393632865604174, 'bidirectional': True, 'conv_dropout': 0.027615775998248843, 'out_channels': 14, 'lr': 0.0030721602699728774}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1467625603687018 Test Loss: 0.16185398090380831\n",
      "Epoch: 1 Train Loss: 0.15417917372882367 Test Loss: 0.1393474992781211\n",
      "Epoch: 2 Train Loss: 0.13522976663708686 Test Loss: 0.1372090399193878\n",
      "Epoch: 3 Train Loss: 0.13056945117413998 Test Loss: 0.13670669723682985\n",
      "Epoch: 4 Train Loss: 0.12829124797210098 Test Loss: 0.1386307467596409\n",
      "Epoch: 5 Train Loss: 0.1260020425066352 Test Loss: 0.13413635061119503\n",
      "Epoch: 6 Train Loss: 0.12525905323177577 Test Loss: 0.13740903870782817\n",
      "Epoch: 7 Train Loss: 0.1253359957754612 Test Loss: 0.132545136007519\n",
      "Epoch: 8 Train Loss: 0.12208503957688809 Test Loss: 0.1320822982075877\n",
      "Epoch: 9 Train Loss: 0.12239888821989298 Test Loss: 0.13304452684681162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:40:47,400]\u001b[0m Trial 72 finished with value: 0.6879084967320261 and parameters: {'hidden_size': 72, 'num_layers': 1, 'lstm_dropout': 0.07445049182424013, 'fc_dropout': 0.06440605453509744, 'bidirectional': True, 'conv_dropout': 0.03192361652561085, 'out_channels': 12, 'lr': 0.000467001829233814}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12246635184288025 Test Loss: 0.1326356754242517\n",
      "Epoch: 1 Train Loss: 0.2009568537910236 Test Loss: 0.17393044239808672\n",
      "Epoch: 2 Train Loss: 0.18565343395443634 Test Loss: 0.17644179075176772\n",
      "Epoch: 3 Train Loss: 0.19837968317002524 Test Loss: 0.16023795096911847\n",
      "Epoch: 4 Train Loss: 0.1967083326138265 Test Loss: 0.1724827379827349\n",
      "Epoch: 5 Train Loss: 0.20752841566600838 Test Loss: 0.17826603651760867\n",
      "Epoch: 6 Train Loss: 0.1884670697459951 Test Loss: 0.18923324469131783\n",
      "Epoch: 7 Train Loss: 0.18747492112144828 Test Loss: 0.16394135320541292\n",
      "Epoch: 8 Train Loss: 0.1749024201337248 Test Loss: 0.16366068551989313\n",
      "Epoch: 9 Train Loss: 0.19633697967105546 Test Loss: 0.16456842237411026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:41:53,860]\u001b[0m Trial 73 finished with value: 0.6740858505564388 and parameters: {'hidden_size': 107, 'num_layers': 1, 'lstm_dropout': 0.057022934242904846, 'fc_dropout': 0.0905894638558875, 'bidirectional': True, 'conv_dropout': 0.07989338984306939, 'out_channels': 17, 'lr': 0.006429427801511336}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.20442539997696876 Test Loss: 0.23165028984862984\n",
      "Epoch: 1 Train Loss: 0.185162425680086 Test Loss: 0.1807650804531555\n",
      "Epoch: 2 Train Loss: 0.17993144136192277 Test Loss: 0.16710756159723758\n",
      "Epoch: 3 Train Loss: 0.18194862632835285 Test Loss: 0.22773589200962085\n",
      "Epoch: 4 Train Loss: 0.17516734838224948 Test Loss: 0.17566881656123046\n",
      "Epoch: 5 Train Loss: 0.17861007810449228 Test Loss: 0.19097913989199164\n",
      "Epoch: 6 Train Loss: 0.17515839248448611 Test Loss: 0.1754041740272087\n",
      "Epoch: 7 Train Loss: 0.17116493957219645 Test Loss: 0.20935475095710793\n",
      "Epoch: 8 Train Loss: 0.1831919724745443 Test Loss: 0.18412099422785802\n",
      "Epoch: 9 Train Loss: 0.17459887637812643 Test Loss: 0.17037253018718557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:43:00,524]\u001b[0m Trial 74 finished with value: 0.6597110754414126 and parameters: {'hidden_size': 92, 'num_layers': 1, 'lstm_dropout': 0.09282381930912965, 'fc_dropout': 0.00012042133472047432, 'bidirectional': True, 'conv_dropout': 0.012171278869225095, 'out_channels': 9, 'lr': 0.009053577288006338}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17909164434196428 Test Loss: 0.16826312881581984\n",
      "Epoch: 1 Train Loss: 0.21542832678924315 Test Loss: 0.18227057581166395\n",
      "Epoch: 2 Train Loss: 0.21756099454968497 Test Loss: 0.1752445365007693\n",
      "Epoch: 3 Train Loss: 0.201628175178729 Test Loss: 0.17534587491815462\n",
      "Epoch: 4 Train Loss: 0.1908276592873037 Test Loss: 0.17465841576468927\n",
      "Epoch: 5 Train Loss: 0.19193543922416867 Test Loss: 0.1734379477346667\n",
      "Epoch: 6 Train Loss: 0.1829862887525931 Test Loss: 0.23441402705463643\n",
      "Epoch: 7 Train Loss: 0.1944362227005302 Test Loss: 0.2720470277035755\n",
      "Epoch: 8 Train Loss: 0.17833384120501578 Test Loss: 0.17617226727663898\n",
      "Epoch: 9 Train Loss: 0.17861074643954636 Test Loss: 0.17860881984233856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:44:08,656]\u001b[0m Trial 75 finished with value: 0.6562242374278647 and parameters: {'hidden_size': 37, 'num_layers': 1, 'lstm_dropout': 0.03037224700241552, 'fc_dropout': 0.03650392008030513, 'bidirectional': True, 'conv_dropout': 0.035597462459016606, 'out_channels': 15, 'lr': 0.013338949770690278}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1714133436962962 Test Loss: 0.1752252162347872\n",
      "Epoch: 1 Train Loss: 0.15860893342345952 Test Loss: 0.1469597705244161\n",
      "Epoch: 2 Train Loss: 0.14901522657275199 Test Loss: 0.14824166059636842\n",
      "Epoch: 3 Train Loss: 0.14507964268550277 Test Loss: 0.145327820802649\n",
      "Epoch: 4 Train Loss: 0.15079403045400977 Test Loss: 0.1550877598224404\n",
      "Epoch: 5 Train Loss: 0.14916324889585375 Test Loss: 0.1698146646726317\n",
      "Epoch: 6 Train Loss: 0.14685926590561868 Test Loss: 0.14775509925815053\n",
      "Epoch: 7 Train Loss: 0.1458880793593824 Test Loss: 0.14577647162892948\n",
      "Epoch: 8 Train Loss: 0.1438069042645395 Test Loss: 0.14502898607248316\n",
      "Epoch: 9 Train Loss: 0.1473801113963127 Test Loss: 0.14554870991518323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:45:11,132]\u001b[0m Trial 76 finished with value: 0.6763052208835342 and parameters: {'hidden_size': 47, 'num_layers': 1, 'lstm_dropout': 0.013632347445807574, 'fc_dropout': 0.017452455880338703, 'bidirectional': False, 'conv_dropout': 0.0634613376019994, 'out_channels': 10, 'lr': 0.0028469673738997243}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14374772976860403 Test Loss: 0.14736597639279433\n",
      "Epoch: 1 Train Loss: 0.18163836073949932 Test Loss: 0.1612952199583046\n",
      "Epoch: 2 Train Loss: 0.1668198907494545 Test Loss: 0.15572332596769348\n",
      "Epoch: 3 Train Loss: 0.16221126650050283 Test Loss: 0.1617532564095034\n",
      "Epoch: 4 Train Loss: 0.15829098299667238 Test Loss: 0.16867221311663097\n",
      "Epoch: 5 Train Loss: 0.1582133559450507 Test Loss: 0.16361600669404378\n",
      "Epoch: 6 Train Loss: 0.16047676216065884 Test Loss: 0.17060538040646633\n",
      "Epoch: 7 Train Loss: 0.15608724097311497 Test Loss: 0.15131931631162335\n",
      "Epoch: 8 Train Loss: 0.15559999410137534 Test Loss: 0.15186132019320234\n",
      "Epoch: 9 Train Loss: 0.15270322606936096 Test Loss: 0.15734063422146696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:46:26,756]\u001b[0m Trial 77 finished with value: 0.6468285043069695 and parameters: {'hidden_size': 52, 'num_layers': 2, 'lstm_dropout': 0.048019198820343056, 'fc_dropout': 0.11816523452596568, 'bidirectional': True, 'conv_dropout': 0.00020638334184613222, 'out_channels': 13, 'lr': 0.017027590476725817}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1575739457823336 Test Loss: 0.1560908102522643\n",
      "Epoch: 1 Train Loss: 0.20735718650890048 Test Loss: 0.35194514249460757\n",
      "Epoch: 2 Train Loss: 0.20105969657028328 Test Loss: 0.22590544561449344\n",
      "Epoch: 3 Train Loss: 0.19684800655171275 Test Loss: 0.17688676110578896\n",
      "Epoch: 4 Train Loss: 0.1839458538832143 Test Loss: 0.20091715092791584\n",
      "Epoch: 5 Train Loss: 0.2007583836321719 Test Loss: 0.17406380935289417\n",
      "Epoch: 6 Train Loss: 0.19086631980803795 Test Loss: 0.16245847802531843\n",
      "Epoch: 7 Train Loss: 0.18887213792609983 Test Loss: 0.176559799312117\n",
      "Epoch: 8 Train Loss: 0.19473124106517062 Test Loss: 0.19591444177841677\n",
      "Epoch: 9 Train Loss: 0.19438926573921927 Test Loss: 0.19087534293029518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:47:35,392]\u001b[0m Trial 78 finished with value: 0.6768 and parameters: {'hidden_size': 100, 'num_layers': 1, 'lstm_dropout': 0.10413143534765423, 'fc_dropout': 0.13832467417790056, 'bidirectional': True, 'conv_dropout': 0.05458729118772432, 'out_channels': 27, 'lr': 0.005539267977137619}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.19406221491738687 Test Loss: 0.16347072507067326\n",
      "Epoch: 1 Train Loss: 0.22523570555564948 Test Loss: 0.20978351879995852\n",
      "Epoch: 2 Train Loss: 0.210188696547359 Test Loss: 0.3991353860535561\n",
      "Epoch: 3 Train Loss: 0.24517795727893243 Test Loss: 0.22540905198901326\n",
      "Epoch: 4 Train Loss: 0.2518132972128966 Test Loss: 0.2780526148225255\n",
      "Epoch: 5 Train Loss: 0.23189130041473982 Test Loss: 0.19761023365746672\n",
      "Epoch: 6 Train Loss: 0.2054781460246537 Test Loss: 0.207925018309928\n",
      "Epoch: 7 Train Loss: 0.21002260562367736 Test Loss: 0.16039790589802752\n",
      "Epoch: 8 Train Loss: 0.23345452112387574 Test Loss: 0.1769449539637318\n",
      "Epoch: 9 Train Loss: 0.2299400950732641 Test Loss: 0.23088030843212962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:48:42,383]\u001b[0m Trial 79 finished with value: 0.6633825944170773 and parameters: {'hidden_size': 121, 'num_layers': 1, 'lstm_dropout': 0.06566940948824054, 'fc_dropout': 0.09249742979911513, 'bidirectional': True, 'conv_dropout': 0.013228348819222205, 'out_channels': 17, 'lr': 0.011558955184230751}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.23035727803575864 Test Loss: 0.1931053547682568\n",
      "Epoch: 1 Train Loss: 0.16273171668052674 Test Loss: 0.14065422984762505\n",
      "Epoch: 2 Train Loss: 0.13343071350455285 Test Loss: 0.1358104672092504\n",
      "Epoch: 3 Train Loss: 0.12952204536646605 Test Loss: 0.13607860808840955\n",
      "Epoch: 4 Train Loss: 0.12667471648901701 Test Loss: 0.13600133962857838\n",
      "Epoch: 5 Train Loss: 0.12348073737621307 Test Loss: 0.13693640667635698\n",
      "Epoch: 6 Train Loss: 0.12164393577128649 Test Loss: 0.13566907934737377\n",
      "Epoch: 7 Train Loss: 0.12008556186407804 Test Loss: 0.1323128237534826\n",
      "Epoch: 8 Train Loss: 0.11727892253547907 Test Loss: 0.13311769174763\n",
      "Epoch: 9 Train Loss: 0.11551605350226164 Test Loss: 0.1313786497250342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:49:56,660]\u001b[0m Trial 80 finished with value: 0.694241686942417 and parameters: {'hidden_size': 188, 'num_layers': 1, 'lstm_dropout': 0.12322048627629202, 'fc_dropout': 0.049355462740746474, 'bidirectional': True, 'conv_dropout': 0.03645735170903294, 'out_channels': 11, 'lr': 0.00012183470643268985}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11538643669188023 Test Loss: 0.12935927552810778\n",
      "Epoch: 1 Train Loss: 0.16233015636578202 Test Loss: 0.1576152356258168\n",
      "Epoch: 2 Train Loss: 0.15125225995481015 Test Loss: 0.14518835076604025\n",
      "Epoch: 3 Train Loss: 0.14798977353870868 Test Loss: 0.15468098051822224\n",
      "Epoch: 4 Train Loss: 0.1441008761420846 Test Loss: 0.14974718746809532\n",
      "Epoch: 5 Train Loss: 0.14982036583796143 Test Loss: 0.1625793613969518\n",
      "Epoch: 6 Train Loss: 0.14679949038997292 Test Loss: 0.15843066575523382\n",
      "Epoch: 7 Train Loss: 0.14904522143378854 Test Loss: 0.1704353861192378\n",
      "Epoch: 8 Train Loss: 0.14644265598356723 Test Loss: 0.143668186258727\n",
      "Epoch: 9 Train Loss: 0.14353673609346151 Test Loss: 0.15281637305447374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:50:55,371]\u001b[0m Trial 81 finished with value: 0.6811244979919678 and parameters: {'hidden_size': 98, 'num_layers': 1, 'lstm_dropout': 0.08373833080407886, 'fc_dropout': 0.14852463234515956, 'bidirectional': True, 'conv_dropout': 0.028162171770766235, 'out_channels': 8, 'lr': 0.0023288175131806624}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14878403737656773 Test Loss: 0.14550012413162394\n",
      "Epoch: 1 Train Loss: 0.18550458849072457 Test Loss: 0.16636295352999966\n",
      "Epoch: 2 Train Loss: 0.1763152818115428 Test Loss: 0.16383763038502713\n",
      "Epoch: 3 Train Loss: 0.16493049532696605 Test Loss: 0.15840764084277442\n",
      "Epoch: 4 Train Loss: 0.17617529309121893 Test Loss: 0.16381695714240638\n",
      "Epoch: 5 Train Loss: 0.17089248745888472 Test Loss: 0.25513371560196674\n",
      "Epoch: 6 Train Loss: 0.17022539053168148 Test Loss: 0.16625491983164994\n",
      "Epoch: 7 Train Loss: 0.16856910919025542 Test Loss: 0.15078047098228917\n",
      "Epoch: 8 Train Loss: 0.162215071888268 Test Loss: 0.16563203874915933\n",
      "Epoch: 9 Train Loss: 0.16817218824252486 Test Loss: 0.1547163697167898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:52:00,558]\u001b[0m Trial 82 finished with value: 0.6806451612903226 and parameters: {'hidden_size': 152, 'num_layers': 1, 'lstm_dropout': 0.04682013359458246, 'fc_dropout': 0.1769456690983528, 'bidirectional': True, 'conv_dropout': 0.04071420884203124, 'out_channels': 5, 'lr': 0.0057108208921529385}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17297597638815643 Test Loss: 0.1560969503400044\n",
      "Epoch: 1 Train Loss: 0.15872787674963473 Test Loss: 0.15797123332885793\n",
      "Epoch: 2 Train Loss: 0.14610504172891378 Test Loss: 0.14369430770865455\n",
      "Epoch: 3 Train Loss: 0.14283398512527345 Test Loss: 0.14741797022783337\n",
      "Epoch: 4 Train Loss: 0.14188864018842579 Test Loss: 0.1533165635666051\n",
      "Epoch: 5 Train Loss: 0.146394069981575 Test Loss: 0.15340153639689802\n",
      "Epoch: 6 Train Loss: 0.1419698259189725 Test Loss: 0.14375160938610856\n",
      "Epoch: 7 Train Loss: 0.13943967996761203 Test Loss: 0.14273512762147017\n",
      "Epoch: 8 Train Loss: 0.14161170184388758 Test Loss: 0.1381048170117715\n",
      "Epoch: 9 Train Loss: 0.1402819790571928 Test Loss: 0.14738109061559931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:52:53,349]\u001b[0m Trial 83 finished with value: 0.690238278247502 and parameters: {'hidden_size': 109, 'num_layers': 1, 'lstm_dropout': 0.07082498239961946, 'fc_dropout': 0.032045163894060216, 'bidirectional': True, 'conv_dropout': 0.0878101439719893, 'out_channels': 8, 'lr': 0.0020567532891033495}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1387501819960773 Test Loss: 0.14764120742178763\n",
      "Epoch: 1 Train Loss: 0.1925731322903186 Test Loss: 0.1804794005115335\n",
      "Epoch: 2 Train Loss: 0.19045491397278383 Test Loss: 0.16317703053593255\n",
      "Epoch: 3 Train Loss: 0.184137146974355 Test Loss: 0.17413341498282103\n",
      "Epoch: 4 Train Loss: 0.18240806064591744 Test Loss: 0.187377385161341\n",
      "Epoch: 5 Train Loss: 0.17095073358817026 Test Loss: 0.15569362753686813\n",
      "Epoch: 6 Train Loss: 0.18987950273114257 Test Loss: 0.16673372351466276\n",
      "Epoch: 7 Train Loss: 0.17733838947028854 Test Loss: 0.15289815632513346\n",
      "Epoch: 8 Train Loss: 0.17831223505865781 Test Loss: 0.2293889115294129\n",
      "Epoch: 9 Train Loss: 0.18169682805016638 Test Loss: 0.15070747784651317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:53:55,199]\u001b[0m Trial 84 finished with value: 0.6767275615567911 and parameters: {'hidden_size': 83, 'num_layers': 1, 'lstm_dropout': 0.02929128928734069, 'fc_dropout': 0.18792181995912668, 'bidirectional': True, 'conv_dropout': 0.01354751156578273, 'out_channels': 9, 'lr': 0.008402715277225189}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1855894243581686 Test Loss: 0.15172534635344062\n",
      "Epoch: 1 Train Loss: 0.17696641950821504 Test Loss: 0.1629970208548319\n",
      "Epoch: 2 Train Loss: 0.16752823317572474 Test Loss: 0.18324845230069975\n",
      "Epoch: 3 Train Loss: 0.17920688091814518 Test Loss: 0.1904266496998267\n",
      "Epoch: 4 Train Loss: 0.17716832636510954 Test Loss: 0.16079620621836604\n",
      "Epoch: 5 Train Loss: 0.1720221677871421 Test Loss: 0.1580875378530532\n",
      "Epoch: 6 Train Loss: 0.1751889942248119 Test Loss: 0.15988718007747738\n",
      "Epoch: 7 Train Loss: 0.1661413231632672 Test Loss: 0.15722459341628484\n",
      "Epoch: 8 Train Loss: 0.17345717306979933 Test Loss: 0.17028143046536862\n",
      "Epoch: 9 Train Loss: 0.18117706434614955 Test Loss: 0.163857248111869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:55:00,495]\u001b[0m Trial 85 finished with value: 0.6783804430863254 and parameters: {'hidden_size': 117, 'num_layers': 1, 'lstm_dropout': 0.09116286604650997, 'fc_dropout': 0.15470165099070776, 'bidirectional': True, 'conv_dropout': 0.07181958193160251, 'out_channels': 14, 'lr': 0.005238267134211038}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18642926050862296 Test Loss: 0.1582459833074254\n",
      "Epoch: 1 Train Loss: 0.15348146478682756 Test Loss: 0.1389011204147491\n",
      "Epoch: 2 Train Loss: 0.13398251565098762 Test Loss: 0.1390835972467122\n",
      "Epoch: 3 Train Loss: 0.129613358643651 Test Loss: 0.13817319684266188\n",
      "Epoch: 4 Train Loss: 0.12765442479252814 Test Loss: 0.13611887242442694\n",
      "Epoch: 5 Train Loss: 0.125854562240839 Test Loss: 0.13757618074826064\n",
      "Epoch: 6 Train Loss: 0.12408129346072674 Test Loss: 0.13634248581021643\n",
      "Epoch: 7 Train Loss: 0.12123982727229596 Test Loss: 0.13421513255054768\n",
      "Epoch: 8 Train Loss: 0.12133834389299154 Test Loss: 0.1375777479142141\n",
      "Epoch: 9 Train Loss: 0.12038999710530042 Test Loss: 0.1353051114869051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:56:07,425]\u001b[0m Trial 86 finished with value: 0.6963562753036437 and parameters: {'hidden_size': 130, 'num_layers': 1, 'lstm_dropout': 0.13596214114905664, 'fc_dropout': 0.043566617285501284, 'bidirectional': True, 'conv_dropout': 0.055822520612954105, 'out_channels': 11, 'lr': 0.00023611363986555698}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11850254325121641 Test Loss: 0.13233039649530723\n",
      "Epoch: 1 Train Loss: 0.1587762581244111 Test Loss: 0.16078917413188246\n",
      "Epoch: 2 Train Loss: 0.14490707399845124 Test Loss: 0.1708291034740857\n",
      "Epoch: 3 Train Loss: 0.14077930156737567 Test Loss: 0.1401858119645153\n",
      "Epoch: 4 Train Loss: 0.14333524195849895 Test Loss: 0.1443240907959664\n",
      "Epoch: 5 Train Loss: 0.1427114848729223 Test Loss: 0.13907771571256672\n",
      "Epoch: 6 Train Loss: 0.14070018784552812 Test Loss: 0.1433286413836022\n",
      "Epoch: 7 Train Loss: 0.14300279197543858 Test Loss: 0.13945682234348009\n",
      "Epoch: 8 Train Loss: 0.14622260412275792 Test Loss: 0.1550606340512086\n",
      "Epoch: 9 Train Loss: 0.14218511413782836 Test Loss: 0.14605539598570655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:57:12,712]\u001b[0m Trial 87 finished with value: 0.6847736625514403 and parameters: {'hidden_size': 64, 'num_layers': 1, 'lstm_dropout': 0.1050498322049789, 'fc_dropout': 0.012601782820145624, 'bidirectional': True, 'conv_dropout': 0.103759150282063, 'out_channels': 12, 'lr': 0.0021421538647502705}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13964646501019598 Test Loss: 0.14300136829907903\n",
      "Epoch: 1 Train Loss: 0.1802135506734252 Test Loss: 0.15570750050008678\n",
      "Epoch: 2 Train Loss: 0.17775654642401495 Test Loss: 0.17861489073995251\n",
      "Epoch: 3 Train Loss: 0.16821244721915574 Test Loss: 0.1653830225076586\n",
      "Epoch: 4 Train Loss: 0.1731799217650667 Test Loss: 0.15789367703084176\n",
      "Epoch: 5 Train Loss: 0.16532333670966326 Test Loss: 0.16233589555532596\n",
      "Epoch: 6 Train Loss: 0.1662615088775754 Test Loss: 0.15978795100158205\n",
      "Epoch: 7 Train Loss: 0.16522932149730624 Test Loss: 0.1623330492609606\n",
      "Epoch: 8 Train Loss: 0.16735348891541363 Test Loss: 0.1826973094488866\n",
      "Epoch: 9 Train Loss: 0.17087965140603484 Test Loss: 0.17987103866169246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:58:15,812]\u001b[0m Trial 88 finished with value: 0.6707882534775889 and parameters: {'hidden_size': 134, 'num_layers': 1, 'lstm_dropout': 0.0586675051486451, 'fc_dropout': 0.039320250049278686, 'bidirectional': False, 'conv_dropout': 0.052477593807092486, 'out_channels': 11, 'lr': 0.009559377752234824}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17730617450401187 Test Loss: 0.1763753690325414\n",
      "Epoch: 1 Train Loss: 0.15686122281104325 Test Loss: 0.13943602678517755\n",
      "Epoch: 2 Train Loss: 0.1322815018966794 Test Loss: 0.13787270442079813\n",
      "Epoch: 3 Train Loss: 0.1276650007739663 Test Loss: 0.13548267920748494\n",
      "Epoch: 4 Train Loss: 0.1256418863028288 Test Loss: 0.13264430136369249\n",
      "Epoch: 5 Train Loss: 0.12332648168727756 Test Loss: 0.13654888822985722\n",
      "Epoch: 6 Train Loss: 0.12119099052846431 Test Loss: 0.13933482350775608\n",
      "Epoch: 7 Train Loss: 0.11815419694036246 Test Loss: 0.13555115288474595\n",
      "Epoch: 8 Train Loss: 0.11477131560742855 Test Loss: 0.13598932316318488\n",
      "Epoch: 9 Train Loss: 0.11476760154813528 Test Loss: 0.1364875705942464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 14:59:34,964]\u001b[0m Trial 89 finished with value: 0.704703161141095 and parameters: {'hidden_size': 165, 'num_layers': 1, 'lstm_dropout': 0.13040835359398392, 'fc_dropout': 0.06444043904962649, 'bidirectional': True, 'conv_dropout': 0.023318776935638153, 'out_channels': 16, 'lr': 0.00017508001204973665}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1131177976951003 Test Loss: 0.13616557380321404\n",
      "Epoch: 1 Train Loss: 0.17878804611302912 Test Loss: 0.15118808801562642\n",
      "Epoch: 2 Train Loss: 0.1486592914581299 Test Loss: 0.15128352967337869\n",
      "Epoch: 3 Train Loss: 0.1495479898646474 Test Loss: 0.16019216861230687\n",
      "Epoch: 4 Train Loss: 0.14483418115079402 Test Loss: 0.1489057761435501\n",
      "Epoch: 5 Train Loss: 0.14681794142872095 Test Loss: 0.15834514129335603\n",
      "Epoch: 6 Train Loss: 0.14879605030044912 Test Loss: 0.1487845546199967\n",
      "Epoch: 7 Train Loss: 0.1500449018843472 Test Loss: 0.15155522446460523\n",
      "Epoch: 8 Train Loss: 0.14693922342807056 Test Loss: 0.15166064510092186\n",
      "Epoch: 9 Train Loss: 0.14813857964500785 Test Loss: 0.15213789127338617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:01:32,316]\u001b[0m Trial 90 finished with value: 0.6699346405228759 and parameters: {'hidden_size': 164, 'num_layers': 2, 'lstm_dropout': 0.012208527697538725, 'fc_dropout': 0.07328323587800457, 'bidirectional': True, 'conv_dropout': 0.00937495466376019, 'out_channels': 19, 'lr': 0.006391956767592045}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14572032817602157 Test Loss: 0.16021106824034842\n",
      "Epoch: 1 Train Loss: 0.1528416187375784 Test Loss: 0.13949717834782296\n",
      "Epoch: 2 Train Loss: 0.134477947640419 Test Loss: 0.13774844206357822\n",
      "Epoch: 3 Train Loss: 0.13079209053739904 Test Loss: 0.1396274363366179\n",
      "Epoch: 4 Train Loss: 0.12810883854031563 Test Loss: 0.13504002345339083\n",
      "Epoch: 5 Train Loss: 0.12649338363856077 Test Loss: 0.1392567109780761\n",
      "Epoch: 6 Train Loss: 0.12181664451956749 Test Loss: 0.13674734238856517\n",
      "Epoch: 7 Train Loss: 0.12149963105097412 Test Loss: 0.14116784781455613\n",
      "Epoch: 8 Train Loss: 0.11978940961360932 Test Loss: 0.13414936631429977\n",
      "Epoch: 9 Train Loss: 0.11826453175991773 Test Loss: 0.13258934885965654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:02:52,557]\u001b[0m Trial 91 finished with value: 0.6984126984126985 and parameters: {'hidden_size': 174, 'num_layers': 1, 'lstm_dropout': 0.1280761037809622, 'fc_dropout': 0.05501611360846986, 'bidirectional': True, 'conv_dropout': 0.028119420804019746, 'out_channels': 16, 'lr': 0.0004655960255298313}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11678996818512678 Test Loss: 0.13588691149918605\n",
      "Epoch: 1 Train Loss: 0.18053886200701819 Test Loss: 0.1606992754561547\n",
      "Epoch: 2 Train Loss: 0.16265436656959356 Test Loss: 0.1470710288304776\n",
      "Epoch: 3 Train Loss: 0.1671354506969452 Test Loss: 0.17117060556079441\n",
      "Epoch: 4 Train Loss: 0.1708693396287039 Test Loss: 0.19598668299990293\n",
      "Epoch: 5 Train Loss: 0.15948840571120382 Test Loss: 0.16415533176459635\n",
      "Epoch: 6 Train Loss: 0.17436517281159758 Test Loss: 0.1973552584481506\n",
      "Epoch: 7 Train Loss: 0.16724512823335827 Test Loss: 0.18344515573215514\n",
      "Epoch: 8 Train Loss: 0.17729386828057467 Test Loss: 0.17673221982780474\n",
      "Epoch: 9 Train Loss: 0.17508039644854143 Test Loss: 0.19142746567107238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:04:14,316]\u001b[0m Trial 92 finished with value: 0.677570093457944 and parameters: {'hidden_size': 177, 'num_layers': 1, 'lstm_dropout': 0.08064977639578372, 'fc_dropout': 0.05684772919366665, 'bidirectional': True, 'conv_dropout': 0.02511609114462217, 'out_channels': 16, 'lr': 0.004744881197261689}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17096894941385835 Test Loss: 0.20608141958325232\n",
      "Epoch: 1 Train Loss: 0.16434762753881513 Test Loss: 0.1513335652494678\n",
      "Epoch: 2 Train Loss: 0.14538516083285213 Test Loss: 0.14359127553388143\n",
      "Epoch: 3 Train Loss: 0.14381609354168176 Test Loss: 0.1488397707314656\n",
      "Epoch: 4 Train Loss: 0.14253146678060294 Test Loss: 0.14466927015481476\n",
      "Epoch: 5 Train Loss: 0.1427771067738533 Test Loss: 0.15295868546526414\n",
      "Epoch: 6 Train Loss: 0.14585457586012782 Test Loss: 0.18081394982741425\n",
      "Epoch: 7 Train Loss: 0.14591928576184438 Test Loss: 0.14864890476147208\n",
      "Epoch: 8 Train Loss: 0.14469658794403076 Test Loss: 0.14763342154126008\n",
      "Epoch: 9 Train Loss: 0.14493714366983623 Test Loss: 0.15545539413920986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:05:14,866]\u001b[0m Trial 93 finished with value: 0.6793349168646081 and parameters: {'hidden_size': 195, 'num_layers': 1, 'lstm_dropout': 0.11853549872692301, 'fc_dropout': 0.02365167106913988, 'bidirectional': True, 'conv_dropout': 0.039983817014709676, 'out_channels': 15, 'lr': 0.001902003986793416}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14206377360150219 Test Loss: 0.14377192931231886\n",
      "Epoch: 1 Train Loss: 0.22733864355248515 Test Loss: 0.2091441586310157\n",
      "Epoch: 2 Train Loss: 0.19673461859282107 Test Loss: 0.16433138686556595\n",
      "Epoch: 3 Train Loss: 0.20933135292753577 Test Loss: 0.16848337803238306\n",
      "Epoch: 4 Train Loss: 0.22860248294554858 Test Loss: 0.1965153369057281\n",
      "Epoch: 5 Train Loss: 0.2116901929773856 Test Loss: 0.2907132364833875\n",
      "Epoch: 6 Train Loss: 0.21187607151328702 Test Loss: 0.19114581323020494\n",
      "Epoch: 7 Train Loss: 0.23112564992453363 Test Loss: 0.22741204538098433\n",
      "Epoch: 8 Train Loss: 0.2306653557714424 Test Loss: 0.21885279055644635\n",
      "Epoch: 9 Train Loss: 0.24436602574398275 Test Loss: 0.2387617167885811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:06:36,036]\u001b[0m Trial 94 finished with value: 0.6682577565632458 and parameters: {'hidden_size': 162, 'num_layers': 1, 'lstm_dropout': 0.03907817676384104, 'fc_dropout': 0.06718098059621659, 'bidirectional': True, 'conv_dropout': 0.02258124590184844, 'out_channels': 17, 'lr': 0.008348563504222608}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.2262118011521583 Test Loss: 0.18956053247467017\n",
      "Epoch: 1 Train Loss: 0.16924517872724681 Test Loss: 0.27908141202337594\n",
      "Epoch: 2 Train Loss: 0.16574686231662053 Test Loss: 0.18668028974411682\n",
      "Epoch: 3 Train Loss: 0.16721255127163603 Test Loss: 0.15170822437471762\n",
      "Epoch: 4 Train Loss: 0.16376716551417486 Test Loss: 0.15056221481686394\n",
      "Epoch: 5 Train Loss: 0.16104931717440485 Test Loss: 0.1527982343065615\n",
      "Epoch: 6 Train Loss: 0.16699831301700324 Test Loss: 0.16904866858757436\n",
      "Epoch: 7 Train Loss: 0.17176300377491863 Test Loss: 0.15694022175079336\n",
      "Epoch: 8 Train Loss: 0.16627515101674945 Test Loss: 0.1495080295259865\n",
      "Epoch: 9 Train Loss: 0.16402015776219778 Test Loss: 0.1531962362317422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:07:51,353]\u001b[0m Trial 95 finished with value: 0.6774193548387096 and parameters: {'hidden_size': 158, 'num_layers': 1, 'lstm_dropout': 0.0001397996889969666, 'fc_dropout': 0.08492803301633423, 'bidirectional': True, 'conv_dropout': 0.006757156367971562, 'out_channels': 18, 'lr': 0.002985527796339573}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1704991919189226 Test Loss: 0.1504538141684934\n",
      "Epoch: 1 Train Loss: 0.18228125020489097 Test Loss: 0.18681977782100914\n",
      "Epoch: 2 Train Loss: 0.16956998007819057 Test Loss: 0.1940325879709075\n",
      "Epoch: 3 Train Loss: 0.17214213432744147 Test Loss: 0.15851877953488225\n",
      "Epoch: 4 Train Loss: 0.1686895127505064 Test Loss: 0.18137448274503692\n",
      "Epoch: 5 Train Loss: 0.1733483935382217 Test Loss: 0.19990283901507136\n",
      "Epoch: 6 Train Loss: 0.1603446092437953 Test Loss: 0.17684563621878624\n",
      "Epoch: 7 Train Loss: 0.16799020629450678 Test Loss: 0.16365279949987277\n",
      "Epoch: 8 Train Loss: 0.18061326540391892 Test Loss: 0.16622516887780195\n",
      "Epoch: 9 Train Loss: 0.17355822018496692 Test Loss: 0.15453278427473463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:09:06,954]\u001b[0m Trial 96 finished with value: 0.671850699844479 and parameters: {'hidden_size': 168, 'num_layers': 1, 'lstm_dropout': 0.066444727250853, 'fc_dropout': 0.05867363535131384, 'bidirectional': True, 'conv_dropout': 0.02854312173272675, 'out_channels': 14, 'lr': 0.0044463459370181774}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17926693769898266 Test Loss: 0.18350679942736992\n",
      "Epoch: 1 Train Loss: 0.2711461659632274 Test Loss: 0.19570700563014315\n",
      "Epoch: 2 Train Loss: 0.2441262568490696 Test Loss: 0.1872685498546083\n",
      "Epoch: 3 Train Loss: 0.22428755973104852 Test Loss: 0.20432150687058323\n",
      "Epoch: 4 Train Loss: 0.2562689931495959 Test Loss: 0.2611307129522372\n",
      "Epoch: 5 Train Loss: 0.23731241724204702 Test Loss: 0.3080333462568928\n",
      "Epoch: 6 Train Loss: 0.24682652280511103 Test Loss: 0.19572909451803913\n",
      "Epoch: 7 Train Loss: 0.22921770033486827 Test Loss: 0.20725817758792314\n",
      "Epoch: 8 Train Loss: 0.2501749687349773 Test Loss: 0.2512790381003873\n",
      "Epoch: 9 Train Loss: 0.22704967570998705 Test Loss: 0.16924760998866428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:10:21,460]\u001b[0m Trial 97 finished with value: 0.662847790507365 and parameters: {'hidden_size': 174, 'num_layers': 1, 'lstm_dropout': 0.12516094290038313, 'fc_dropout': 0.028511242647669292, 'bidirectional': True, 'conv_dropout': 0.06486180367842295, 'out_channels': 13, 'lr': 0.011233206778422884}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.20846031916178762 Test Loss: 0.4596538132371994\n",
      "Epoch: 1 Train Loss: 0.22394500724314712 Test Loss: 0.27765114872814745\n",
      "Epoch: 2 Train Loss: 0.19197144952700473 Test Loss: 0.2557702453715129\n",
      "Epoch: 3 Train Loss: 0.20114296874143184 Test Loss: 0.1778952230672581\n",
      "Epoch: 4 Train Loss: 0.2162581139536007 Test Loss: 0.16947241365528717\n",
      "Epoch: 5 Train Loss: 0.19911384083589073 Test Loss: 0.21909670623394248\n",
      "Epoch: 6 Train Loss: 0.2226876066992936 Test Loss: 0.18375361445969857\n",
      "Epoch: 7 Train Loss: 0.20955918202456086 Test Loss: 0.2946895346528636\n",
      "Epoch: 8 Train Loss: 0.1921481094658375 Test Loss: 0.18435126201312144\n",
      "Epoch: 9 Train Loss: 0.19394927647057922 Test Loss: 0.17128528229082926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:11:37,309]\u001b[0m Trial 98 finished with value: 0.6610455311973018 and parameters: {'hidden_size': 142, 'num_layers': 1, 'lstm_dropout': 0.10856621366348904, 'fc_dropout': 0.10134851535072249, 'bidirectional': True, 'conv_dropout': 0.04075828126091031, 'out_channels': 21, 'lr': 0.0070315275767143404}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.20587595286563737 Test Loss: 0.1787589257374739\n",
      "Epoch: 1 Train Loss: 0.16290347914993764 Test Loss: 0.15692993744422262\n",
      "Epoch: 2 Train Loss: 0.1471397215284407 Test Loss: 0.14875956262333895\n",
      "Epoch: 3 Train Loss: 0.14462809593006967 Test Loss: 0.1502002520224871\n",
      "Epoch: 4 Train Loss: 0.14455034215897322 Test Loss: 0.14385988501409372\n",
      "Epoch: 5 Train Loss: 0.14055725130625069 Test Loss: 0.1453204157110601\n",
      "Epoch: 6 Train Loss: 0.1402354837886989 Test Loss: 0.14506102928790612\n",
      "Epoch: 7 Train Loss: 0.13924135269373655 Test Loss: 0.17063985767360693\n",
      "Epoch: 8 Train Loss: 0.14064786101132631 Test Loss: 0.1407864663047722\n",
      "Epoch: 9 Train Loss: 0.14057994360029696 Test Loss: 0.1524799545905508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:12:57,585]\u001b[0m Trial 99 finished with value: 0.694267515923567 and parameters: {'hidden_size': 184, 'num_layers': 1, 'lstm_dropout': 0.023221683080747874, 'fc_dropout': 0.12305822036618048, 'bidirectional': True, 'conv_dropout': 0.07714825307700787, 'out_channels': 16, 'lr': 0.0015455814790237548}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14295738685205578 Test Loss: 0.1496511771159169\n",
      "Epoch: 1 Train Loss: 0.20823893591240047 Test Loss: 0.22646846058897482\n",
      "Epoch: 2 Train Loss: 0.21828042872902007 Test Loss: 0.26095452202192415\n",
      "Epoch: 3 Train Loss: 0.21032618623527816 Test Loss: 0.20627419633073762\n",
      "Epoch: 4 Train Loss: 0.19950486129261552 Test Loss: 0.1753418475460892\n",
      "Epoch: 5 Train Loss: 0.20934058020762167 Test Loss: 0.18376435515970682\n",
      "Epoch: 6 Train Loss: 0.20242815936589614 Test Loss: 0.17974867876886894\n",
      "Epoch: 7 Train Loss: 0.2063281587571546 Test Loss: 0.3498340250965886\n",
      "Epoch: 8 Train Loss: 0.2315921175075695 Test Loss: 0.30639977058166634\n",
      "Epoch: 9 Train Loss: 0.20652636348851958 Test Loss: 0.15878254875612144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:13:52,000]\u001b[0m Trial 100 finished with value: 0.6429780033840948 and parameters: {'hidden_size': 32, 'num_layers': 1, 'lstm_dropout': 0.050613299249998224, 'fc_dropout': 0.07992608441925315, 'bidirectional': True, 'conv_dropout': 0.01009405357028375, 'out_channels': 20, 'lr': 0.01389635121661954}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1997263955356786 Test Loss: 0.21382440845244013\n",
      "Epoch: 1 Train Loss: 0.18161135971844197 Test Loss: 0.14944154342499594\n",
      "Epoch: 2 Train Loss: 0.13926442836225034 Test Loss: 0.14117621366803448\n",
      "Epoch: 3 Train Loss: 0.13390138695836068 Test Loss: 0.14081776711625604\n",
      "Epoch: 4 Train Loss: 0.13173193023502827 Test Loss: 0.13982964273744497\n",
      "Epoch: 5 Train Loss: 0.1293435692191124 Test Loss: 0.13856021793612752\n",
      "Epoch: 6 Train Loss: 0.12836490569859743 Test Loss: 0.13525601787070116\n",
      "Epoch: 7 Train Loss: 0.1274721590310335 Test Loss: 0.13728168301177196\n",
      "Epoch: 8 Train Loss: 0.12620725528001786 Test Loss: 0.13624931377962754\n",
      "Epoch: 9 Train Loss: 0.12499002552330495 Test Loss: 0.13551744716926314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:14:56,150]\u001b[0m Trial 101 finished with value: 0.6892744479495269 and parameters: {'hidden_size': 40, 'num_layers': 1, 'lstm_dropout': 0.13571317370272257, 'fc_dropout': 0.045785934666125475, 'bidirectional': True, 'conv_dropout': 0.05514555420511627, 'out_channels': 12, 'lr': 0.00011027626765487407}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12313222807198763 Test Loss: 0.13851491005394978\n",
      "Epoch: 1 Train Loss: 0.17668951494693755 Test Loss: 0.1617034437676398\n",
      "Epoch: 2 Train Loss: 0.17040067838896067 Test Loss: 0.1648955056592584\n",
      "Epoch: 3 Train Loss: 0.1683845901608467 Test Loss: 0.1551409228719747\n",
      "Epoch: 4 Train Loss: 0.18444176177280025 Test Loss: 0.169858711096235\n",
      "Epoch: 5 Train Loss: 0.16934816217906773 Test Loss: 0.19504033313460126\n",
      "Epoch: 6 Train Loss: 0.16354558629281818 Test Loss: 0.15944754722685858\n",
      "Epoch: 7 Train Loss: 0.16711226268792526 Test Loss: 0.16870266071464213\n",
      "Epoch: 8 Train Loss: 0.17457970750667154 Test Loss: 0.17362482830608328\n",
      "Epoch: 9 Train Loss: 0.16549416670333594 Test Loss: 0.1719002422516624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:16:02,824]\u001b[0m Trial 102 finished with value: 0.6823161189358372 and parameters: {'hidden_size': 154, 'num_layers': 1, 'lstm_dropout': 0.09771284804637445, 'fc_dropout': 0.013354307756121746, 'bidirectional': True, 'conv_dropout': 0.04983235083403074, 'out_channels': 10, 'lr': 0.004447869751949836}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16888168802075088 Test Loss: 0.29864666399102624\n",
      "Epoch: 1 Train Loss: 0.1610430103212595 Test Loss: 0.14429087761325388\n",
      "Epoch: 2 Train Loss: 0.1353348676905036 Test Loss: 0.13883933061942125\n",
      "Epoch: 3 Train Loss: 0.1317330091536045 Test Loss: 0.14074125440832905\n",
      "Epoch: 4 Train Loss: 0.12875029663294554 Test Loss: 0.13731166087209987\n",
      "Epoch: 5 Train Loss: 0.12822006134837866 Test Loss: 0.1437614403900128\n",
      "Epoch: 6 Train Loss: 0.12514084687680005 Test Loss: 0.13334350472988601\n",
      "Epoch: 7 Train Loss: 0.12229542259722948 Test Loss: 0.13399837075319057\n",
      "Epoch: 8 Train Loss: 0.12052908013761043 Test Loss: 0.13311013616859532\n",
      "Epoch: 9 Train Loss: 0.11999792656302452 Test Loss: 0.1352111992839807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:17:00,458]\u001b[0m Trial 103 finished with value: 0.6926829268292684 and parameters: {'hidden_size': 129, 'num_layers': 1, 'lstm_dropout': 0.14840869125030123, 'fc_dropout': 0.05028632354317591, 'bidirectional': True, 'conv_dropout': 0.02035187004891144, 'out_channels': 7, 'lr': 0.00026611543122069574}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11688590472340583 Test Loss: 0.13131470534319695\n",
      "Epoch: 1 Train Loss: 0.15648531889505685 Test Loss: 0.14248867192493078\n",
      "Epoch: 2 Train Loss: 0.1467408868521452 Test Loss: 0.14371420810826288\n",
      "Epoch: 3 Train Loss: 0.14750919341444968 Test Loss: 0.1439912725989811\n",
      "Epoch: 4 Train Loss: 0.1449685863673687 Test Loss: 0.1659318326776044\n",
      "Epoch: 5 Train Loss: 0.14145620776340365 Test Loss: 0.1441107707978866\n",
      "Epoch: 6 Train Loss: 0.147462678713724 Test Loss: 0.15382826797658214\n",
      "Epoch: 7 Train Loss: 0.14373377294912934 Test Loss: 0.14407824253895507\n",
      "Epoch: 8 Train Loss: 0.13965265833698212 Test Loss: 0.1468181220424799\n",
      "Epoch: 9 Train Loss: 0.13955320623144507 Test Loss: 0.16451116718542272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:18:01,361]\u001b[0m Trial 104 finished with value: 0.6833602584814217 and parameters: {'hidden_size': 75, 'num_layers': 1, 'lstm_dropout': 0.12797559791213994, 'fc_dropout': 0.0693566582050073, 'bidirectional': True, 'conv_dropout': 0.00010492618400500392, 'out_channels': 11, 'lr': 0.0022076693160752647}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1448738522067666 Test Loss: 0.1535441996380925\n",
      "Epoch: 1 Train Loss: 0.20153240266979555 Test Loss: 0.17489719543808374\n",
      "Epoch: 2 Train Loss: 0.19320883629568852 Test Loss: 0.16438301859762722\n",
      "Epoch: 3 Train Loss: 0.19896006556870416 Test Loss: 0.2051620989526137\n",
      "Epoch: 4 Train Loss: 0.1937905805970542 Test Loss: 0.19895289617757234\n",
      "Epoch: 5 Train Loss: 0.18922329309834168 Test Loss: 0.1734329456368241\n",
      "Epoch: 6 Train Loss: 0.18759571272060274 Test Loss: 0.19506754033481732\n",
      "Epoch: 7 Train Loss: 0.19100793981170283 Test Loss: 0.17133723846235024\n",
      "Epoch: 8 Train Loss: 0.18773783878739922 Test Loss: 0.17656275003958052\n",
      "Epoch: 9 Train Loss: 0.1869684653497883 Test Loss: 0.1633469700343169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:19:03,828]\u001b[0m Trial 105 finished with value: 0.6656 and parameters: {'hidden_size': 95, 'num_layers': 1, 'lstm_dropout': 0.1631513196122142, 'fc_dropout': 0.03822165524237015, 'bidirectional': True, 'conv_dropout': 0.032598450506793206, 'out_channels': 18, 'lr': 0.007646970651374983}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.20713882175156503 Test Loss: 0.2098009465823914\n",
      "Epoch: 1 Train Loss: 0.20057837530970574 Test Loss: 0.19474311161060304\n",
      "Epoch: 2 Train Loss: 0.190020999066066 Test Loss: 0.21754163529421872\n",
      "Epoch: 3 Train Loss: 0.20214110345602967 Test Loss: 0.15829450464227235\n",
      "Epoch: 4 Train Loss: 0.19012730788776536 Test Loss: 0.16148225589545248\n",
      "Epoch: 5 Train Loss: 0.18646081877031828 Test Loss: 0.17612590280453713\n",
      "Epoch: 6 Train Loss: 0.19093058119306808 Test Loss: 0.15410807335707613\n",
      "Epoch: 7 Train Loss: 0.18824180656007958 Test Loss: 0.15456598403509528\n",
      "Epoch: 8 Train Loss: 0.18896401584444103 Test Loss: 0.16493584498310812\n",
      "Epoch: 9 Train Loss: 0.18684529672828504 Test Loss: 0.17694265552507804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:20:42,598]\u001b[0m Trial 106 finished with value: 0.6834008097165992 and parameters: {'hidden_size': 169, 'num_layers': 1, 'lstm_dropout': 0.14169865003044957, 'fc_dropout': 0.10059055002743612, 'bidirectional': True, 'conv_dropout': 0.060912967009670506, 'out_channels': 29, 'lr': 0.004798120330266959}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18706063185017555 Test Loss: 0.1601892297792906\n",
      "Epoch: 1 Train Loss: 0.2224127442273544 Test Loss: 0.22229974059582935\n",
      "Epoch: 2 Train Loss: 0.19054406726974993 Test Loss: 0.17128572477914464\n",
      "Epoch: 3 Train Loss: 0.20904316763301395 Test Loss: 0.21760919371161597\n",
      "Epoch: 4 Train Loss: 0.1956242181878537 Test Loss: 0.17731015043654524\n",
      "Epoch: 5 Train Loss: 0.20680231861546636 Test Loss: 0.17313106236354517\n",
      "Epoch: 6 Train Loss: 0.1974215465105721 Test Loss: 0.2041149298874691\n",
      "Epoch: 7 Train Loss: 0.1857859022035729 Test Loss: 0.16415726604719702\n",
      "Epoch: 8 Train Loss: 0.17901676383512094 Test Loss: 0.2610676155336158\n",
      "Epoch: 9 Train Loss: 0.18279401138969698 Test Loss: 0.18066153625329842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:21:36,691]\u001b[0m Trial 107 finished with value: 0.6671814671814671 and parameters: {'hidden_size': 54, 'num_layers': 1, 'lstm_dropout': 0.08252715138475838, 'fc_dropout': 0.004653802832631226, 'bidirectional': True, 'conv_dropout': 0.08792273542922191, 'out_channels': 22, 'lr': 0.010349868150834041}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.19035929019832984 Test Loss: 0.1695978629608124\n",
      "Epoch: 1 Train Loss: 0.15702727849036455 Test Loss: 0.15425399581666666\n",
      "Epoch: 2 Train Loss: 0.14724381854385138 Test Loss: 0.14296177627084355\n",
      "Epoch: 3 Train Loss: 0.14263867409080266 Test Loss: 0.1423340939080563\n",
      "Epoch: 4 Train Loss: 0.1423660819247365 Test Loss: 0.16854351499793344\n",
      "Epoch: 5 Train Loss: 0.13795841920375823 Test Loss: 0.15111003858974567\n",
      "Epoch: 6 Train Loss: 0.14143567183464767 Test Loss: 0.13673166959240032\n",
      "Epoch: 7 Train Loss: 0.13856755073815585 Test Loss: 0.1392006234090311\n",
      "Epoch: 8 Train Loss: 0.1382675179719925 Test Loss: 0.1395273035951554\n",
      "Epoch: 9 Train Loss: 0.13667812439501287 Test Loss: 0.14860460229408437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:22:36,429]\u001b[0m Trial 108 finished with value: 0.6881720430107527 and parameters: {'hidden_size': 70, 'num_layers': 1, 'lstm_dropout': 0.11251569449334911, 'fc_dropout': 0.05551878616193244, 'bidirectional': False, 'conv_dropout': 0.0431269991768912, 'out_channels': 14, 'lr': 0.0022742957909620584}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13842522591128945 Test Loss: 0.1399695859722103\n",
      "Epoch: 1 Train Loss: 0.21587484816755168 Test Loss: 0.17969253796417586\n",
      "Epoch: 2 Train Loss: 0.18317603411246092 Test Loss: 0.28095824319680335\n",
      "Epoch: 3 Train Loss: 0.19385122107395436 Test Loss: 0.17629797149080628\n",
      "Epoch: 4 Train Loss: 0.20014554641396207 Test Loss: 0.2669448776505538\n",
      "Epoch: 5 Train Loss: 0.19657944915519912 Test Loss: 0.22946907220201526\n",
      "Epoch: 6 Train Loss: 0.20753618191380518 Test Loss: 0.2107186012201386\n",
      "Epoch: 7 Train Loss: 0.20450929046457167 Test Loss: 0.15808170527731552\n",
      "Epoch: 8 Train Loss: 0.21178102942719707 Test Loss: 0.19130254039070763\n",
      "Epoch: 9 Train Loss: 0.19714970159583609 Test Loss: 0.18873261235812053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:23:38,628]\u001b[0m Trial 109 finished with value: 0.6517412935323383 and parameters: {'hidden_size': 210, 'num_layers': 1, 'lstm_dropout': 0.030826733576376636, 'fc_dropout': 0.04381128734404252, 'bidirectional': True, 'conv_dropout': 0.02549342162271556, 'out_channels': 15, 'lr': 0.006301712190484094}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18428519388309214 Test Loss: 0.1924406834446584\n",
      "Epoch: 1 Train Loss: 0.17463650638982653 Test Loss: 0.15494979977512513\n",
      "Epoch: 2 Train Loss: 0.1651274044211954 Test Loss: 0.1717768606652443\n",
      "Epoch: 3 Train Loss: 0.1570402468010783 Test Loss: 0.22817233483903646\n",
      "Epoch: 4 Train Loss: 0.16085961980398278 Test Loss: 0.15958799866917797\n",
      "Epoch: 5 Train Loss: 0.1629422299232334 Test Loss: 0.15266627860597717\n",
      "Epoch: 6 Train Loss: 0.15671774011962117 Test Loss: 0.17616550419658136\n",
      "Epoch: 7 Train Loss: 0.1566122344709933 Test Loss: 0.15182263845690905\n",
      "Epoch: 8 Train Loss: 0.16333396137570963 Test Loss: 0.15601484234126423\n",
      "Epoch: 9 Train Loss: 0.1669605535261333 Test Loss: 0.16758662284003756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:24:35,138]\u001b[0m Trial 110 finished with value: 0.691900075700227 and parameters: {'hidden_size': 86, 'num_layers': 1, 'lstm_dropout': 0.09308637105623215, 'fc_dropout': 0.027329070170879422, 'bidirectional': True, 'conv_dropout': 0.013119862234850958, 'out_channels': 25, 'lr': 0.0037384262617996527}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1784215375049971 Test Loss: 0.1578259877652263\n",
      "Epoch: 1 Train Loss: 0.1540176523834467 Test Loss: 0.14927072361849558\n",
      "Epoch: 2 Train Loss: 0.13756296623796224 Test Loss: 0.1419761257942397\n",
      "Epoch: 3 Train Loss: 0.13528208040446044 Test Loss: 0.1382855952035981\n",
      "Epoch: 4 Train Loss: 0.132864622554183 Test Loss: 0.13801773192402653\n",
      "Epoch: 5 Train Loss: 0.12976058575809002 Test Loss: 0.1360785205381366\n",
      "Epoch: 6 Train Loss: 0.12902706459090113 Test Loss: 0.13598794837038927\n",
      "Epoch: 7 Train Loss: 0.1301510578021407 Test Loss: 0.13487090455731168\n",
      "Epoch: 8 Train Loss: 0.12468312542140483 Test Loss: 0.13877421883515084\n",
      "Epoch: 9 Train Loss: 0.12659062654674053 Test Loss: 0.14616019740409125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:25:37,999]\u001b[0m Trial 111 finished with value: 0.6853482786228983 and parameters: {'hidden_size': 114, 'num_layers': 1, 'lstm_dropout': 0.17773858944713475, 'fc_dropout': 0.20519476365369999, 'bidirectional': True, 'conv_dropout': 0.03344755002854232, 'out_channels': 13, 'lr': 0.0005631933776775759}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12668104755133391 Test Loss: 0.1412924886368715\n",
      "Epoch: 1 Train Loss: 0.1603553816974163 Test Loss: 0.14527701580831512\n",
      "Epoch: 2 Train Loss: 0.1370166304692626 Test Loss: 0.14842400553758248\n",
      "Epoch: 3 Train Loss: 0.1323845159754157 Test Loss: 0.13935971619210208\n",
      "Epoch: 4 Train Loss: 0.12866481315344572 Test Loss: 0.13747834053616553\n",
      "Epoch: 5 Train Loss: 0.12582240496426822 Test Loss: 0.13472905386084566\n",
      "Epoch: 6 Train Loss: 0.12584483320564033 Test Loss: 0.13925454563821277\n",
      "Epoch: 7 Train Loss: 0.12403483909517526 Test Loss: 0.13633278186638326\n",
      "Epoch: 8 Train Loss: 0.12130568474382163 Test Loss: 0.13740218292695647\n",
      "Epoch: 9 Train Loss: 0.12064032707214356 Test Loss: 0.13301391849597802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:26:47,164]\u001b[0m Trial 112 finished with value: 0.7051482059282372 and parameters: {'hidden_size': 122, 'num_layers': 1, 'lstm_dropout': 0.1321909836264767, 'fc_dropout': 0.1656222073415948, 'bidirectional': True, 'conv_dropout': 0.05253992591066141, 'out_channels': 7, 'lr': 0.00023942051328395837}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11896405428946018 Test Loss: 0.13198170612176385\n",
      "Epoch: 1 Train Loss: 0.17476581811606884 Test Loss: 0.1623161359907339\n",
      "Epoch: 2 Train Loss: 0.15639994809776545 Test Loss: 0.20142226785044975\n",
      "Epoch: 3 Train Loss: 0.16397014547307046 Test Loss: 0.17912829215058124\n",
      "Epoch: 4 Train Loss: 0.15409755483940243 Test Loss: 0.15301773525750675\n",
      "Epoch: 5 Train Loss: 0.14715286795012653 Test Loss: 0.16634140378861026\n",
      "Epoch: 6 Train Loss: 0.1530111695319414 Test Loss: 0.15055212086310593\n",
      "Epoch: 7 Train Loss: 0.15158807381503284 Test Loss: 0.20548478925761324\n",
      "Epoch: 8 Train Loss: 0.14865229362361132 Test Loss: 0.1438153985435494\n",
      "Epoch: 9 Train Loss: 0.14492898986786604 Test Loss: 0.1447968404002178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:28:01,248]\u001b[0m Trial 113 finished with value: 0.6999999999999998 and parameters: {'hidden_size': 103, 'num_layers': 1, 'lstm_dropout': 0.1353865657980653, 'fc_dropout': 0.11639793355819834, 'bidirectional': True, 'conv_dropout': 0.05677413608802388, 'out_channels': 33, 'lr': 0.002409167027441121}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15514898593202234 Test Loss: 0.1677136843393262\n",
      "Epoch: 1 Train Loss: 0.19641501632407307 Test Loss: 0.1780813127293433\n",
      "Epoch: 2 Train Loss: 0.183195531403739 Test Loss: 0.15997992675846662\n",
      "Epoch: 3 Train Loss: 0.1694299326021224 Test Loss: 0.19341924381903566\n",
      "Epoch: 4 Train Loss: 0.16430897437268868 Test Loss: 0.16053020148969496\n",
      "Epoch: 5 Train Loss: 0.1624194566456601 Test Loss: 0.1616916132543367\n",
      "Epoch: 6 Train Loss: 0.1540960063867271 Test Loss: 0.17383069389562208\n",
      "Epoch: 7 Train Loss: 0.15640133495926856 Test Loss: 0.15208918025223211\n",
      "Epoch: 8 Train Loss: 0.1552318075466901 Test Loss: 0.15938677772516593\n",
      "Epoch: 9 Train Loss: 0.1661297888278961 Test Loss: 0.14488474252267766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:28:44,074]\u001b[0m Trial 114 finished with value: 0.6752205292702487 and parameters: {'hidden_size': 94, 'num_layers': 1, 'lstm_dropout': 0.1487907562552684, 'fc_dropout': 0.161915047368237, 'bidirectional': True, 'conv_dropout': 0.0702701617437109, 'out_channels': 37, 'lr': 0.003481737522601561}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17077636320944875 Test Loss: 0.1761951573853628\n",
      "Epoch: 1 Train Loss: 0.22674360312761274 Test Loss: 0.330054131500812\n",
      "Epoch: 2 Train Loss: 0.1946235324332025 Test Loss: 0.2724401138986226\n",
      "Epoch: 3 Train Loss: 0.19893134002491134 Test Loss: 0.19059687599944422\n",
      "Epoch: 4 Train Loss: 0.19210141831459476 Test Loss: 0.17654953567912213\n",
      "Epoch: 5 Train Loss: 0.20126906148241833 Test Loss: 0.22672891627495792\n",
      "Epoch: 6 Train Loss: 0.22453053525777067 Test Loss: 0.19003099796418754\n",
      "Epoch: 7 Train Loss: 0.18825160730481147 Test Loss: 0.17239827348794134\n",
      "Epoch: 8 Train Loss: 0.19165869361367077 Test Loss: 0.23034116791556783\n",
      "Epoch: 9 Train Loss: 0.2012651654731715 Test Loss: 0.21131693118306907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:29:44,762]\u001b[0m Trial 115 finished with value: 0.6748971193415638 and parameters: {'hidden_size': 103, 'num_layers': 1, 'lstm_dropout': 0.0753420413013016, 'fc_dropout': 0.13206060893324503, 'bidirectional': True, 'conv_dropout': 0.04486125822553218, 'out_channels': 34, 'lr': 0.007074926188023035}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1873505050639622 Test Loss: 0.16906837935740957\n",
      "Epoch: 1 Train Loss: 0.16187603875026108 Test Loss: 0.17017436323883817\n",
      "Epoch: 2 Train Loss: 0.15163917459994555 Test Loss: 0.1508342824197901\n",
      "Epoch: 3 Train Loss: 0.1509713914550841 Test Loss: 0.160111745889373\n",
      "Epoch: 4 Train Loss: 0.1501674583055079 Test Loss: 0.1424944584195416\n",
      "Epoch: 5 Train Loss: 0.14201038638837635 Test Loss: 0.14102552118249975\n",
      "Epoch: 6 Train Loss: 0.14631641827486455 Test Loss: 0.18036228751603026\n",
      "Epoch: 7 Train Loss: 0.14855621098056435 Test Loss: 0.14224876169139108\n",
      "Epoch: 8 Train Loss: 0.14033590056598186 Test Loss: 0.14569275602757836\n",
      "Epoch: 9 Train Loss: 0.14360006516613066 Test Loss: 0.15479087175729986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:30:46,984]\u001b[0m Trial 116 finished with value: 0.6854460093896714 and parameters: {'hidden_size': 44, 'num_layers': 1, 'lstm_dropout': 0.05685186287594357, 'fc_dropout': 0.11384598449217166, 'bidirectional': True, 'conv_dropout': 0.019684770746958673, 'out_channels': 34, 'lr': 0.002118516030416883}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.148859873831179 Test Loss: 0.20472100734176596\n",
      "Epoch: 1 Train Loss: 0.2198252356072805 Test Loss: 0.23682630704805113\n",
      "Epoch: 2 Train Loss: 0.2149478194828611 Test Loss: 0.2217243994220187\n",
      "Epoch: 3 Train Loss: 0.23959416299127043 Test Loss: 0.18040449395344352\n",
      "Epoch: 4 Train Loss: 0.21124931770365218 Test Loss: 0.16974656160075824\n",
      "Epoch: 5 Train Loss: 0.22439465784205023 Test Loss: 0.2899813867178413\n",
      "Epoch: 6 Train Loss: 0.21743425040014555 Test Loss: 0.1834207411034229\n",
      "Epoch: 7 Train Loss: 0.1994229989490239 Test Loss: 0.37681648427746733\n",
      "Epoch: 8 Train Loss: 0.19078674210818716 Test Loss: 0.23155504960816697\n",
      "Epoch: 9 Train Loss: 0.20051251557818614 Test Loss: 0.18667284929648803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:31:50,509]\u001b[0m Trial 117 finished with value: 0.6639344262295083 and parameters: {'hidden_size': 78, 'num_layers': 1, 'lstm_dropout': 0.12880758870641507, 'fc_dropout': 0.1437025568665378, 'bidirectional': True, 'conv_dropout': 0.008767885732278656, 'out_channels': 33, 'lr': 0.00862115278101479}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.21520849506342785 Test Loss: 0.1678483360714782\n",
      "Epoch: 1 Train Loss: 0.16682042160518468 Test Loss: 0.16646435732146897\n",
      "Epoch: 2 Train Loss: 0.16647295416593552 Test Loss: 0.15834547520969242\n",
      "Epoch: 3 Train Loss: 0.16903846818730234 Test Loss: 0.14839753790642507\n",
      "Epoch: 4 Train Loss: 0.1614893286317587 Test Loss: 0.1691178561191256\n",
      "Epoch: 5 Train Loss: 0.1576724550947547 Test Loss: 0.16734136754391007\n",
      "Epoch: 6 Train Loss: 0.16495684402883054 Test Loss: 0.18644397917646952\n",
      "Epoch: 7 Train Loss: 0.16622468827962875 Test Loss: 0.15072812752935072\n",
      "Epoch: 8 Train Loss: 0.1642374575894326 Test Loss: 0.2287561466572241\n",
      "Epoch: 9 Train Loss: 0.16272816603481768 Test Loss: 0.1592963021665145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:32:49,294]\u001b[0m Trial 118 finished with value: 0.6610169491525423 and parameters: {'hidden_size': 108, 'num_layers': 1, 'lstm_dropout': 0.11168360276213822, 'fc_dropout': 0.12297556374016322, 'bidirectional': True, 'conv_dropout': 0.053807706997388224, 'out_channels': 5, 'lr': 0.0051479320260323855}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16116693753376604 Test Loss: 0.14799442282095313\n",
      "Epoch: 1 Train Loss: 1.4737024113432857 Test Loss: 1.2753508909822653\n",
      "Epoch: 2 Train Loss: 1.3153183299326796 Test Loss: 0.2732426979290411\n",
      "Epoch: 3 Train Loss: 1.1720506942254154 Test Loss: 4.787518722180741\n",
      "Epoch: 4 Train Loss: 1.1590128278678753 Test Loss: 0.2724090415282181\n",
      "Epoch: 5 Train Loss: 1.285214683961543 Test Loss: 0.43981011835233375\n",
      "Epoch: 6 Train Loss: 0.9948983478842652 Test Loss: 0.49217428409824737\n",
      "Epoch: 7 Train Loss: 1.065602720241098 Test Loss: 0.2645605002729276\n",
      "Epoch: 8 Train Loss: 1.1652113743989514 Test Loss: 0.2661136568378145\n",
      "Epoch: 9 Train Loss: 1.2035533801559588 Test Loss: 0.5878408786886484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:33:57,412]\u001b[0m Trial 119 finished with value: 0.13797597989014057 and parameters: {'hidden_size': 121, 'num_layers': 3, 'lstm_dropout': 0.06509846603675376, 'fc_dropout': 0.17200240738470052, 'bidirectional': True, 'conv_dropout': 0.03930479959825866, 'out_channels': 9, 'lr': 0.03913298243762278}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 1.1183623997973793 Test Loss: 0.2643324623045068\n",
      "Epoch: 1 Train Loss: 0.251895892618713 Test Loss: 0.18108538829664977\n",
      "Epoch: 2 Train Loss: 0.18461608306597918 Test Loss: 0.16380850841609623\n",
      "Epoch: 3 Train Loss: 0.18595146454982459 Test Loss: 0.17042889786116516\n",
      "Epoch: 4 Train Loss: 0.1857828580209054 Test Loss: 0.18376779104746616\n",
      "Epoch: 5 Train Loss: 0.1962692783440463 Test Loss: 0.1957914085460666\n",
      "Epoch: 6 Train Loss: 0.18786845588842407 Test Loss: 0.1664359650065819\n",
      "Epoch: 7 Train Loss: 0.21120783860785886 Test Loss: 0.17664988216357871\n",
      "Epoch: 8 Train Loss: 0.23305075551925256 Test Loss: 0.20355040722856887\n",
      "Epoch: 9 Train Loss: 0.20931875741209952 Test Loss: 0.15646340045780419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:34:54,032]\u001b[0m Trial 120 finished with value: 0.6666666666666667 and parameters: {'hidden_size': 90, 'num_layers': 1, 'lstm_dropout': 0.043334864683024825, 'fc_dropout': 0.08171535886963242, 'bidirectional': False, 'conv_dropout': 0.07560563509206102, 'out_channels': 39, 'lr': 0.011681186194818324}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.19832388996137307 Test Loss: 0.2831784667307362\n",
      "Epoch: 1 Train Loss: 0.1573295373365283 Test Loss: 0.1459972072309389\n",
      "Epoch: 2 Train Loss: 0.13720157210379838 Test Loss: 0.1462082201823259\n",
      "Epoch: 3 Train Loss: 0.13364223320782184 Test Loss: 0.1413128294122105\n",
      "Epoch: 4 Train Loss: 0.1316435039997101 Test Loss: 0.13964269297143903\n",
      "Epoch: 5 Train Loss: 0.12957339446395635 Test Loss: 0.14070255917827257\n",
      "Epoch: 6 Train Loss: 0.12940785253643988 Test Loss: 0.1383543297969781\n",
      "Epoch: 7 Train Loss: 0.12860319841504098 Test Loss: 0.14282841812045619\n",
      "Epoch: 8 Train Loss: 0.12742350768595934 Test Loss: 0.1366039298462887\n",
      "Epoch: 9 Train Loss: 0.12604960573017598 Test Loss: 0.13767867286305743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:35:49,092]\u001b[0m Trial 121 finished with value: 0.6807817589576547 and parameters: {'hidden_size': 133, 'num_layers': 1, 'lstm_dropout': 0.15895984491241552, 'fc_dropout': 0.06536850488051235, 'bidirectional': True, 'conv_dropout': 0.06507251666226199, 'out_channels': 7, 'lr': 0.00045425295242203543}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12585539181679486 Test Loss: 0.13853265480182994\n",
      "Epoch: 1 Train Loss: 0.15996513835787773 Test Loss: 0.14560586951089838\n",
      "Epoch: 2 Train Loss: 0.13694938753843308 Test Loss: 0.14152382080333112\n",
      "Epoch: 3 Train Loss: 0.1324592143177986 Test Loss: 0.13816777735758132\n",
      "Epoch: 4 Train Loss: 0.12943168176859618 Test Loss: 0.14204321534465106\n",
      "Epoch: 5 Train Loss: 0.12794025717228652 Test Loss: 0.1374062934307197\n",
      "Epoch: 6 Train Loss: 0.12580241410285234 Test Loss: 0.13505676173316405\n",
      "Epoch: 7 Train Loss: 0.12420548860430718 Test Loss: 0.13823512052230466\n",
      "Epoch: 8 Train Loss: 0.12246416985690593 Test Loss: 0.13740909849695218\n",
      "Epoch: 9 Train Loss: 0.12073583213835955 Test Loss: 0.13410912099154518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:36:47,368]\u001b[0m Trial 122 finished with value: 0.6886274509803921 and parameters: {'hidden_size': 140, 'num_layers': 1, 'lstm_dropout': 0.14302278299575324, 'fc_dropout': 0.19499110933549887, 'bidirectional': True, 'conv_dropout': 0.05594752200230019, 'out_channels': 10, 'lr': 0.00021198128019694917}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11966923282146454 Test Loss: 0.13613976217127932\n",
      "Epoch: 1 Train Loss: 0.19043326698644086 Test Loss: 0.152292714885677\n",
      "Epoch: 2 Train Loss: 0.17761944478279912 Test Loss: 0.21758786398644436\n",
      "Epoch: 3 Train Loss: 0.18587816698006354 Test Loss: 0.16532340997639602\n",
      "Epoch: 4 Train Loss: 0.1697422609327652 Test Loss: 0.20611484699879593\n",
      "Epoch: 5 Train Loss: 0.16700011908332818 Test Loss: 0.15018859405082446\n",
      "Epoch: 6 Train Loss: 0.1658427273464389 Test Loss: 0.15734204168791494\n",
      "Epoch: 7 Train Loss: 0.17245162188829855 Test Loss: 0.15612068580100522\n",
      "Epoch: 8 Train Loss: 0.168393709596619 Test Loss: 0.14555785196205487\n",
      "Epoch: 9 Train Loss: 0.17204603241325822 Test Loss: 0.2144835678809962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:37:39,419]\u001b[0m Trial 123 finished with value: 0.6898113207547171 and parameters: {'hidden_size': 118, 'num_layers': 1, 'lstm_dropout': 0.13367514093904578, 'fc_dropout': 0.09823233256290581, 'bidirectional': True, 'conv_dropout': 0.02590743906797683, 'out_channels': 36, 'lr': 0.0033081029487903747}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18368360666451045 Test Loss: 0.1574218959604113\n",
      "Epoch: 1 Train Loss: 0.18523378840156365 Test Loss: 0.16436406837913176\n",
      "Epoch: 2 Train Loss: 0.16417203230834565 Test Loss: 0.17556348106505487\n",
      "Epoch: 3 Train Loss: 0.1589362211342901 Test Loss: 0.1571783872541433\n",
      "Epoch: 4 Train Loss: 0.1698613335369155 Test Loss: 0.16065639238388013\n",
      "Epoch: 5 Train Loss: 0.1686603116239421 Test Loss: 0.2006363668047582\n",
      "Epoch: 6 Train Loss: 0.16956546289757826 Test Loss: 0.15801701971445792\n",
      "Epoch: 7 Train Loss: 0.17118251399560833 Test Loss: 0.15857089744113123\n",
      "Epoch: 8 Train Loss: 0.1700204064455116 Test Loss: 0.2356282917362565\n",
      "Epoch: 9 Train Loss: 0.17894968996448443 Test Loss: 0.15442860266640068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:38:42,294]\u001b[0m Trial 124 finished with value: 0.6794258373205742 and parameters: {'hidden_size': 147, 'num_layers': 1, 'lstm_dropout': 0.16883695835922627, 'fc_dropout': 0.01860974715340874, 'bidirectional': True, 'conv_dropout': 0.04816296116035926, 'out_channels': 12, 'lr': 0.005593044082432405}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16571030797269196 Test Loss: 0.16414885324077866\n",
      "Epoch: 1 Train Loss: 0.15906348587647082 Test Loss: 0.14919787355231495\n",
      "Epoch: 2 Train Loss: 0.14774658841192723 Test Loss: 0.14483388218754967\n",
      "Epoch: 3 Train Loss: 0.14937687757462262 Test Loss: 0.14848002355795697\n",
      "Epoch: 4 Train Loss: 0.14460916076153515 Test Loss: 0.14824556882460468\n",
      "Epoch: 5 Train Loss: 0.15063915538340808 Test Loss: 0.1620971008855552\n",
      "Epoch: 6 Train Loss: 0.1482247602827847 Test Loss: 0.15604741904682246\n",
      "Epoch: 7 Train Loss: 0.15045163020454347 Test Loss: 0.15538151743122564\n",
      "Epoch: 8 Train Loss: 0.15098982490301133 Test Loss: 0.1586081964862399\n",
      "Epoch: 9 Train Loss: 0.14835994114913045 Test Loss: 0.1493001570984626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:39:30,700]\u001b[0m Trial 125 finished with value: 0.6786833855799372 and parameters: {'hidden_size': 127, 'num_layers': 1, 'lstm_dropout': 0.12382542461864274, 'fc_dropout': 0.10620551682192252, 'bidirectional': True, 'conv_dropout': 0.09304380493764805, 'out_channels': 6, 'lr': 0.0026065036191361365}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14953526362776756 Test Loss: 0.16749768549600205\n",
      "Epoch: 1 Train Loss: 0.1646149197101593 Test Loss: 0.1488432620916837\n",
      "Epoch: 2 Train Loss: 0.148940791336447 Test Loss: 0.14897508847232635\n",
      "Epoch: 3 Train Loss: 0.14467709069848061 Test Loss: 0.1528484559299561\n",
      "Epoch: 4 Train Loss: 0.14308214512243866 Test Loss: 0.1476530027203857\n",
      "Epoch: 5 Train Loss: 0.15103908298015595 Test Loss: 0.1456144104678981\n",
      "Epoch: 6 Train Loss: 0.1504985280316323 Test Loss: 0.143946121634243\n",
      "Epoch: 7 Train Loss: 0.1477426300726831 Test Loss: 0.14433277271295222\n",
      "Epoch: 8 Train Loss: 0.14639886390939355 Test Loss: 0.14584813400293692\n",
      "Epoch: 9 Train Loss: 0.14834477545637637 Test Loss: 0.14564893837161244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:40:27,063]\u001b[0m Trial 126 finished with value: 0.6763518966908798 and parameters: {'hidden_size': 103, 'num_layers': 1, 'lstm_dropout': 0.09012410076720626, 'fc_dropout': 0.13528781509444388, 'bidirectional': True, 'conv_dropout': 0.03206415188835522, 'out_channels': 32, 'lr': 0.0018081292980637745}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14500454354584216 Test Loss: 0.14446820696583762\n",
      "Epoch: 1 Train Loss: 0.16468383095562458 Test Loss: 0.1552489562192188\n",
      "Epoch: 2 Train Loss: 0.1551733162857592 Test Loss: 0.1655238353864501\n",
      "Epoch: 3 Train Loss: 0.15426634373106063 Test Loss: 0.15954205644325897\n",
      "Epoch: 4 Train Loss: 0.1452551980547607 Test Loss: 0.1466099373555888\n",
      "Epoch: 5 Train Loss: 0.15020042366981506 Test Loss: 0.1499426867396306\n",
      "Epoch: 6 Train Loss: 0.1503442243816331 Test Loss: 0.1512991961079855\n",
      "Epoch: 7 Train Loss: 0.14995989438444376 Test Loss: 0.15230245942684312\n",
      "Epoch: 8 Train Loss: 0.15329676991179586 Test Loss: 0.16657456222433634\n",
      "Epoch: 9 Train Loss: 0.15408662558831274 Test Loss: 0.14622607170797575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:41:22,297]\u001b[0m Trial 127 finished with value: 0.6721044045676998 and parameters: {'hidden_size': 37, 'num_layers': 1, 'lstm_dropout': 0.1011229391178037, 'fc_dropout': 0.03300832482050083, 'bidirectional': True, 'conv_dropout': 0.018953364774192336, 'out_channels': 15, 'lr': 0.004563684603757574}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1458757267408073 Test Loss: 0.1534183434041116\n",
      "Epoch: 1 Train Loss: 0.1936605512412265 Test Loss: 0.17334670807196262\n",
      "Epoch: 2 Train Loss: 0.18829454633253626 Test Loss: 0.18615915359685214\n",
      "Epoch: 3 Train Loss: 0.18121651697140187 Test Loss: 0.23431754130579996\n",
      "Epoch: 4 Train Loss: 0.18250711923912166 Test Loss: 0.16575813983766416\n",
      "Epoch: 5 Train Loss: 0.17512379404241218 Test Loss: 0.16305697556977836\n",
      "Epoch: 6 Train Loss: 0.16915573457274585 Test Loss: 0.16067893348765164\n",
      "Epoch: 7 Train Loss: 0.1651628221269697 Test Loss: 0.19162886189118314\n",
      "Epoch: 8 Train Loss: 0.1667456152431667 Test Loss: 0.1579807818400117\n",
      "Epoch: 9 Train Loss: 0.17207408667653798 Test Loss: 0.16698117580967017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:42:18,140]\u001b[0m Trial 128 finished with value: 0.658312447786132 and parameters: {'hidden_size': 60, 'num_layers': 1, 'lstm_dropout': 0.11413564431210116, 'fc_dropout': 0.08778036713553869, 'bidirectional': True, 'conv_dropout': 0.08086051654936513, 'out_channels': 10, 'lr': 0.009092436793854776}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17752394928950815 Test Loss: 0.16262235172902242\n",
      "Epoch: 1 Train Loss: 0.18020738509893416 Test Loss: 0.14860679354435338\n",
      "Epoch: 2 Train Loss: 0.1385403370141983 Test Loss: 0.1447630362382855\n",
      "Epoch: 3 Train Loss: 0.13542502302080392 Test Loss: 0.14174492194498786\n",
      "Epoch: 4 Train Loss: 0.13300922553688288 Test Loss: 0.13827709892032722\n",
      "Epoch: 5 Train Loss: 0.1298736266121268 Test Loss: 0.13787629857016637\n",
      "Epoch: 6 Train Loss: 0.12941494137346746 Test Loss: 0.13677563702764983\n",
      "Epoch: 7 Train Loss: 0.12819838006794454 Test Loss: 0.13643653404574616\n",
      "Epoch: 8 Train Loss: 0.1279716156706214 Test Loss: 0.13514953575576075\n",
      "Epoch: 9 Train Loss: 0.12694191346913575 Test Loss: 0.13633366996725907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:43:14,307]\u001b[0m Trial 129 finished with value: 0.689935064935065 and parameters: {'hidden_size': 49, 'num_layers': 1, 'lstm_dropout': 0.19507232087888415, 'fc_dropout': 0.056916045960725824, 'bidirectional': True, 'conv_dropout': 0.11903260634844104, 'out_channels': 9, 'lr': 0.00012738804401619367}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12558084703832864 Test Loss: 0.134192422163277\n",
      "Epoch: 1 Train Loss: 0.19531862454870716 Test Loss: 0.16409928880084437\n",
      "Epoch: 2 Train Loss: 0.19850582007975318 Test Loss: 0.26928109722267746\n",
      "Epoch: 3 Train Loss: 0.18833207546300254 Test Loss: 0.17740245629994633\n",
      "Epoch: 4 Train Loss: 0.19355476767688523 Test Loss: 0.16692388970732167\n",
      "Epoch: 5 Train Loss: 0.2091036029683659 Test Loss: 0.20685071286525183\n",
      "Epoch: 6 Train Loss: 0.19108542983029037 Test Loss: 0.21010310152179587\n",
      "Epoch: 7 Train Loss: 0.18822542383205146 Test Loss: 0.19986938360182885\n",
      "Epoch: 8 Train Loss: 0.1962626516492106 Test Loss: 0.15302943604620406\n",
      "Epoch: 9 Train Loss: 0.17567983489371836 Test Loss: 0.1584722057234841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:44:07,081]\u001b[0m Trial 130 finished with value: 0.6533333333333333 and parameters: {'hidden_size': 111, 'num_layers': 1, 'lstm_dropout': 0.013943379058715299, 'fc_dropout': 0.17955536853811355, 'bidirectional': True, 'conv_dropout': 0.060731518312707275, 'out_channels': 17, 'lr': 0.006231320243584776}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1869178277723491 Test Loss: 0.16173841048198673\n",
      "Epoch: 1 Train Loss: 0.15587898193076252 Test Loss: 0.14375458802944555\n",
      "Epoch: 2 Train Loss: 0.14343082066327334 Test Loss: 0.14097555301869258\n",
      "Epoch: 3 Train Loss: 0.13963735494762658 Test Loss: 0.14268635582333555\n",
      "Epoch: 4 Train Loss: 0.14262752421908081 Test Loss: 0.14452267274968683\n",
      "Epoch: 5 Train Loss: 0.1426065850429237 Test Loss: 0.1480007792849796\n",
      "Epoch: 6 Train Loss: 0.14052503619492054 Test Loss: 0.1368400207259499\n",
      "Epoch: 7 Train Loss: 0.13823173147663473 Test Loss: 0.14416526551968373\n",
      "Epoch: 8 Train Loss: 0.13954519408717753 Test Loss: 0.13645631019561627\n",
      "Epoch: 9 Train Loss: 0.13931591175198554 Test Loss: 0.1401196749993978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:45:00,972]\u001b[0m Trial 131 finished with value: 0.6825019794140935 and parameters: {'hidden_size': 125, 'num_layers': 1, 'lstm_dropout': 0.130943919651145, 'fc_dropout': 0.15718647164305927, 'bidirectional': True, 'conv_dropout': 0.03874728582508636, 'out_channels': 8, 'lr': 0.0019127615643589678}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1383928279168904 Test Loss: 0.13765130862712668\n",
      "Epoch: 1 Train Loss: 0.17736039975397289 Test Loss: 0.18155204941676303\n",
      "Epoch: 2 Train Loss: 0.16118474105782807 Test Loss: 0.16494216385502786\n",
      "Epoch: 3 Train Loss: 0.16454304307661952 Test Loss: 0.15377232829293314\n",
      "Epoch: 4 Train Loss: 0.16759191828109324 Test Loss: 0.1631424454436563\n",
      "Epoch: 5 Train Loss: 0.16253943436127155 Test Loss: 0.17386610830982271\n",
      "Epoch: 6 Train Loss: 0.16109211232103407 Test Loss: 0.16199547036910972\n",
      "Epoch: 7 Train Loss: 0.15806624982506037 Test Loss: 0.17536146806094782\n",
      "Epoch: 8 Train Loss: 0.162414565288648 Test Loss: 0.17695657646331114\n",
      "Epoch: 9 Train Loss: 0.16310271094590426 Test Loss: 0.15163095340061303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:45:56,282]\u001b[0m Trial 132 finished with value: 0.6805555555555555 and parameters: {'hidden_size': 98, 'num_layers': 1, 'lstm_dropout': 0.15455502646913818, 'fc_dropout': 0.2184968162050417, 'bidirectional': True, 'conv_dropout': 0.01084607726902416, 'out_channels': 11, 'lr': 0.0038837242907315142}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15397106322571635 Test Loss: 0.14665874500517934\n",
      "Epoch: 1 Train Loss: 0.15430206547454 Test Loss: 0.14301160774149071\n",
      "Epoch: 2 Train Loss: 0.13182011979669334 Test Loss: 0.14302175967826153\n",
      "Epoch: 3 Train Loss: 0.12833269955813884 Test Loss: 0.13264484928486447\n",
      "Epoch: 4 Train Loss: 0.12412638821452857 Test Loss: 0.13423622712290612\n",
      "Epoch: 5 Train Loss: 0.12105635601878166 Test Loss: 0.13505831165030932\n",
      "Epoch: 6 Train Loss: 0.11903501957058907 Test Loss: 0.13181484572458477\n",
      "Epoch: 7 Train Loss: 0.11726608672887087 Test Loss: 0.13601532072340622\n",
      "Epoch: 8 Train Loss: 0.11485764172002673 Test Loss: 0.13357863062248823\n",
      "Epoch: 9 Train Loss: 0.11351214140504598 Test Loss: 0.1348621399638752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:47:06,162]\u001b[0m Trial 133 finished with value: 0.6984375 and parameters: {'hidden_size': 115, 'num_layers': 1, 'lstm_dropout': 0.14231393162615108, 'fc_dropout': 0.19465056683587775, 'bidirectional': True, 'conv_dropout': 0.0010523623884246165, 'out_channels': 13, 'lr': 0.00023528861730644376}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11091551694720983 Test Loss: 0.1350235947357199\n",
      "Epoch: 1 Train Loss: 0.1605479335360229 Test Loss: 0.1460236868740747\n",
      "Epoch: 2 Train Loss: 0.1489311469130218 Test Loss: 0.14032140197440648\n",
      "Epoch: 3 Train Loss: 0.14487316795513033 Test Loss: 0.14567198884634736\n",
      "Epoch: 4 Train Loss: 0.14355377833731472 Test Loss: 0.1456053614937745\n",
      "Epoch: 5 Train Loss: 0.1421573618888855 Test Loss: 0.14462700213629978\n",
      "Epoch: 6 Train Loss: 0.1398596074692905 Test Loss: 0.16435509179376614\n",
      "Epoch: 7 Train Loss: 0.14299964658170938 Test Loss: 0.1490212444947979\n",
      "Epoch: 8 Train Loss: 0.1392358158916235 Test Loss: 0.14300821652522863\n",
      "Epoch: 9 Train Loss: 0.1443942966401577 Test Loss: 0.14149542359379344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:48:15,744]\u001b[0m Trial 134 finished with value: 0.6961240310077519 and parameters: {'hidden_size': 133, 'num_layers': 1, 'lstm_dropout': 0.1410034914935617, 'fc_dropout': 0.1682513862606958, 'bidirectional': True, 'conv_dropout': 0.001100836467689773, 'out_channels': 13, 'lr': 0.002094872400719781}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13907437868639827 Test Loss: 0.1390727434825069\n",
      "Epoch: 1 Train Loss: 0.19189672160912305 Test Loss: 0.15700364124160796\n",
      "Epoch: 2 Train Loss: 0.18705393763408065 Test Loss: 0.19200478935578522\n",
      "Epoch: 3 Train Loss: 0.18363886114982889 Test Loss: 0.23203960244724983\n",
      "Epoch: 4 Train Loss: 0.18246308838604017 Test Loss: 0.16970369505722777\n",
      "Epoch: 5 Train Loss: 0.17715688938996754 Test Loss: 0.18919116217336548\n",
      "Epoch: 6 Train Loss: 0.1889817795935058 Test Loss: 0.17816814345370133\n",
      "Epoch: 7 Train Loss: 0.189976728622918 Test Loss: 0.18694100388513205\n",
      "Epoch: 8 Train Loss: 0.18928038754221052 Test Loss: 0.17432623188466595\n",
      "Epoch: 9 Train Loss: 0.1835851013562642 Test Loss: 0.17962703684243722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:49:10,182]\u001b[0m Trial 135 finished with value: 0.6776119402985075 and parameters: {'hidden_size': 106, 'num_layers': 1, 'lstm_dropout': 0.10465070005540793, 'fc_dropout': 0.012075738960542863, 'bidirectional': True, 'conv_dropout': 0.02477664411672665, 'out_channels': 16, 'lr': 0.007649491946183096}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.2094760787418112 Test Loss: 0.19141207991269069\n",
      "Epoch: 1 Train Loss: 0.19598633456788958 Test Loss: 0.15713458417501217\n",
      "Epoch: 2 Train Loss: 0.1775059413987212 Test Loss: 0.26616914667778263\n",
      "Epoch: 3 Train Loss: 0.19934055862168315 Test Loss: 0.19484975179002736\n",
      "Epoch: 4 Train Loss: 0.18031679134960285 Test Loss: 0.23723042025692023\n",
      "Epoch: 5 Train Loss: 0.18983811180298216 Test Loss: 0.1610389391359049\n",
      "Epoch: 6 Train Loss: 0.19102613947317004 Test Loss: 0.18315602572688375\n",
      "Epoch: 7 Train Loss: 0.18990344936372713 Test Loss: 0.19960238371556177\n",
      "Epoch: 8 Train Loss: 0.18197885031173938 Test Loss: 0.1573095655205627\n",
      "Epoch: 9 Train Loss: 0.19204567543570883 Test Loss: 0.16118742211814077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:50:07,584]\u001b[0m Trial 136 finished with value: 0.6792156862745098 and parameters: {'hidden_size': 243, 'num_layers': 1, 'lstm_dropout': 0.12103956313110872, 'fc_dropout': 0.1895018113275151, 'bidirectional': True, 'conv_dropout': 0.00013195265352729225, 'out_channels': 14, 'lr': 0.004474131581438995}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18585751694323263 Test Loss: 0.23708104524395454\n",
      "Epoch: 1 Train Loss: 0.15758876893818377 Test Loss: 0.14197810749395395\n",
      "Epoch: 2 Train Loss: 0.13261243829727173 Test Loss: 0.13711892261791725\n",
      "Epoch: 3 Train Loss: 0.12810887226462364 Test Loss: 0.136292315085237\n",
      "Epoch: 4 Train Loss: 0.12463046303540468 Test Loss: 0.1396916831989353\n",
      "Epoch: 5 Train Loss: 0.12311611990034581 Test Loss: 0.13934560331959314\n",
      "Epoch: 6 Train Loss: 0.11966335480064154 Test Loss: 0.1348791262283683\n",
      "Epoch: 7 Train Loss: 0.11721707132607699 Test Loss: 0.1321872122550068\n",
      "Epoch: 8 Train Loss: 0.11668019528537989 Test Loss: 0.13304774312022777\n",
      "Epoch: 9 Train Loss: 0.1133609505429864 Test Loss: 0.1373641025066709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:51:03,001]\u001b[0m Trial 137 finished with value: 0.6966292134831461 and parameters: {'hidden_size': 113, 'num_layers': 1, 'lstm_dropout': 0.037087948949883195, 'fc_dropout': 0.0747412304750385, 'bidirectional': True, 'conv_dropout': 0.014725610096378766, 'out_channels': 12, 'lr': 0.0001974569275263209}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11120819056108594 Test Loss: 0.13251999946543203\n",
      "Epoch: 1 Train Loss: 0.15812332678437233 Test Loss: 0.14615980309014692\n",
      "Epoch: 2 Train Loss: 0.13222601296156644 Test Loss: 0.1380155429291649\n",
      "Epoch: 3 Train Loss: 0.12837298158705235 Test Loss: 0.1379163076404851\n",
      "Epoch: 4 Train Loss: 0.12574386010468006 Test Loss: 0.13479824881619826\n",
      "Epoch: 5 Train Loss: 0.12218952807337045 Test Loss: 0.134224781647515\n",
      "Epoch: 6 Train Loss: 0.12068852842599154 Test Loss: 0.14268741062500132\n",
      "Epoch: 7 Train Loss: 0.11780486460775137 Test Loss: 0.1331579232106384\n",
      "Epoch: 8 Train Loss: 0.11596339233666658 Test Loss: 0.13222990960430223\n",
      "Epoch: 9 Train Loss: 0.11246877040416002 Test Loss: 0.13912239893616293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:51:55,766]\u001b[0m Trial 138 finished with value: 0.7039106145251397 and parameters: {'hidden_size': 95, 'num_layers': 1, 'lstm_dropout': 0.037461094034305115, 'fc_dropout': 0.07525746061988628, 'bidirectional': True, 'conv_dropout': 0.013393443983779708, 'out_channels': 15, 'lr': 0.00015022459717349768}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11096592486947775 Test Loss: 0.14056357751174953\n",
      "Epoch: 1 Train Loss: 0.1761614461414516 Test Loss: 0.15923499810798003\n",
      "Epoch: 2 Train Loss: 0.16824647144004704 Test Loss: 0.1615895565402822\n",
      "Epoch: 3 Train Loss: 0.16944289925545453 Test Loss: 0.17554303893027975\n",
      "Epoch: 4 Train Loss: 0.17673735004868357 Test Loss: 0.16057412943448693\n",
      "Epoch: 5 Train Loss: 0.16868443921534346 Test Loss: 0.15683484949861853\n",
      "Epoch: 6 Train Loss: 0.17466001211507245 Test Loss: 0.15280796076876288\n",
      "Epoch: 7 Train Loss: 0.17414189737174893 Test Loss: 0.1574063972114755\n",
      "Epoch: 8 Train Loss: 0.16672058724910022 Test Loss: 0.16427326074149756\n",
      "Epoch: 9 Train Loss: 0.17801828580723378 Test Loss: 0.16667080909823076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:52:52,295]\u001b[0m Trial 139 finished with value: 0.6818181818181819 and parameters: {'hidden_size': 81, 'num_layers': 1, 'lstm_dropout': 0.03074101545686886, 'fc_dropout': 0.09310246518133085, 'bidirectional': True, 'conv_dropout': 0.0282772456133735, 'out_channels': 16, 'lr': 0.005926688770214866}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17640733369803055 Test Loss: 0.15586014634992082\n",
      "Epoch: 1 Train Loss: 0.1715742544196546 Test Loss: 0.16493685818470705\n",
      "Epoch: 2 Train Loss: 0.15698589947149158 Test Loss: 0.15495881400169276\n",
      "Epoch: 3 Train Loss: 0.1569974611390382 Test Loss: 0.14487211112254345\n",
      "Epoch: 4 Train Loss: 0.15413550159931183 Test Loss: 0.15240177552635298\n",
      "Epoch: 5 Train Loss: 0.15677946210429072 Test Loss: 0.15005426531949173\n",
      "Epoch: 6 Train Loss: 0.15336984903793782 Test Loss: 0.14905734614025765\n",
      "Epoch: 7 Train Loss: 0.15034474108889698 Test Loss: 0.1534027952534227\n",
      "Epoch: 8 Train Loss: 0.15205693941265344 Test Loss: 0.16311606874885842\n",
      "Epoch: 9 Train Loss: 0.15713743358328938 Test Loss: 0.16731153086672862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:53:44,113]\u001b[0m Trial 140 finished with value: 0.6838810641627543 and parameters: {'hidden_size': 95, 'num_layers': 1, 'lstm_dropout': 0.04906553251175469, 'fc_dropout': 0.14872485966274643, 'bidirectional': True, 'conv_dropout': 0.0134502903492245, 'out_channels': 19, 'lr': 0.0029429549941696804}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1499225749168545 Test Loss: 0.17079086521322046\n",
      "Epoch: 1 Train Loss: 0.16443440751433372 Test Loss: 0.14588733562848533\n",
      "Epoch: 2 Train Loss: 0.13406771148741245 Test Loss: 0.1399936329888793\n",
      "Epoch: 3 Train Loss: 0.12846932194679975 Test Loss: 0.13554003506232373\n",
      "Epoch: 4 Train Loss: 0.12655371987968683 Test Loss: 0.13874440488164513\n",
      "Epoch: 5 Train Loss: 0.12446187284588814 Test Loss: 0.13405200063634795\n",
      "Epoch: 6 Train Loss: 0.12113230422288179 Test Loss: 0.13848877818392108\n",
      "Epoch: 7 Train Loss: 0.11969388460963964 Test Loss: 0.13282096753724085\n",
      "Epoch: 8 Train Loss: 0.11636839294880628 Test Loss: 0.1334363685998197\n",
      "Epoch: 9 Train Loss: 0.11657609927207231 Test Loss: 0.13191561167315838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:54:27,361]\u001b[0m Trial 141 finished with value: 0.7042925278219395 and parameters: {'hidden_size': 90, 'num_layers': 1, 'lstm_dropout': 0.035322979104031225, 'fc_dropout': 0.07744340976482139, 'bidirectional': True, 'conv_dropout': 0.015546463850646845, 'out_channels': 12, 'lr': 0.00013691752530351704}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11532292516082525 Test Loss: 0.13436773145934358\n",
      "Epoch: 1 Train Loss: 0.15604533081799746 Test Loss: 0.1464447856764681\n",
      "Epoch: 2 Train Loss: 0.14605833074077965 Test Loss: 0.146347840748037\n",
      "Epoch: 3 Train Loss: 0.14710489128902554 Test Loss: 0.14930493797000033\n",
      "Epoch: 4 Train Loss: 0.1439337196737528 Test Loss: 0.1429932037124428\n",
      "Epoch: 5 Train Loss: 0.1450715942658484 Test Loss: 0.14594145144779272\n",
      "Epoch: 6 Train Loss: 0.1457421632323414 Test Loss: 0.1459694242003722\n",
      "Epoch: 7 Train Loss: 0.14004490360543131 Test Loss: 0.14643259134036474\n",
      "Epoch: 8 Train Loss: 0.14079403741136193 Test Loss: 0.1628433316588973\n",
      "Epoch: 9 Train Loss: 0.14618781311511994 Test Loss: 0.14371588766670074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:55:25,984]\u001b[0m Trial 142 finished with value: 0.6902086677367576 and parameters: {'hidden_size': 88, 'num_layers': 1, 'lstm_dropout': 0.024038838382502085, 'fc_dropout': 0.0820569494325821, 'bidirectional': True, 'conv_dropout': 0.03575142189191942, 'out_channels': 15, 'lr': 0.001960868025244582}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1401629276946187 Test Loss: 0.14029121726227645\n",
      "Epoch: 1 Train Loss: 0.17290298443995417 Test Loss: 0.14898279581528406\n",
      "Epoch: 2 Train Loss: 0.15933152527920902 Test Loss: 0.16255336383970592\n",
      "Epoch: 3 Train Loss: 0.1592752918332815 Test Loss: 0.16020067702657498\n",
      "Epoch: 4 Train Loss: 0.15166153741963206 Test Loss: 0.14943751287512697\n",
      "Epoch: 5 Train Loss: 0.15864929037690162 Test Loss: 0.17746403546759876\n",
      "Epoch: 6 Train Loss: 0.16001776055395603 Test Loss: 0.16174758586604088\n",
      "Epoch: 7 Train Loss: 0.15293536959523335 Test Loss: 0.1558067715747621\n",
      "Epoch: 8 Train Loss: 0.15627908800430595 Test Loss: 0.1500484457197852\n",
      "Epoch: 9 Train Loss: 0.16054795109853148 Test Loss: 0.15553780418996233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:56:22,634]\u001b[0m Trial 143 finished with value: 0.6766325727773408 and parameters: {'hidden_size': 101, 'num_layers': 1, 'lstm_dropout': 0.0557671578445709, 'fc_dropout': 0.07499143258705188, 'bidirectional': True, 'conv_dropout': 0.008336580922544839, 'out_channels': 13, 'lr': 0.003826858440235849}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15754820425696672 Test Loss: 0.16451288906101602\n",
      "Epoch: 1 Train Loss: 0.19641365915848874 Test Loss: 0.17489063620757753\n",
      "Epoch: 2 Train Loss: 0.1827048600513488 Test Loss: 0.1619759634815561\n",
      "Epoch: 3 Train Loss: 0.18239855422042311 Test Loss: 0.15504630931769126\n",
      "Epoch: 4 Train Loss: 0.18381198146995156 Test Loss: 0.15769965641986067\n",
      "Epoch: 5 Train Loss: 0.1858523548482917 Test Loss: 0.18296972058784847\n",
      "Epoch: 6 Train Loss: 0.16759973392141983 Test Loss: 0.15350707854254367\n",
      "Epoch: 7 Train Loss: 0.17444934814302251 Test Loss: 0.16762863196129094\n",
      "Epoch: 8 Train Loss: 0.16889770242925733 Test Loss: 0.17292797239943625\n",
      "Epoch: 9 Train Loss: 0.1825219973322004 Test Loss: 0.17322243365813225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:57:17,541]\u001b[0m Trial 144 finished with value: 0.6769480519480521 and parameters: {'hidden_size': 93, 'num_layers': 1, 'lstm_dropout': 0.07268023745006671, 'fc_dropout': 0.11457438288192198, 'bidirectional': True, 'conv_dropout': 0.0186920206860586, 'out_channels': 14, 'lr': 0.005910604017894065}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18586992005798966 Test Loss: 0.17617794338869638\n",
      "Epoch: 1 Train Loss: 0.16127143452037127 Test Loss: 0.1591381254373862\n",
      "Epoch: 2 Train Loss: 0.14757128301002084 Test Loss: 0.14901677624117166\n",
      "Epoch: 3 Train Loss: 0.14434832803532482 Test Loss: 0.1459080284050764\n",
      "Epoch: 4 Train Loss: 0.1406107260018587 Test Loss: 0.1446350429284449\n",
      "Epoch: 5 Train Loss: 0.13989898212626575 Test Loss: 0.15645574190514014\n",
      "Epoch: 6 Train Loss: 0.14449371121376753 Test Loss: 0.15047586199116356\n",
      "Epoch: 7 Train Loss: 0.14423196598663926 Test Loss: 0.14481224061343997\n",
      "Epoch: 8 Train Loss: 0.14082958055380732 Test Loss: 0.1443698464598233\n",
      "Epoch: 9 Train Loss: 0.1411822217836976 Test Loss: 0.1443584326404733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:58:13,989]\u001b[0m Trial 145 finished with value: 0.6780982073265783 and parameters: {'hidden_size': 85, 'num_layers': 1, 'lstm_dropout': 0.01065221913581451, 'fc_dropout': 0.06969532861993848, 'bidirectional': True, 'conv_dropout': 0.042795421641135964, 'out_channels': 17, 'lr': 0.00204511996070701}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14198760790899395 Test Loss: 0.14498411754991253\n",
      "Epoch: 1 Train Loss: 0.15689327234774827 Test Loss: 0.14014888597063171\n",
      "Epoch: 2 Train Loss: 0.13403810116648673 Test Loss: 0.13782771995749338\n",
      "Epoch: 3 Train Loss: 0.12824356411844492 Test Loss: 0.13550184060709355\n",
      "Epoch: 4 Train Loss: 0.1255482450723648 Test Loss: 0.13497413736515151\n",
      "Epoch: 5 Train Loss: 0.12277798114717006 Test Loss: 0.13086651974378494\n",
      "Epoch: 6 Train Loss: 0.1200373156696558 Test Loss: 0.133951764690657\n",
      "Epoch: 7 Train Loss: 0.11696816786825658 Test Loss: 0.13504197805846174\n",
      "Epoch: 8 Train Loss: 0.11588262734115123 Test Loss: 0.13273666004617565\n",
      "Epoch: 9 Train Loss: 0.11343291308879852 Test Loss: 0.13542971830702008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 15:59:08,419]\u001b[0m Trial 146 finished with value: 0.7025761124121781 and parameters: {'hidden_size': 106, 'num_layers': 1, 'lstm_dropout': 0.04145518350309381, 'fc_dropout': 0.05436906875036695, 'bidirectional': True, 'conv_dropout': 0.029813992387071296, 'out_channels': 18, 'lr': 0.00020733968068056507}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11154995076283812 Test Loss: 0.1370716988757705\n",
      "Epoch: 1 Train Loss: 0.20710852595320903 Test Loss: 0.17805099285567721\n",
      "Epoch: 2 Train Loss: 0.19466143032132094 Test Loss: 0.24894406122825713\n",
      "Epoch: 3 Train Loss: 0.21416176766743883 Test Loss: 0.16948885790194376\n",
      "Epoch: 4 Train Loss: 0.20652738391137682 Test Loss: 0.1676262776536968\n",
      "Epoch: 5 Train Loss: 0.19224496550438924 Test Loss: 0.170345736965061\n",
      "Epoch: 6 Train Loss: 0.19590605905076955 Test Loss: 0.152059225734478\n",
      "Epoch: 7 Train Loss: 0.19604346135109663 Test Loss: 0.1638762894958353\n",
      "Epoch: 8 Train Loss: 0.20786745371469295 Test Loss: 0.18795057053799732\n",
      "Epoch: 9 Train Loss: 0.19532674737637862 Test Loss: 0.22281709381010228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:00:06,892]\u001b[0m Trial 147 finished with value: 0.6591820368885325 and parameters: {'hidden_size': 103, 'num_layers': 1, 'lstm_dropout': 0.03667195101996645, 'fc_dropout': 0.04020080199447407, 'bidirectional': True, 'conv_dropout': 0.021119143569636428, 'out_channels': 18, 'lr': 0.008432083064992869}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.22306444537487696 Test Loss: 0.1944949205253666\n",
      "Epoch: 1 Train Loss: 0.18134538038372994 Test Loss: 0.1503722802185403\n",
      "Epoch: 2 Train Loss: 0.14192812668681146 Test Loss: 0.15016120295828808\n",
      "Epoch: 3 Train Loss: 0.1384150873363018 Test Loss: 0.14414733930374868\n",
      "Epoch: 4 Train Loss: 0.13572949563413858 Test Loss: 0.14044441275608044\n",
      "Epoch: 5 Train Loss: 0.1332054308488965 Test Loss: 0.13876817264733984\n",
      "Epoch: 6 Train Loss: 0.13356785228848458 Test Loss: 0.1396035079043894\n",
      "Epoch: 7 Train Loss: 0.13053371248245238 Test Loss: 0.13779190860795804\n",
      "Epoch: 8 Train Loss: 0.13087725932598113 Test Loss: 0.13787322376554195\n",
      "Epoch: 9 Train Loss: 0.12954658110290765 Test Loss: 0.13582760684144574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:01:08,435]\u001b[0m Trial 148 finished with value: 0.6940711462450593 and parameters: {'hidden_size': 110, 'num_layers': 1, 'lstm_dropout': 0.06309744520224977, 'fc_dropout': 0.06461706339551727, 'bidirectional': True, 'conv_dropout': 0.1944717726435632, 'out_channels': 3, 'lr': 0.00016859638612085452}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12810900106579065 Test Loss: 0.13851986610042022\n",
      "Epoch: 1 Train Loss: 0.3868841024619527 Test Loss: 0.2867864098772927\n",
      "Epoch: 2 Train Loss: 0.35651036771847483 Test Loss: 0.2821334010412613\n",
      "Epoch: 3 Train Loss: 0.33476789757263914 Test Loss: 0.2911198888533412\n",
      "Epoch: 4 Train Loss: 0.3064010553415099 Test Loss: 0.22987930883114902\n",
      "Epoch: 5 Train Loss: 0.3292217824973809 Test Loss: 0.24778958664873776\n",
      "Epoch: 6 Train Loss: 0.35048709627744695 Test Loss: 0.2853013657121964\n",
      "Epoch: 7 Train Loss: 0.3177828203026822 Test Loss: 0.3336386972675308\n",
      "Epoch: 8 Train Loss: 0.30078309166904377 Test Loss: 0.3150468586330167\n",
      "Epoch: 9 Train Loss: 0.2902387738258105 Test Loss: 0.274207694496801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:02:12,885]\u001b[0m Trial 149 finished with value: 0.640194489465154 and parameters: {'hidden_size': 177, 'num_layers': 1, 'lstm_dropout': 0.020480848089383052, 'fc_dropout': 0.06048629611054507, 'bidirectional': False, 'conv_dropout': 0.047158893652099014, 'out_channels': 16, 'lr': 0.022408482806825752}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.2906562907044186 Test Loss: 0.45291162493921644\n",
      "Epoch: 1 Train Loss: 0.1844801272675395 Test Loss: 0.17537388394768247\n",
      "Epoch: 2 Train Loss: 0.1767257387964055 Test Loss: 0.1519287918774655\n",
      "Epoch: 3 Train Loss: 0.1665423916645348 Test Loss: 0.1867952836013902\n",
      "Epoch: 4 Train Loss: 0.17820351046626456 Test Loss: 0.16656788137143316\n",
      "Epoch: 5 Train Loss: 0.16574819407295435 Test Loss: 0.16908152998921971\n",
      "Epoch: 6 Train Loss: 0.1742825079118833 Test Loss: 0.15496191035468168\n",
      "Epoch: 7 Train Loss: 0.1723411570103839 Test Loss: 0.1713992834876711\n",
      "Epoch: 8 Train Loss: 0.16396334829977713 Test Loss: 0.16615786090249213\n",
      "Epoch: 9 Train Loss: 0.1653609878673684 Test Loss: 0.23814556751877797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:03:15,084]\u001b[0m Trial 150 finished with value: 0.6793349168646081 and parameters: {'hidden_size': 97, 'num_layers': 1, 'lstm_dropout': 0.08308191635599765, 'fc_dropout': 0.05324484092225431, 'bidirectional': True, 'conv_dropout': 0.03160909974041804, 'out_channels': 18, 'lr': 0.004601016044222547}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.168855961371772 Test Loss: 0.15108148985432265\n",
      "Epoch: 1 Train Loss: 0.1575004673153162 Test Loss: 0.2100096838708711\n",
      "Epoch: 2 Train Loss: 0.14887974802702666 Test Loss: 0.13963569558490388\n",
      "Epoch: 3 Train Loss: 0.14555362587459386 Test Loss: 0.14272907647652366\n",
      "Epoch: 4 Train Loss: 0.1434306041251868 Test Loss: 0.14335484273089005\n",
      "Epoch: 5 Train Loss: 0.1439968716621399 Test Loss: 0.14115753231760556\n",
      "Epoch: 6 Train Loss: 0.13929002618640662 Test Loss: 0.16168976206624042\n",
      "Epoch: 7 Train Loss: 0.14200946201421322 Test Loss: 0.1378473441440838\n",
      "Epoch: 8 Train Loss: 0.1408715546518564 Test Loss: 0.1525402313645798\n",
      "Epoch: 9 Train Loss: 0.13738865896239877 Test Loss: 0.1407029051958515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:04:14,636]\u001b[0m Trial 151 finished with value: 0.6983372921615202 and parameters: {'hidden_size': 92, 'num_layers': 1, 'lstm_dropout': 0.04400907469625354, 'fc_dropout': 0.18319137862924517, 'bidirectional': True, 'conv_dropout': 0.0002408071124472059, 'out_channels': 15, 'lr': 0.0020760575828489983}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1389118785534054 Test Loss: 0.13804711031313902\n",
      "Epoch: 1 Train Loss: 0.16210126228258015 Test Loss: 0.14998528612747836\n",
      "Epoch: 2 Train Loss: 0.14785763039290906 Test Loss: 0.15681007846047323\n",
      "Epoch: 3 Train Loss: 0.14948865478299558 Test Loss: 0.14173450359045126\n",
      "Epoch: 4 Train Loss: 0.14458617007434368 Test Loss: 0.14511131303021893\n",
      "Epoch: 5 Train Loss: 0.14329799157343806 Test Loss: 0.18790483685580794\n",
      "Epoch: 6 Train Loss: 0.14143471452388912 Test Loss: 0.14815593022888843\n",
      "Epoch: 7 Train Loss: 0.1433595122627914 Test Loss: 0.13839906215155945\n",
      "Epoch: 8 Train Loss: 0.14259570915400982 Test Loss: 0.14364854503161134\n",
      "Epoch: 9 Train Loss: 0.1451312421016395 Test Loss: 0.14476965914685697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:05:19,508]\u001b[0m Trial 152 finished with value: 0.6887312844759653 and parameters: {'hidden_size': 107, 'num_layers': 1, 'lstm_dropout': 0.042481801538238904, 'fc_dropout': 0.09111378797685814, 'bidirectional': True, 'conv_dropout': 0.0016158401678696677, 'out_channels': 14, 'lr': 0.0028661067165228725}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14256804356724023 Test Loss: 0.1514244301083941\n",
      "Epoch: 1 Train Loss: 0.15812079213559627 Test Loss: 0.1441706553065834\n",
      "Epoch: 2 Train Loss: 0.14986910385712982 Test Loss: 0.1621274814699976\n",
      "Epoch: 3 Train Loss: 0.14390738216415047 Test Loss: 0.1476512852321251\n",
      "Epoch: 4 Train Loss: 0.14301563592404126 Test Loss: 0.1471127089434348\n",
      "Epoch: 5 Train Loss: 0.14254154055453838 Test Loss: 0.1529396732647222\n",
      "Epoch: 6 Train Loss: 0.14087148496210575 Test Loss: 0.1377914080771204\n",
      "Epoch: 7 Train Loss: 0.13994570739008486 Test Loss: 0.14183490477895108\n",
      "Epoch: 8 Train Loss: 0.13784836070761083 Test Loss: 0.14348950484892525\n",
      "Epoch: 9 Train Loss: 0.140802623225376 Test Loss: 0.1392411512795824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:06:19,050]\u001b[0m Trial 153 finished with value: 0.6888168557536467 and parameters: {'hidden_size': 43, 'num_layers': 1, 'lstm_dropout': 0.0494014261055414, 'fc_dropout': 0.18504525856927145, 'bidirectional': True, 'conv_dropout': 0.012709227021026306, 'out_channels': 15, 'lr': 0.0019327943526702622}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13799292779862882 Test Loss: 0.1353192311375381\n",
      "Epoch: 1 Train Loss: 0.1575195361763239 Test Loss: 0.14129430952425392\n",
      "Epoch: 2 Train Loss: 0.13330902329683303 Test Loss: 0.13934976865832036\n",
      "Epoch: 3 Train Loss: 0.12971712743788957 Test Loss: 0.13665622789948323\n",
      "Epoch: 4 Train Loss: 0.12568089917749167 Test Loss: 0.13673448125822857\n",
      "Epoch: 5 Train Loss: 0.12402460400164127 Test Loss: 0.13442787526252742\n",
      "Epoch: 6 Train Loss: 0.12114515427201987 Test Loss: 0.13160954508632897\n",
      "Epoch: 7 Train Loss: 0.11830418010503053 Test Loss: 0.13200817916232843\n",
      "Epoch: 8 Train Loss: 0.11674536536186933 Test Loss: 0.1348474482163644\n",
      "Epoch: 9 Train Loss: 0.11477811656072735 Test Loss: 0.13349468990886648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:07:29,881]\u001b[0m Trial 154 finished with value: 0.7015384615384616 and parameters: {'hidden_size': 91, 'num_layers': 1, 'lstm_dropout': 0.029401691926593417, 'fc_dropout': 0.022692433816434775, 'bidirectional': True, 'conv_dropout': 0.02464588934598275, 'out_channels': 13, 'lr': 0.00021957567414521351}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11307981660962105 Test Loss: 0.13754675812876452\n",
      "Epoch: 1 Train Loss: 0.1703737952657044 Test Loss: 0.19062456155654056\n",
      "Epoch: 2 Train Loss: 0.15494242386184634 Test Loss: 0.22090369705542232\n",
      "Epoch: 3 Train Loss: 0.1572945434883237 Test Loss: 0.1890335035020896\n",
      "Epoch: 4 Train Loss: 0.16076541311107576 Test Loss: 0.15183654166579533\n",
      "Epoch: 5 Train Loss: 0.15514269821401686 Test Loss: 0.19709637692717377\n",
      "Epoch: 6 Train Loss: 0.15689319695346057 Test Loss: 0.19876940925672543\n",
      "Epoch: 7 Train Loss: 0.16704845624733716 Test Loss: 0.19862274910076358\n",
      "Epoch: 8 Train Loss: 0.16343102949373425 Test Loss: 0.18311642163162367\n",
      "Epoch: 9 Train Loss: 0.15120396847240627 Test Loss: 0.15988810573772977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:08:31,543]\u001b[0m Trial 155 finished with value: 0.6852589641434262 and parameters: {'hidden_size': 92, 'num_layers': 1, 'lstm_dropout': 0.03190122421713036, 'fc_dropout': 0.025981566813134953, 'bidirectional': True, 'conv_dropout': 0.009435630830728797, 'out_channels': 16, 'lr': 0.0040247354455946495}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15593730089217425 Test Loss: 0.14819326160100701\n",
      "Epoch: 1 Train Loss: 0.2065713705623173 Test Loss: 0.20646384736402526\n",
      "Epoch: 2 Train Loss: 0.1924498931420385 Test Loss: 0.21759267247277506\n",
      "Epoch: 3 Train Loss: 0.19616409278446809 Test Loss: 0.20197919439286374\n",
      "Epoch: 4 Train Loss: 0.19839980229656212 Test Loss: 0.16234184704280605\n",
      "Epoch: 5 Train Loss: 0.19788853988642513 Test Loss: 0.2220798311665797\n",
      "Epoch: 6 Train Loss: 0.19445311353304423 Test Loss: 0.16218418078854108\n",
      "Epoch: 7 Train Loss: 0.20713051658822224 Test Loss: 0.16967644496633413\n",
      "Epoch: 8 Train Loss: 0.22129193480659742 Test Loss: 0.2039673022558383\n",
      "Epoch: 9 Train Loss: 0.20069824696201832 Test Loss: 0.18439333248785295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:09:35,659]\u001b[0m Trial 156 finished with value: 0.6630602782071098 and parameters: {'hidden_size': 99, 'num_layers': 1, 'lstm_dropout': 0.027038346118183666, 'fc_dropout': 0.009405408708518727, 'bidirectional': True, 'conv_dropout': 0.02172654786471636, 'out_channels': 17, 'lr': 0.0071723706378613765}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.20926634925829712 Test Loss: 0.4101512220769478\n",
      "Epoch: 1 Train Loss: 0.15953090516775847 Test Loss: 0.1690486112175087\n",
      "Epoch: 2 Train Loss: 0.14462753955423832 Test Loss: 0.151679599842134\n",
      "Epoch: 3 Train Loss: 0.14672701691798865 Test Loss: 0.14574845109027795\n",
      "Epoch: 4 Train Loss: 0.14175839821323752 Test Loss: 0.17695696823992216\n",
      "Epoch: 5 Train Loss: 0.1412596636503935 Test Loss: 0.15410357242533432\n",
      "Epoch: 6 Train Loss: 0.1420156974039972 Test Loss: 0.15925442799925804\n",
      "Epoch: 7 Train Loss: 0.14192752726711333 Test Loss: 0.1530910333791099\n",
      "Epoch: 8 Train Loss: 0.1412810698390007 Test Loss: 0.1510446736493859\n",
      "Epoch: 9 Train Loss: 0.14116113507449626 Test Loss: 0.14336777870623638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:10:41,668]\u001b[0m Trial 157 finished with value: 0.685672514619883 and parameters: {'hidden_size': 119, 'num_layers': 1, 'lstm_dropout': 0.014017661204022595, 'fc_dropout': 0.04592696672927829, 'bidirectional': True, 'conv_dropout': 0.0015904210460218199, 'out_channels': 13, 'lr': 0.001824128735707829}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1417938111320138 Test Loss: 0.1652822022582181\n",
      "Epoch: 1 Train Loss: 0.1549953758120537 Test Loss: 0.14561950592413403\n",
      "Epoch: 2 Train Loss: 0.13421432454884052 Test Loss: 0.14196751606516755\n",
      "Epoch: 3 Train Loss: 0.13018311430066823 Test Loss: 0.13625598284668816\n",
      "Epoch: 4 Train Loss: 0.12654742915034295 Test Loss: 0.1414400062497003\n",
      "Epoch: 5 Train Loss: 0.12445262525081635 Test Loss: 0.13779143573115238\n",
      "Epoch: 6 Train Loss: 0.12198380130082369 Test Loss: 0.13968430812985372\n",
      "Epoch: 7 Train Loss: 0.12039549154490232 Test Loss: 0.1383252454826388\n",
      "Epoch: 8 Train Loss: 0.11938034550398588 Test Loss: 0.14309648924266188\n",
      "Epoch: 9 Train Loss: 0.1154690836906433 Test Loss: 0.1411302590373749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:11:46,771]\u001b[0m Trial 158 finished with value: 0.7002360346184106 and parameters: {'hidden_size': 105, 'num_layers': 1, 'lstm_dropout': 0.0006425004567303799, 'fc_dropout': 0.03349272422520819, 'bidirectional': True, 'conv_dropout': 0.036218007132884256, 'out_channels': 15, 'lr': 0.0002458942341430075}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1155773933172226 Test Loss: 0.13397331861035225\n",
      "Epoch: 1 Train Loss: 0.19922877270877362 Test Loss: 0.16412593533222478\n",
      "Epoch: 2 Train Loss: 0.1513741437405348 Test Loss: 0.15499841289731642\n",
      "Epoch: 3 Train Loss: 0.145217134770751 Test Loss: 0.1492497749245776\n",
      "Epoch: 4 Train Loss: 0.1404952633678913 Test Loss: 0.14672237719162204\n",
      "Epoch: 5 Train Loss: 0.13765962660908698 Test Loss: 0.1475146610599261\n",
      "Epoch: 6 Train Loss: 0.1367452481865883 Test Loss: 0.14558611657863227\n",
      "Epoch: 7 Train Loss: 0.13436802953481675 Test Loss: 0.14460030096336104\n",
      "Epoch: 8 Train Loss: 0.13417966952621938 Test Loss: 0.14402295826984862\n",
      "Epoch: 9 Train Loss: 0.1327205958276987 Test Loss: 0.14877356620380483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:12:51,960]\u001b[0m Trial 159 finished with value: 0.676923076923077 and parameters: {'hidden_size': 104, 'num_layers': 1, 'lstm_dropout': 0.0013231842341972014, 'fc_dropout': 0.03269322573306699, 'bidirectional': True, 'conv_dropout': 0.032257820945548396, 'out_channels': 1, 'lr': 0.0001661390066074976}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13282243295460938 Test Loss: 0.14392773278605062\n",
      "Epoch: 1 Train Loss: 1.0875590343998156 Test Loss: 0.40404846710926545\n",
      "Epoch: 2 Train Loss: 0.6428449143324222 Test Loss: 0.38368814427572223\n",
      "Epoch: 3 Train Loss: 0.758911484352577 Test Loss: 1.0976783940386203\n",
      "Epoch: 4 Train Loss: 0.6608971295748118 Test Loss: 2.125478549493052\n",
      "Epoch: 5 Train Loss: 0.7289359893073172 Test Loss: 0.7050311875761552\n",
      "Epoch: 6 Train Loss: 0.6755135750731052 Test Loss: 0.531139161521807\n",
      "Epoch: 7 Train Loss: 0.5461748245407273 Test Loss: 0.5397167386709566\n",
      "Epoch: 8 Train Loss: 0.8913445262177964 Test Loss: 0.34316360216049224\n",
      "Epoch: 9 Train Loss: 0.85389569935391 Test Loss: 0.641915276856334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:13:57,331]\u001b[0m Trial 160 finished with value: 0.6138775510204081 and parameters: {'hidden_size': 112, 'num_layers': 1, 'lstm_dropout': 0.008319751999704897, 'fc_dropout': 0.02187610002150259, 'bidirectional': True, 'conv_dropout': 0.04773392784044019, 'out_channels': 17, 'lr': 0.05485210720221149}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.7869868129562863 Test Loss: 0.5627554297848292\n",
      "Epoch: 1 Train Loss: 0.17273391335681082 Test Loss: 0.21577890781825557\n",
      "Epoch: 2 Train Loss: 0.16136281527653337 Test Loss: 0.16184333252449767\n",
      "Epoch: 3 Train Loss: 0.1614038264196366 Test Loss: 0.1549419562716168\n",
      "Epoch: 4 Train Loss: 0.16265065870461987 Test Loss: 0.18600964367675324\n",
      "Epoch: 5 Train Loss: 0.15891902097687124 Test Loss: 0.15217564547785556\n",
      "Epoch: 6 Train Loss: 0.15841971525475382 Test Loss: 0.14611472608967901\n",
      "Epoch: 7 Train Loss: 0.15114957167357207 Test Loss: 0.14862276300395164\n",
      "Epoch: 8 Train Loss: 0.1543761943893507 Test Loss: 0.18904967283600935\n",
      "Epoch: 9 Train Loss: 0.15051221081912516 Test Loss: 0.17975190148566858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:15:01,664]\u001b[0m Trial 161 finished with value: 0.6893280632411067 and parameters: {'hidden_size': 97, 'num_layers': 1, 'lstm_dropout': 0.018849941373626257, 'fc_dropout': 0.20233861073699422, 'bidirectional': True, 'conv_dropout': 0.02555751553121173, 'out_channels': 15, 'lr': 0.003832540784049058}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.15821690487759188 Test Loss: 0.17817104437177222\n",
      "Epoch: 1 Train Loss: 0.162932309140265 Test Loss: 0.1439169535336022\n",
      "Epoch: 2 Train Loss: 0.1339371639817953 Test Loss: 0.14365450255632306\n",
      "Epoch: 3 Train Loss: 0.1300413356348872 Test Loss: 0.1388948840913348\n",
      "Epoch: 4 Train Loss: 0.12645028757303953 Test Loss: 0.13683896188656933\n",
      "Epoch: 5 Train Loss: 0.12520490752756597 Test Loss: 0.13826449186550066\n",
      "Epoch: 6 Train Loss: 0.12243530705422163 Test Loss: 0.13472885056473197\n",
      "Epoch: 7 Train Loss: 0.12053932029604912 Test Loss: 0.138653624993258\n",
      "Epoch: 8 Train Loss: 0.11820928261131049 Test Loss: 0.1364125191939239\n",
      "Epoch: 9 Train Loss: 0.11641628103405237 Test Loss: 0.1373702613339304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:16:03,914]\u001b[0m Trial 162 finished with value: 0.680429397192403 and parameters: {'hidden_size': 88, 'num_layers': 1, 'lstm_dropout': 0.03820970225368557, 'fc_dropout': 0.001513824353339941, 'bidirectional': True, 'conv_dropout': 0.017328600260222635, 'out_channels': 14, 'lr': 0.0001341147647601901}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11462056118100881 Test Loss: 0.1337703184281199\n",
      "Epoch: 1 Train Loss: 0.20182755072182043 Test Loss: 0.257866985652746\n",
      "Epoch: 2 Train Loss: 0.18733824792527592 Test Loss: 0.18418739141209034\n",
      "Epoch: 3 Train Loss: 0.1788548744790023 Test Loss: 0.16121839595357546\n",
      "Epoch: 4 Train Loss: 0.1678475629665889 Test Loss: 0.1775886569835674\n",
      "Epoch: 5 Train Loss: 0.17823001793220172 Test Loss: 0.19917607278869556\n",
      "Epoch: 6 Train Loss: 0.17074729211097583 Test Loss: 0.20085092312909258\n",
      "Epoch: 7 Train Loss: 0.1768313189042732 Test Loss: 0.15765202978250983\n",
      "Epoch: 8 Train Loss: 0.17593411249942145 Test Loss: 0.16701405482313122\n",
      "Epoch: 9 Train Loss: 0.17865849336273967 Test Loss: 0.26455254184820254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:17:03,313]\u001b[0m Trial 163 finished with value: 0.6777358490566038 and parameters: {'hidden_size': 92, 'num_layers': 1, 'lstm_dropout': 0.05421189249452375, 'fc_dropout': 0.049703953486700383, 'bidirectional': True, 'conv_dropout': 0.2403944822741556, 'out_channels': 16, 'lr': 0.0052030153007116}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.19072832868285478 Test Loss: 0.178353841522167\n",
      "Epoch: 1 Train Loss: 0.1587663438990712 Test Loss: 0.14729948126422332\n",
      "Epoch: 2 Train Loss: 0.14528743774965405 Test Loss: 0.1421312153125152\n",
      "Epoch: 3 Train Loss: 0.13998335860595107 Test Loss: 0.1643361449985506\n",
      "Epoch: 4 Train Loss: 0.1414335155956447 Test Loss: 0.14177009986993222\n",
      "Epoch: 5 Train Loss: 0.14438692129775882 Test Loss: 0.15104001215078866\n",
      "Epoch: 6 Train Loss: 0.14722577809467913 Test Loss: 0.14501996900731573\n",
      "Epoch: 7 Train Loss: 0.14163212141320108 Test Loss: 0.1469901363118388\n",
      "Epoch: 8 Train Loss: 0.13927098224572837 Test Loss: 0.14156770607093558\n",
      "Epoch: 9 Train Loss: 0.14271628235541284 Test Loss: 0.14030517448192112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:18:08,262]\u001b[0m Trial 164 finished with value: 0.6812297734627832 and parameters: {'hidden_size': 101, 'num_layers': 1, 'lstm_dropout': 0.06627477450245353, 'fc_dropout': 0.03140922547689694, 'bidirectional': True, 'conv_dropout': 0.033952114121340846, 'out_channels': 15, 'lr': 0.002260243539960756}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1400414926569909 Test Loss: 0.17137106630531623\n",
      "Epoch: 1 Train Loss: 0.17455488640274852 Test Loss: 0.15384579399904122\n",
      "Epoch: 2 Train Loss: 0.1660364663567394 Test Loss: 0.14471072636651822\n",
      "Epoch: 3 Train Loss: 0.15853708522096277 Test Loss: 0.1517579547120645\n",
      "Epoch: 4 Train Loss: 0.1578649329405278 Test Loss: 0.1534798834651423\n",
      "Epoch: 5 Train Loss: 0.15944927624519914 Test Loss: 0.15885856483256616\n",
      "Epoch: 6 Train Loss: 0.1594711203755811 Test Loss: 0.14762635021425854\n",
      "Epoch: 7 Train Loss: 0.1569749842779711 Test Loss: 0.18189563887184873\n",
      "Epoch: 8 Train Loss: 0.1592082980453968 Test Loss: 0.15287502340603465\n",
      "Epoch: 9 Train Loss: 0.15270968666579574 Test Loss: 0.15996734146921399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:19:11,501]\u001b[0m Trial 165 finished with value: 0.6884735202492211 and parameters: {'hidden_size': 83, 'num_layers': 1, 'lstm_dropout': 0.02728538445279616, 'fc_dropout': 0.2189452944667117, 'bidirectional': True, 'conv_dropout': 0.010902241993853104, 'out_channels': 19, 'lr': 0.002951375045215884}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1568469393610023 Test Loss: 0.1407983270220863\n",
      "Epoch: 1 Train Loss: 0.1665743319183588 Test Loss: 0.1457939129144239\n",
      "Epoch: 2 Train Loss: 0.13832344934046267 Test Loss: 0.1402790854378535\n",
      "Epoch: 3 Train Loss: 0.13648282327204941 Test Loss: 0.14385755682667603\n",
      "Epoch: 4 Train Loss: 0.1331198376044631 Test Loss: 0.13819076448155287\n",
      "Epoch: 5 Train Loss: 0.13103171367049218 Test Loss: 0.13841995093435905\n",
      "Epoch: 6 Train Loss: 0.13154479418992995 Test Loss: 0.1359131445173924\n",
      "Epoch: 7 Train Loss: 0.13000731465816498 Test Loss: 0.13539536305652639\n",
      "Epoch: 8 Train Loss: 0.12905285514593123 Test Loss: 0.13498828923121428\n",
      "Epoch: 9 Train Loss: 0.1279106604576111 Test Loss: 0.1350106299905398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:20:17,776]\u001b[0m Trial 166 finished with value: 0.6856690419635787 and parameters: {'hidden_size': 108, 'num_layers': 1, 'lstm_dropout': 0.04548133585361413, 'fc_dropout': 0.018905644772937324, 'bidirectional': True, 'conv_dropout': 0.2740996718098131, 'out_channels': 13, 'lr': 0.00011684803720499019}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12859027556777 Test Loss: 0.1350182136252951\n",
      "Epoch: 1 Train Loss: 0.18884510880196467 Test Loss: 0.15510384337351726\n",
      "Epoch: 2 Train Loss: 0.16488362581133842 Test Loss: 0.15629466147587512\n",
      "Epoch: 3 Train Loss: 0.17076382935221773 Test Loss: 0.1688708280817198\n",
      "Epoch: 4 Train Loss: 0.1908855483067571 Test Loss: 0.21838800297282374\n",
      "Epoch: 5 Train Loss: 0.18311619567722082 Test Loss: 0.17845928607086023\n",
      "Epoch: 6 Train Loss: 0.1924170852392679 Test Loss: 0.18619519955338762\n",
      "Epoch: 7 Train Loss: 0.19760316785587928 Test Loss: 0.17816921986472872\n",
      "Epoch: 8 Train Loss: 0.17960014002081007 Test Loss: 0.19136365792288568\n",
      "Epoch: 9 Train Loss: 0.17170418927456485 Test Loss: 0.18383591031185545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:21:22,400]\u001b[0m Trial 167 finished with value: 0.6628664495114006 and parameters: {'hidden_size': 96, 'num_layers': 1, 'lstm_dropout': 0.009494267500401702, 'fc_dropout': 0.04140761290582974, 'bidirectional': True, 'conv_dropout': 0.038846936978625284, 'out_channels': 12, 'lr': 0.00656710521673593}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.17909434935618193 Test Loss: 0.18185847353847762\n",
      "Epoch: 1 Train Loss: 0.1990446165420115 Test Loss: 0.17456115457636956\n",
      "Epoch: 2 Train Loss: 0.18670031634261833 Test Loss: 0.18319701609728387\n",
      "Epoch: 3 Train Loss: 0.18989988277163355 Test Loss: 0.16441123908796249\n",
      "Epoch: 4 Train Loss: 0.19398471873607487 Test Loss: 0.16488634435811078\n",
      "Epoch: 5 Train Loss: 0.18479827290056272 Test Loss: 0.16130579370088852\n",
      "Epoch: 6 Train Loss: 0.1878944496031385 Test Loss: 0.16567451432466315\n",
      "Epoch: 7 Train Loss: 0.19209306775275617 Test Loss: 0.28343172919897053\n",
      "Epoch: 8 Train Loss: 0.19189170257039367 Test Loss: 0.23757170075282882\n",
      "Epoch: 9 Train Loss: 0.19187423206090462 Test Loss: 0.15074477117425336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:22:33,966]\u001b[0m Trial 168 finished with value: 0.681504221028396 and parameters: {'hidden_size': 114, 'num_layers': 1, 'lstm_dropout': 0.05598248924592095, 'fc_dropout': 0.19720820777483378, 'bidirectional': True, 'conv_dropout': 0.024170106064876285, 'out_channels': 31, 'lr': 0.004554809263206068}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1761904348574579 Test Loss: 0.23696021768863287\n",
      "Epoch: 1 Train Loss: 1.0114352729748461 Test Loss: 0.694604616017715\n",
      "Epoch: 2 Train Loss: 0.7002932552409725 Test Loss: 0.35847775935255455\n",
      "Epoch: 3 Train Loss: 0.4553449662669893 Test Loss: 0.2889682873949623\n",
      "Epoch: 4 Train Loss: 0.6040251239356604 Test Loss: 0.49522539810482086\n",
      "Epoch: 5 Train Loss: 0.4224599699021669 Test Loss: 1.7732109612169358\n",
      "Epoch: 6 Train Loss: 0.6885406950313223 Test Loss: 0.9173345014025275\n",
      "Epoch: 7 Train Loss: 0.6006561853646304 Test Loss: 0.6633181941236982\n",
      "Epoch: 8 Train Loss: 0.6055616483348295 Test Loss: 0.47344005481169826\n",
      "Epoch: 9 Train Loss: 0.5479960393257949 Test Loss: 0.5694030455932317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:23:37,081]\u001b[0m Trial 169 finished with value: 0.6363636363636364 and parameters: {'hidden_size': 186, 'num_layers': 1, 'lstm_dropout': 0.00044149947449581214, 'fc_dropout': 0.0540657507620535, 'bidirectional': True, 'conv_dropout': 0.05709858349277727, 'out_channels': 18, 'lr': 0.026492938213761495}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.5145902950454054 Test Loss: 0.9181129564919037\n",
      "Epoch: 1 Train Loss: 0.16075675578862428 Test Loss: 0.14866085653714003\n",
      "Epoch: 2 Train Loss: 0.14734572232961654 Test Loss: 0.14399189538004015\n",
      "Epoch: 3 Train Loss: 0.14483313063383102 Test Loss: 0.1401823737863868\n",
      "Epoch: 4 Train Loss: 0.14602518318891525 Test Loss: 0.1546727567241667\n",
      "Epoch: 5 Train Loss: 0.14229391210824252 Test Loss: 0.14232116080701543\n",
      "Epoch: 6 Train Loss: 0.14110488967224954 Test Loss: 0.1494530407985607\n",
      "Epoch: 7 Train Loss: 0.1426648460291326 Test Loss: 0.14805112904407822\n",
      "Epoch: 8 Train Loss: 0.13996921488717198 Test Loss: 0.13870373452766635\n",
      "Epoch: 9 Train Loss: 0.14052940705418587 Test Loss: 0.14973571283605913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:24:27,065]\u001b[0m Trial 170 finished with value: 0.6928104575163399 and parameters: {'hidden_size': 39, 'num_layers': 1, 'lstm_dropout': 0.021417121446656973, 'fc_dropout': 0.06431825084329099, 'bidirectional': True, 'conv_dropout': 0.12939295618472987, 'out_channels': 14, 'lr': 0.0020251754410349518}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1393021648734808 Test Loss: 0.14769226369468835\n",
      "Epoch: 1 Train Loss: 0.15756554792523383 Test Loss: 0.15004899290899118\n",
      "Epoch: 2 Train Loss: 0.1458197022423148 Test Loss: 0.19913893484453948\n",
      "Epoch: 3 Train Loss: 0.14230469411239027 Test Loss: 0.17600221596970655\n",
      "Epoch: 4 Train Loss: 0.14100497775748372 Test Loss: 0.13949517884288734\n",
      "Epoch: 5 Train Loss: 0.13845045201256873 Test Loss: 0.13693145675638232\n",
      "Epoch: 6 Train Loss: 0.13580516429170966 Test Loss: 0.1437082420260952\n",
      "Epoch: 7 Train Loss: 0.1365998174250126 Test Loss: 0.13849083273507917\n",
      "Epoch: 8 Train Loss: 0.1356902870349586 Test Loss: 0.1388458861633183\n",
      "Epoch: 9 Train Loss: 0.13379053652919828 Test Loss: 0.1414803928954485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:25:30,736]\u001b[0m Trial 171 finished with value: 0.6856214459788791 and parameters: {'hidden_size': 75, 'num_layers': 1, 'lstm_dropout': 0.041162574310852476, 'fc_dropout': 0.10088106746065462, 'bidirectional': True, 'conv_dropout': 0.04490327549293333, 'out_channels': 13, 'lr': 0.0017369453924886322}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13717870294228196 Test Loss: 0.13842479156229062\n",
      "Epoch: 1 Train Loss: 0.1629397421885282 Test Loss: 0.1812462259170275\n",
      "Epoch: 2 Train Loss: 0.15331956197842955 Test Loss: 0.16250962733972474\n",
      "Epoch: 3 Train Loss: 0.1540791304387152 Test Loss: 0.15661590640989545\n",
      "Epoch: 4 Train Loss: 0.15228692680075764 Test Loss: 0.14117424156124028\n",
      "Epoch: 5 Train Loss: 0.1533889742460102 Test Loss: 0.14854207796196398\n",
      "Epoch: 6 Train Loss: 0.14738280124142766 Test Loss: 0.1524070956336614\n",
      "Epoch: 7 Train Loss: 0.14792805808074772 Test Loss: 0.1654678624400054\n",
      "Epoch: 8 Train Loss: 0.15053197145834565 Test Loss: 0.1474777698612061\n",
      "Epoch: 9 Train Loss: 0.14890268662497402 Test Loss: 0.15749596546109493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:26:32,483]\u001b[0m Trial 172 finished with value: 0.6809563066776587 and parameters: {'hidden_size': 34, 'num_layers': 1, 'lstm_dropout': 0.0784631293236765, 'fc_dropout': 0.08461476787116039, 'bidirectional': True, 'conv_dropout': 0.0003521150130232723, 'out_channels': 12, 'lr': 0.003884518509897363}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.149390415045619 Test Loss: 0.16448681141895513\n",
      "Epoch: 1 Train Loss: 0.15537823826521635 Test Loss: 0.14525465008478386\n",
      "Epoch: 2 Train Loss: 0.1430259454280138 Test Loss: 0.1526976675509264\n",
      "Epoch: 3 Train Loss: 0.14299122416600585 Test Loss: 0.14519628360510445\n",
      "Epoch: 4 Train Loss: 0.14045236048400403 Test Loss: 0.14285651439080793\n",
      "Epoch: 5 Train Loss: 0.13854512577354908 Test Loss: 0.1387106152221608\n",
      "Epoch: 6 Train Loss: 0.13872856071293355 Test Loss: 0.14395149585645134\n",
      "Epoch: 7 Train Loss: 0.1380032558992505 Test Loss: 0.14110843549830654\n",
      "Epoch: 8 Train Loss: 0.13593026611730458 Test Loss: 0.16156978619109374\n",
      "Epoch: 9 Train Loss: 0.13649926477521657 Test Loss: 0.14646806350400368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:27:33,123]\u001b[0m Trial 173 finished with value: 0.6964856230031948 and parameters: {'hidden_size': 47, 'num_layers': 1, 'lstm_dropout': 0.09886766339092842, 'fc_dropout': 0.17891787407390733, 'bidirectional': True, 'conv_dropout': 0.0686114239724847, 'out_channels': 15, 'lr': 0.0016476375624917658}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1366549004867673 Test Loss: 0.14064880478353545\n",
      "Epoch: 1 Train Loss: 1.7463906979500272 Test Loss: 0.8161931239528486\n",
      "Epoch: 2 Train Loss: 1.4732718574271966 Test Loss: 0.9326059948761134\n",
      "Epoch: 3 Train Loss: 1.2182244384588925 Test Loss: 0.5038330348788485\n",
      "Epoch: 4 Train Loss: 1.3610600432674853 Test Loss: 1.6054232259114625\n",
      "Epoch: 5 Train Loss: 0.995798385730253 Test Loss: 1.1872492550167055\n",
      "Epoch: 6 Train Loss: 0.9508891077695895 Test Loss: 0.3305396693141256\n",
      "Epoch: 7 Train Loss: 0.9779137885777083 Test Loss: 0.6738014616709571\n",
      "Epoch: 8 Train Loss: 0.8076128018571609 Test Loss: 0.8075231491402387\n",
      "Epoch: 9 Train Loss: 0.898628529219411 Test Loss: 1.3645877786464824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:28:28,108]\u001b[0m Trial 174 finished with value: 0.5902306648575304 and parameters: {'hidden_size': 90, 'num_layers': 1, 'lstm_dropout': 0.03353297378999978, 'fc_dropout': 0.12416408211695906, 'bidirectional': True, 'conv_dropout': 0.028935720651740292, 'out_channels': 11, 'lr': 0.06746804363905129}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.9477197957251957 Test Loss: 0.8139021170428797\n",
      "Epoch: 1 Train Loss: 0.1572451129168272 Test Loss: 0.1430103990276115\n",
      "Epoch: 2 Train Loss: 0.13364032460898162 Test Loss: 0.1381476529466268\n",
      "Epoch: 3 Train Loss: 0.129042677372694 Test Loss: 0.13461983141998132\n",
      "Epoch: 4 Train Loss: 0.12590563589185477 Test Loss: 0.13862004801154898\n",
      "Epoch: 5 Train Loss: 0.12256495739370585 Test Loss: 0.13142232460597644\n",
      "Epoch: 6 Train Loss: 0.12085736967921257 Test Loss: 0.1323792982798891\n",
      "Epoch: 7 Train Loss: 0.11717494837343692 Test Loss: 0.12905998938321211\n",
      "Epoch: 8 Train Loss: 0.11429551632404328 Test Loss: 0.1335223290783624\n",
      "Epoch: 9 Train Loss: 0.11318108427524566 Test Loss: 0.12949112273109986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:29:26,191]\u001b[0m Trial 175 finished with value: 0.7055067837190742 and parameters: {'hidden_size': 104, 'num_layers': 1, 'lstm_dropout': 0.14764797379680733, 'fc_dropout': 0.16197163823208763, 'bidirectional': True, 'conv_dropout': 0.01505465961121389, 'out_channels': 17, 'lr': 0.00017829645532945756}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11117449591606855 Test Loss: 0.12970665444176607\n",
      "Epoch: 1 Train Loss: 0.18601596521865577 Test Loss: 0.17196172766220835\n",
      "Epoch: 2 Train Loss: 0.1797267963077873 Test Loss: 0.18592737938244694\n",
      "Epoch: 3 Train Loss: 0.19414577411226927 Test Loss: 0.16664227127386166\n",
      "Epoch: 4 Train Loss: 0.18885692360734102 Test Loss: 0.15651403744214068\n",
      "Epoch: 5 Train Loss: 0.17865535589018836 Test Loss: 0.17172281258403302\n",
      "Epoch: 6 Train Loss: 0.1808241295439191 Test Loss: 0.22111929312925607\n",
      "Epoch: 7 Train Loss: 0.1877874383617658 Test Loss: 0.15847305524439667\n",
      "Epoch: 8 Train Loss: 0.1884667418097146 Test Loss: 0.18180518401280854\n",
      "Epoch: 9 Train Loss: 0.1764179841445759 Test Loss: 0.20498833695676522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:30:20,601]\u001b[0m Trial 176 finished with value: 0.6731707317073171 and parameters: {'hidden_size': 105, 'num_layers': 1, 'lstm_dropout': 0.15443272543724457, 'fc_dropout': 0.17016691415559623, 'bidirectional': True, 'conv_dropout': 0.017541191173204945, 'out_channels': 17, 'lr': 0.0059050763219830275}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.19473000570621807 Test Loss: 0.2380471500494077\n",
      "Epoch: 1 Train Loss: 0.15514688685610892 Test Loss: 0.14531074543468678\n",
      "Epoch: 2 Train Loss: 0.13495886186659337 Test Loss: 0.13659654691601142\n",
      "Epoch: 3 Train Loss: 0.12968370036333798 Test Loss: 0.1385361187802717\n",
      "Epoch: 4 Train Loss: 0.1275026689067483 Test Loss: 0.1367741371311557\n",
      "Epoch: 5 Train Loss: 0.12490215175896884 Test Loss: 0.13381424430793468\n",
      "Epoch: 6 Train Loss: 0.12187419297248125 Test Loss: 0.13263833548385687\n",
      "Epoch: 7 Train Loss: 0.12073196249604225 Test Loss: 0.13310084169427047\n",
      "Epoch: 8 Train Loss: 0.11698236339092255 Test Loss: 0.13010807625187662\n",
      "Epoch: 9 Train Loss: 0.11414185049682855 Test Loss: 0.13581016977814536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:31:27,363]\u001b[0m Trial 177 finished with value: 0.6987179487179488 and parameters: {'hidden_size': 192, 'num_layers': 1, 'lstm_dropout': 0.16641664417168112, 'fc_dropout': 0.16025722440278317, 'bidirectional': False, 'conv_dropout': 0.008838148764859999, 'out_channels': 17, 'lr': 0.00021979521105778868}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11316080090105533 Test Loss: 0.13557395327705354\n",
      "Epoch: 1 Train Loss: 2.75639684324545 Test Loss: 4.128950171108413\n",
      "Epoch: 2 Train Loss: 2.2406370287789628 Test Loss: 1.196627339065212\n",
      "Epoch: 3 Train Loss: 2.2994632560945587 Test Loss: 1.849143281451927\n",
      "Epoch: 4 Train Loss: 2.5327267029111846 Test Loss: 1.3932710999379254\n",
      "Epoch: 5 Train Loss: 2.381529493044798 Test Loss: 0.8539803396715517\n",
      "Epoch: 6 Train Loss: 1.8165806866471539 Test Loss: 0.8357517888619338\n",
      "Epoch: 7 Train Loss: 2.150783232754533 Test Loss: 1.5918231671795007\n",
      "Epoch: 8 Train Loss: 1.9650798453290204 Test Loss: 2.6699781020901994\n",
      "Epoch: 9 Train Loss: 1.7586852032662457 Test Loss: 1.6527209777941543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:32:26,223]\u001b[0m Trial 178 finished with value: 0.6343467543138867 and parameters: {'hidden_size': 122, 'num_layers': 1, 'lstm_dropout': 0.14387613948759978, 'fc_dropout': 0.1617321746599987, 'bidirectional': False, 'conv_dropout': 0.009254608691870187, 'out_channels': 26, 'lr': 0.07762737094645589}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 1.9653672882712085 Test Loss: 0.9821454462306664\n",
      "Epoch: 1 Train Loss: 0.16659472109000198 Test Loss: 0.15065387684030654\n",
      "Epoch: 2 Train Loss: 0.15489953200519085 Test Loss: 0.17027869507575188\n",
      "Epoch: 3 Train Loss: 0.1510101931810379 Test Loss: 0.177135716458729\n",
      "Epoch: 4 Train Loss: 0.154345165322721 Test Loss: 0.19827384673975432\n",
      "Epoch: 5 Train Loss: 0.1553994433231652 Test Loss: 0.15497085866265403\n",
      "Epoch: 6 Train Loss: 0.15688128807339818 Test Loss: 0.19986918314580268\n",
      "Epoch: 7 Train Loss: 0.15258163725994528 Test Loss: 0.15725936892980966\n",
      "Epoch: 8 Train Loss: 0.1512408453658223 Test Loss: 0.15686105566021924\n",
      "Epoch: 9 Train Loss: 0.14970494506284596 Test Loss: 0.16043349601381932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:33:27,002]\u001b[0m Trial 179 finished with value: 0.6833199033037872 and parameters: {'hidden_size': 102, 'num_layers': 1, 'lstm_dropout': 0.16323229604230965, 'fc_dropout': 0.0351081806036567, 'bidirectional': False, 'conv_dropout': 0.03703010814777764, 'out_channels': 18, 'lr': 0.003941829945653366}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14880509738102554 Test Loss: 0.1683421886701601\n",
      "Epoch: 1 Train Loss: 0.1723111116424203 Test Loss: 0.1445442680864574\n",
      "Epoch: 2 Train Loss: 0.13438537752330304 Test Loss: 0.13974596436816855\n",
      "Epoch: 3 Train Loss: 0.130586701720953 Test Loss: 0.13672980329337212\n",
      "Epoch: 4 Train Loss: 0.12784084015190603 Test Loss: 0.13757985667251169\n",
      "Epoch: 5 Train Loss: 0.1269312813565135 Test Loss: 0.13648869720296547\n",
      "Epoch: 6 Train Loss: 0.12470103242099286 Test Loss: 0.14171761909898478\n",
      "Epoch: 7 Train Loss: 0.12260438524931669 Test Loss: 0.13530364427298974\n",
      "Epoch: 8 Train Loss: 0.12156697080135345 Test Loss: 0.13909300053105378\n",
      "Epoch: 9 Train Loss: 0.12082132544666528 Test Loss: 0.1400964115612423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:34:33,650]\u001b[0m Trial 180 finished with value: 0.6886326194398682 and parameters: {'hidden_size': 195, 'num_layers': 3, 'lstm_dropout': 0.14643311933761707, 'fc_dropout': 0.14622444840522736, 'bidirectional': False, 'conv_dropout': 0.020958231115715265, 'out_channels': 20, 'lr': 0.00011487401341011433}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11901660652905703 Test Loss: 0.13575191173357323\n",
      "Epoch: 1 Train Loss: 0.16096774244196713 Test Loss: 0.16229393118962693\n",
      "Epoch: 2 Train Loss: 0.1493705471985042 Test Loss: 0.15963772508485344\n",
      "Epoch: 3 Train Loss: 0.1500778607800603 Test Loss: 0.15004371832639646\n",
      "Epoch: 4 Train Loss: 0.14763994092345237 Test Loss: 0.14221968309293254\n",
      "Epoch: 5 Train Loss: 0.14805905470363795 Test Loss: 0.14470423273920727\n",
      "Epoch: 6 Train Loss: 0.1464360946200788 Test Loss: 0.14804849580537302\n",
      "Epoch: 7 Train Loss: 0.14565226802714168 Test Loss: 0.14491465617233096\n",
      "Epoch: 8 Train Loss: 0.14580548598505558 Test Loss: 0.14329375014208948\n",
      "Epoch: 9 Train Loss: 0.14841077504754066 Test Loss: 0.15861768248125005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:35:24,338]\u001b[0m Trial 181 finished with value: 0.6841317365269461 and parameters: {'hidden_size': 197, 'num_layers': 1, 'lstm_dropout': 0.1311199325954144, 'fc_dropout': 0.18463709899434189, 'bidirectional': False, 'conv_dropout': 0.01604992610180086, 'out_channels': 16, 'lr': 0.0023090575484725085}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14773106271252037 Test Loss: 0.15182069240334317\n",
      "Epoch: 1 Train Loss: 0.16117906800247728 Test Loss: 0.1502317600666334\n",
      "Epoch: 2 Train Loss: 0.14786315118409693 Test Loss: 0.14498786422938775\n",
      "Epoch: 3 Train Loss: 0.15138327931389212 Test Loss: 0.1503311372734011\n",
      "Epoch: 4 Train Loss: 0.14885573996603488 Test Loss: 0.14073778112856344\n",
      "Epoch: 5 Train Loss: 0.14551729631200433 Test Loss: 0.14171449628810343\n",
      "Epoch: 6 Train Loss: 0.1445791266705841 Test Loss: 0.14586795464205665\n",
      "Epoch: 7 Train Loss: 0.14265773220211267 Test Loss: 0.1452579465084754\n",
      "Epoch: 8 Train Loss: 0.1455547132216394 Test Loss: 0.15145645184983936\n",
      "Epoch: 9 Train Loss: 0.1419618541792035 Test Loss: 0.14373356168464826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:36:23,177]\u001b[0m Trial 182 finished with value: 0.6886274509803921 and parameters: {'hidden_size': 215, 'num_layers': 1, 'lstm_dropout': 0.17262547133454006, 'fc_dropout': 0.19607449540447425, 'bidirectional': False, 'conv_dropout': 0.008083932087115038, 'out_channels': 16, 'lr': 0.001760271314451356}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14084153334274888 Test Loss: 0.13965707463911547\n",
      "Epoch: 1 Train Loss: 0.17738690739106386 Test Loss: 0.18936309627831555\n",
      "Epoch: 2 Train Loss: 0.161491853078641 Test Loss: 0.14705904281605928\n",
      "Epoch: 3 Train Loss: 0.16041216351017357 Test Loss: 0.1446345648772943\n",
      "Epoch: 4 Train Loss: 0.15999499907903372 Test Loss: 0.15587771614900411\n",
      "Epoch: 5 Train Loss: 0.16237563121486456 Test Loss: 0.15270196159664814\n",
      "Epoch: 6 Train Loss: 0.16372757243011146 Test Loss: 0.20486820944489692\n",
      "Epoch: 7 Train Loss: 0.1601599472079426 Test Loss: 0.20775764298286087\n",
      "Epoch: 8 Train Loss: 0.16847641724143178 Test Loss: 0.18283985682522147\n",
      "Epoch: 9 Train Loss: 0.1600469581242651 Test Loss: 0.15850343293668076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:37:16,754]\u001b[0m Trial 183 finished with value: 0.6768982229402262 and parameters: {'hidden_size': 116, 'num_layers': 1, 'lstm_dropout': 0.11965862050039323, 'fc_dropout': 0.16025103968144633, 'bidirectional': True, 'conv_dropout': 0.02817148642922934, 'out_channels': 17, 'lr': 0.003656446265676463}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.16215694443769754 Test Loss: 0.14987531064536436\n",
      "Epoch: 1 Train Loss: 0.15172636303305626 Test Loss: 0.1533004645698558\n",
      "Epoch: 2 Train Loss: 0.1370446935452521 Test Loss: 0.13832545835679522\n",
      "Epoch: 3 Train Loss: 0.1312837846070528 Test Loss: 0.1373148877590228\n",
      "Epoch: 4 Train Loss: 0.12890574091672896 Test Loss: 0.13742876212341718\n",
      "Epoch: 5 Train Loss: 0.12735273078531026 Test Loss: 0.14291357338285673\n",
      "Epoch: 6 Train Loss: 0.12634430081993342 Test Loss: 0.14488374247861366\n",
      "Epoch: 7 Train Loss: 0.12344183262959123 Test Loss: 0.13972579987166217\n",
      "Epoch: 8 Train Loss: 0.1217341792114079 Test Loss: 0.1365732382804441\n",
      "Epoch: 9 Train Loss: 0.12211440438181162 Test Loss: 0.1342381150982441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:38:37,892]\u001b[0m Trial 184 finished with value: 0.6898785425101215 and parameters: {'hidden_size': 165, 'num_layers': 1, 'lstm_dropout': 0.18422645340881832, 'fc_dropout': 0.17416032130890444, 'bidirectional': True, 'conv_dropout': 0.0007076206023369953, 'out_channels': 19, 'lr': 0.0005394746787942068}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.12032794887423515 Test Loss: 0.14079192226169446\n",
      "Epoch: 1 Train Loss: 0.1683248751449595 Test Loss: 0.15867884373798158\n",
      "Epoch: 2 Train Loss: 0.1508608082331717 Test Loss: 0.18324323676931212\n",
      "Epoch: 3 Train Loss: 0.15247212490439416 Test Loss: 0.15635603447013294\n",
      "Epoch: 4 Train Loss: 0.14357976916655898 Test Loss: 0.1472006514311408\n",
      "Epoch: 5 Train Loss: 0.14394199645519257 Test Loss: 0.1424529480542571\n",
      "Epoch: 6 Train Loss: 0.14753674039840697 Test Loss: 0.1433117575407885\n",
      "Epoch: 7 Train Loss: 0.14302210927456618 Test Loss: 0.14797608193736106\n",
      "Epoch: 8 Train Loss: 0.14528365516513586 Test Loss: 0.14380986961765221\n",
      "Epoch: 9 Train Loss: 0.1412839120477438 Test Loss: 0.1475842188948545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:39:32,748]\u001b[0m Trial 185 finished with value: 0.6677631578947368 and parameters: {'hidden_size': 98, 'num_layers': 2, 'lstm_dropout': 0.13720548720710868, 'fc_dropout': 0.14041882524815244, 'bidirectional': True, 'conv_dropout': 0.05452053421555174, 'out_channels': 15, 'lr': 0.005120174431118389}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14093439559489487 Test Loss: 0.14784481889380816\n",
      "Epoch: 1 Train Loss: 0.3347986625575765 Test Loss: 0.19287291642861626\n",
      "Epoch: 2 Train Loss: 0.25175891465888345 Test Loss: 0.20344141255409573\n",
      "Epoch: 3 Train Loss: 0.2567501062018011 Test Loss: 0.21771350617523486\n",
      "Epoch: 4 Train Loss: 0.28140498904015404 Test Loss: 0.3391949541723887\n",
      "Epoch: 5 Train Loss: 0.24238377867500385 Test Loss: 0.25345239339797304\n",
      "Epoch: 6 Train Loss: 0.24863448077272332 Test Loss: 0.1602986136409707\n",
      "Epoch: 7 Train Loss: 0.251593421639562 Test Loss: 0.1941544834402399\n",
      "Epoch: 8 Train Loss: 0.2724996625301179 Test Loss: 0.17533417941687016\n",
      "Epoch: 9 Train Loss: 0.2396345573902159 Test Loss: 0.18104156082311568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:40:49,707]\u001b[0m Trial 186 finished with value: 0.6613798572561459 and parameters: {'hidden_size': 179, 'num_layers': 1, 'lstm_dropout': 0.1525799395262029, 'fc_dropout': 0.017754853453144086, 'bidirectional': True, 'conv_dropout': 0.009295013192258946, 'out_channels': 14, 'lr': 0.01940969621778539}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.2846420835569096 Test Loss: 0.34241479517819107\n",
      "Epoch: 1 Train Loss: 2.7837552641842005 Test Loss: 4.761242559523052\n",
      "Epoch: 2 Train Loss: 1.4908642881858063 Test Loss: 0.5640657496520309\n",
      "Epoch: 3 Train Loss: 1.2131543285252018 Test Loss: 0.9284457699440348\n",
      "Epoch: 4 Train Loss: 1.5799516475779913 Test Loss: 0.9675910430947897\n",
      "Epoch: 5 Train Loss: 1.3045514411042267 Test Loss: 0.6811966923509704\n",
      "Epoch: 6 Train Loss: 1.2516673784626462 Test Loss: 2.0552704877684667\n",
      "Epoch: 7 Train Loss: 1.529436242692328 Test Loss: 1.3435441318353907\n",
      "Epoch: 8 Train Loss: 1.0885562833605806 Test Loss: 1.019358982004179\n",
      "Epoch: 9 Train Loss: 1.1950288740569344 Test Loss: 1.2976623222160453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:42:20,965]\u001b[0m Trial 187 finished with value: 0.6598263614838201 and parameters: {'hidden_size': 157, 'num_layers': 1, 'lstm_dropout': 0.04815650322002385, 'fc_dropout': 0.06741074732601726, 'bidirectional': True, 'conv_dropout': 0.03898896569033965, 'out_channels': 36, 'lr': 0.031960688832101444}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 1.3016347389893757 Test Loss: 0.7579568362888135\n",
      "Epoch: 1 Train Loss: 0.503817122453032 Test Loss: 0.23383252876929747\n",
      "Epoch: 2 Train Loss: 0.2681017362197337 Test Loss: 0.29879676473222655\n",
      "Epoch: 3 Train Loss: 0.3575794876220588 Test Loss: 0.4257776146641555\n",
      "Epoch: 4 Train Loss: 0.2871729365784478 Test Loss: 0.33219182539179104\n",
      "Epoch: 5 Train Loss: 0.30727416902575555 Test Loss: 0.2241423617532929\n",
      "Epoch: 6 Train Loss: 0.29544662368778235 Test Loss: 0.27882299093699187\n",
      "Epoch: 7 Train Loss: 0.2680151008950997 Test Loss: 0.2979110969823442\n",
      "Epoch: 8 Train Loss: 0.2899590283618338 Test Loss: 0.45125931286950727\n",
      "Epoch: 9 Train Loss: 0.355462613426536 Test Loss: 0.754351433096214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:43:09,848]\u001b[0m Trial 188 finished with value: 0.6572847682119206 and parameters: {'hidden_size': 108, 'num_layers': 1, 'lstm_dropout': 0.06198153917179724, 'fc_dropout': 0.04739424855852897, 'bidirectional': True, 'conv_dropout': 0.1670817281792149, 'out_channels': 40, 'lr': 0.016649536940133085}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.29764540005703677 Test Loss: 0.2423018465706031\n",
      "Epoch: 1 Train Loss: 1.9752612265671046 Test Loss: 0.6477093114056838\n",
      "Epoch: 2 Train Loss: 1.6885386244481164 Test Loss: 1.3653243715969008\n",
      "Epoch: 3 Train Loss: 1.4264072376896426 Test Loss: 1.4825788391986736\n",
      "Epoch: 4 Train Loss: 1.6964945512307996 Test Loss: 1.4807712820272285\n",
      "Epoch: 5 Train Loss: 1.6954977636922322 Test Loss: 0.7805761955034247\n",
      "Epoch: 6 Train Loss: 1.550052745837683 Test Loss: 1.1444286031028332\n",
      "Epoch: 7 Train Loss: 1.3220465054726167 Test Loss: 1.1033321286285949\n",
      "Epoch: 8 Train Loss: 1.4613830534074337 Test Loss: 6.237424148347812\n",
      "Epoch: 9 Train Loss: 1.516583226796505 Test Loss: 0.7767395472354938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:44:17,875]\u001b[0m Trial 189 finished with value: 0.6391231028667791 and parameters: {'hidden_size': 171, 'num_layers': 1, 'lstm_dropout': 0.246346161808985, 'fc_dropout': 0.23802402197988692, 'bidirectional': True, 'conv_dropout': 0.02335764938485769, 'out_channels': 16, 'lr': 0.043652762259725794}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 1.1919885313876657 Test Loss: 0.4956073406205056\n",
      "Epoch: 1 Train Loss: 0.16388526620566846 Test Loss: 0.14474976191315025\n",
      "Epoch: 2 Train Loss: 0.1343779174119234 Test Loss: 0.14013611441388868\n",
      "Epoch: 3 Train Loss: 0.1311260636165738 Test Loss: 0.13686043110946877\n",
      "Epoch: 4 Train Loss: 0.12789971076846124 Test Loss: 0.1364687324558108\n",
      "Epoch: 5 Train Loss: 0.12559611021131278 Test Loss: 0.1404547783465812\n",
      "Epoch: 6 Train Loss: 0.12375586648285389 Test Loss: 0.13452841276630237\n",
      "Epoch: 7 Train Loss: 0.12149070672541856 Test Loss: 0.13177069533056915\n",
      "Epoch: 8 Train Loss: 0.11953196267187595 Test Loss: 0.1285355126027006\n",
      "Epoch: 9 Train Loss: 0.11795866280049086 Test Loss: 0.13189522234110024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:45:04,997]\u001b[0m Trial 190 finished with value: 0.7072975140336809 and parameters: {'hidden_size': 93, 'num_layers': 1, 'lstm_dropout': 0.1593501233422478, 'fc_dropout': 0.07779212260253443, 'bidirectional': False, 'conv_dropout': 0.05093754437055277, 'out_channels': 18, 'lr': 0.0001821664003579719}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11647943639159203 Test Loss: 0.13019137960462907\n",
      "Epoch: 1 Train Loss: 0.1604213587194681 Test Loss: 0.14209810464074626\n",
      "Epoch: 2 Train Loss: 0.1344552189581096 Test Loss: 0.13780890411724106\n",
      "Epoch: 3 Train Loss: 0.1313600778132677 Test Loss: 0.1409180840632072\n",
      "Epoch: 4 Train Loss: 0.12905835034251212 Test Loss: 0.13779719005794094\n",
      "Epoch: 5 Train Loss: 0.1259013962969184 Test Loss: 0.13506600682656414\n",
      "Epoch: 6 Train Loss: 0.12383414441794156 Test Loss: 0.13282011693325668\n",
      "Epoch: 7 Train Loss: 0.1233937383979559 Test Loss: 0.13906042393856347\n",
      "Epoch: 8 Train Loss: 0.12090543946921825 Test Loss: 0.13166337159756844\n",
      "Epoch: 9 Train Loss: 0.11970416175276041 Test Loss: 0.13538224573214405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:45:34,597]\u001b[0m Trial 191 finished with value: 0.6859504132231404 and parameters: {'hidden_size': 93, 'num_layers': 1, 'lstm_dropout': 0.16011154243791123, 'fc_dropout': 0.07767302384122665, 'bidirectional': False, 'conv_dropout': 0.04708126557830928, 'out_channels': 18, 'lr': 0.00027460822897651974}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.11953080063760281 Test Loss: 0.1315592184347419\n",
      "Epoch: 1 Train Loss: 0.16422908191904426 Test Loss: 0.15935705528079797\n",
      "Epoch: 2 Train Loss: 0.15153728473484515 Test Loss: 0.14837716790600516\n",
      "Epoch: 3 Train Loss: 0.15025349140390754 Test Loss: 0.15624635003673765\n",
      "Epoch: 4 Train Loss: 0.1538024153970182 Test Loss: 0.15627214833260916\n",
      "Epoch: 5 Train Loss: 0.15016357242539524 Test Loss: 0.1687874525499801\n",
      "Epoch: 6 Train Loss: 0.15015408274829387 Test Loss: 0.16031539384513713\n",
      "Epoch: 7 Train Loss: 0.14771958484649658 Test Loss: 0.15748483692995086\n",
      "Epoch: 8 Train Loss: 0.14971223675012588 Test Loss: 0.1487599473012189\n",
      "Epoch: 9 Train Loss: 0.14946591836065054 Test Loss: 0.14493105689676616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:46:02,944]\u001b[0m Trial 192 finished with value: 0.6840031520882585 and parameters: {'hidden_size': 87, 'num_layers': 1, 'lstm_dropout': 0.1476160506888234, 'fc_dropout': 0.1539410447097417, 'bidirectional': False, 'conv_dropout': 0.030837992393571174, 'out_channels': 17, 'lr': 0.0027828702823455044}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14829349660426377 Test Loss: 0.15994444066962113\n",
      "Epoch: 1 Train Loss: 0.15236476984545588 Test Loss: 0.14028356374857334\n",
      "Epoch: 2 Train Loss: 0.14376277500465512 Test Loss: 0.14677462099006952\n",
      "Epoch: 3 Train Loss: 0.14212849044948817 Test Loss: 0.15350433786253864\n",
      "Epoch: 4 Train Loss: 0.14097249521389604 Test Loss: 0.15375094551343127\n",
      "Epoch: 5 Train Loss: 0.13821196219548584 Test Loss: 0.14036465006562088\n",
      "Epoch: 6 Train Loss: 0.14042935627177358 Test Loss: 0.13988397412668593\n",
      "Epoch: 7 Train Loss: 0.13587023348361255 Test Loss: 0.15516292149076066\n",
      "Epoch: 8 Train Loss: 0.14307967279367148 Test Loss: 0.1454048297745875\n",
      "Epoch: 9 Train Loss: 0.138500004645437 Test Loss: 0.15172336603285738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:46:32,274]\u001b[0m Trial 193 finished with value: 0.694800301431801 and parameters: {'hidden_size': 101, 'num_layers': 1, 'lstm_dropout': 0.1739141509548132, 'fc_dropout': 0.05653940251734841, 'bidirectional': False, 'conv_dropout': 0.014679140247169733, 'out_channels': 19, 'lr': 0.001972088101976907}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.13688984793126582 Test Loss: 0.13946777458686513\n",
      "Epoch: 1 Train Loss: 0.16672100170850754 Test Loss: 0.14591057649173866\n",
      "Epoch: 2 Train Loss: 0.1345101741477847 Test Loss: 0.1374788999783631\n",
      "Epoch: 3 Train Loss: 0.13098663624376058 Test Loss: 0.13757844185962465\n",
      "Epoch: 4 Train Loss: 0.12920014050751924 Test Loss: 0.13557038603784938\n",
      "Epoch: 5 Train Loss: 0.12592224934995175 Test Loss: 0.1369222232583946\n",
      "Epoch: 6 Train Loss: 0.12446593485474587 Test Loss: 0.13294028889494963\n",
      "Epoch: 7 Train Loss: 0.122668892352283 Test Loss: 0.1321892860753182\n",
      "Epoch: 8 Train Loss: 0.12014322946369647 Test Loss: 0.13088787911227717\n",
      "Epoch: 9 Train Loss: 0.11952833333164453 Test Loss: 0.13275060246284967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:47:00,871]\u001b[0m Trial 194 finished with value: 0.6966292134831461 and parameters: {'hidden_size': 80, 'num_layers': 1, 'lstm_dropout': 0.13183868278722222, 'fc_dropout': 0.08035701359684053, 'bidirectional': False, 'conv_dropout': 0.05810603003326803, 'out_channels': 15, 'lr': 0.00016863901273753753}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.1176441043138504 Test Loss: 0.13109030274335093\n",
      "Epoch: 1 Train Loss: 0.15967043086737395 Test Loss: 0.2133676534910618\n",
      "Epoch: 2 Train Loss: 0.15036830510552973 Test Loss: 0.14661341890716514\n",
      "Epoch: 3 Train Loss: 0.15013796660229564 Test Loss: 0.13992882920458866\n",
      "Epoch: 4 Train Loss: 0.1511422119282186 Test Loss: 0.15723894077677505\n",
      "Epoch: 5 Train Loss: 0.15268634752109647 Test Loss: 0.15748082784810863\n",
      "Epoch: 6 Train Loss: 0.14408719367608427 Test Loss: 0.1439779902251955\n",
      "Epoch: 7 Train Loss: 0.15018849509134888 Test Loss: 0.15511417074706227\n",
      "Epoch: 8 Train Loss: 0.1460172887198627 Test Loss: 0.1585665557283563\n",
      "Epoch: 9 Train Loss: 0.14668326451629402 Test Loss: 0.1733049164100672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:47:30,999]\u001b[0m Trial 195 finished with value: 0.6782178217821783 and parameters: {'hidden_size': 106, 'num_layers': 1, 'lstm_dropout': 0.1949344375681002, 'fc_dropout': 0.07029467832048207, 'bidirectional': False, 'conv_dropout': 0.00042369647874245463, 'out_channels': 22, 'lr': 0.003499541941069975}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14344342000037433 Test Loss: 0.14374771764198432\n",
      "Epoch: 1 Train Loss: 0.20435624414011835 Test Loss: 0.21914341958751454\n",
      "Epoch: 2 Train Loss: 0.20678577599129638 Test Loss: 0.17615403575352587\n",
      "Epoch: 3 Train Loss: 0.22148949505733326 Test Loss: 0.40138418153561106\n",
      "Epoch: 4 Train Loss: 0.2201363908087136 Test Loss: 0.18339714027060489\n",
      "Epoch: 5 Train Loss: 0.20620526201324538 Test Loss: 0.1871474966356239\n",
      "Epoch: 6 Train Loss: 0.18983470143536105 Test Loss: 0.1821957714067171\n",
      "Epoch: 7 Train Loss: 0.18842423665476962 Test Loss: 0.1689267117893115\n",
      "Epoch: 8 Train Loss: 0.185118381844298 Test Loss: 0.18541855606646201\n",
      "Epoch: 9 Train Loss: 0.18543439743444323 Test Loss: 0.1668411471461431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:48:01,256]\u001b[0m Trial 196 finished with value: 0.650420168067227 and parameters: {'hidden_size': 95, 'num_layers': 1, 'lstm_dropout': 0.16353431234319316, 'fc_dropout': 0.21220216446130366, 'bidirectional': True, 'conv_dropout': 0.038948604782550245, 'out_channels': 17, 'lr': 0.007227176269593941}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.21556007043421269 Test Loss: 0.1962792858988725\n",
      "Epoch: 1 Train Loss: 0.20199287214493378 Test Loss: 0.174942417912328\n",
      "Epoch: 2 Train Loss: 0.18978440520782025 Test Loss: 0.19842485247846373\n",
      "Epoch: 3 Train Loss: 0.17565148752368986 Test Loss: 0.17362738506326947\n",
      "Epoch: 4 Train Loss: 0.18193517850339413 Test Loss: 0.18241666810819135\n",
      "Epoch: 5 Train Loss: 0.17899506505839527 Test Loss: 0.17510176326532048\n",
      "Epoch: 6 Train Loss: 0.17706268862495197 Test Loss: 0.16643180024955934\n",
      "Epoch: 7 Train Loss: 0.18364081616923214 Test Loss: 0.19600065563844082\n",
      "Epoch: 8 Train Loss: 0.18034038812369108 Test Loss: 0.22796768834963202\n",
      "Epoch: 9 Train Loss: 0.1928000908376649 Test Loss: 0.18473388233070318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:48:30,886]\u001b[0m Trial 197 finished with value: 0.6611977030352748 and parameters: {'hidden_size': 86, 'num_layers': 1, 'lstm_dropout': 0.11581922964773639, 'fc_dropout': 0.02632765922053604, 'bidirectional': True, 'conv_dropout': 0.38002766216822836, 'out_channels': 16, 'lr': 0.00549994888088225}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.18603629323244095 Test Loss: 0.17148997728674176\n",
      "Epoch: 1 Train Loss: 0.45028216865493703 Test Loss: 0.197474687580412\n",
      "Epoch: 2 Train Loss: 0.440937029914613 Test Loss: 0.22106640794412635\n",
      "Epoch: 3 Train Loss: 0.4138031628949131 Test Loss: 0.22573002883063528\n",
      "Epoch: 4 Train Loss: 0.3433521620971565 Test Loss: 1.2742398945102924\n",
      "Epoch: 5 Train Loss: 0.3630674364364906 Test Loss: 0.4978729730259904\n",
      "Epoch: 6 Train Loss: 0.3240147673829987 Test Loss: 0.3747628295419569\n",
      "Epoch: 7 Train Loss: 0.27544048936030896 Test Loss: 0.3582507335104252\n",
      "Epoch: 8 Train Loss: 0.25778777707016415 Test Loss: 0.30121536188722275\n",
      "Epoch: 9 Train Loss: 0.3134278957376038 Test Loss: 0.22102053234942806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:49:01,848]\u001b[0m Trial 198 finished with value: 0.6251025430680887 and parameters: {'hidden_size': 100, 'num_layers': 1, 'lstm_dropout': 0.022661096869897146, 'fc_dropout': 0.006893212678818216, 'bidirectional': True, 'conv_dropout': 0.021610204420525587, 'out_channels': 20, 'lr': 0.022430955189625013}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.33186831918019233 Test Loss: 0.21804805674936814\n",
      "Epoch: 1 Train Loss: 0.16852431979067622 Test Loss: 0.14910400517808553\n",
      "Epoch: 2 Train Loss: 0.1495331436444074 Test Loss: 0.18707823094438775\n",
      "Epoch: 3 Train Loss: 0.1532685073584318 Test Loss: 0.14593456290400447\n",
      "Epoch: 4 Train Loss: 0.15167651387006045 Test Loss: 0.16793538356265322\n",
      "Epoch: 5 Train Loss: 0.1548234805399552 Test Loss: 0.1606505140558052\n",
      "Epoch: 6 Train Loss: 0.15228859922010451 Test Loss: 0.14454724868170368\n",
      "Epoch: 7 Train Loss: 0.15348769845049828 Test Loss: 0.15061559905699742\n",
      "Epoch: 8 Train Loss: 0.14984625801704823 Test Loss: 0.14216437327642792\n",
      "Epoch: 9 Train Loss: 0.14812102013714612 Test Loss: 0.1478381675486557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-01 16:49:34,772]\u001b[0m Trial 199 finished with value: 0.6904196357878067 and parameters: {'hidden_size': 202, 'num_layers': 1, 'lstm_dropout': 0.03107025905180027, 'fc_dropout': 0.16650552362044957, 'bidirectional': True, 'conv_dropout': 0.046707382612654814, 'out_channels': 14, 'lr': 0.002033669472721904}. Best is trial 48 with value: 0.7091875474563402.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Train Loss: 0.14728858648724855 Test Loss: 0.1451687787721951\n"
     ]
    }
   ],
   "source": [
    "def lstm_objective(trial):\n",
    "    hidden_size = trial.suggest_int('hidden_size', 32, 256)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lstm_dropout = trial.suggest_float('lstm_dropout', 0, 0.5)\n",
    "    fc_dropout = trial.suggest_float('fc_dropout', 0, 0.5)\n",
    "    bidirectional = trial.suggest_categorical('bidirectional', [True, False])\n",
    "    conv_dropout = trial.suggest_float('conv_dropout', 0, 0.5)\n",
    "    out_channels = trial.suggest_int('out_channels', 1, 40)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-1)\n",
    "    model = LSTMModel(hidden_size=hidden_size, num_layers=num_layers, lstm_dropout=lstm_dropout, fc_dropout=fc_dropout, bidirectional=bidirectional, conv_dropout=conv_dropout, out_channels=out_channels)\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    num_epochs = 10\n",
    "    train_losses, test_losses, train_f1_scores, test_f1_scores = train(criterion, optimizer, model, lstm_train_dataloader3, lstm_test_dataloader3, epochs=num_epochs, save_best=False)\n",
    "    return max(test_f1_scores)\n",
    "\n",
    "study_lstm = optuna.create_study(direction='maximize')\n",
    "study_lstm.optimize(lstm_objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lstm = LSTMModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters())\n",
    "train_losses, test_losses, train_f1_scores, test_f1_scores = train(criterion, optimizer, lstm, lstm_train_dataloader, lstm_test_dataloader, epochs=epochs, save_best=True, save_name='best_rnn_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGzCAYAAAAMr0ziAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACbjklEQVR4nOzdd3hTZfsH8O9J0iTdky4olL1HaQFZClJBVEQEBUQZvuICFVEU/Ck4WaIvKiiKL4ivICCC8IoyLBvKLGXv1dLdQvdIm5zfH0/OSdImadJm0vtzXb3SJicnT0NJ7tzP/dwPx/M8D0IIIYQQFyZx9gAIIYQQQmpDAQshhBBCXB4FLIQQQghxeRSwEEIIIcTlUcBCCCGEEJdHAQshhBBCXB4FLIQQQghxeRSwEEIIIcTlUcBCCCGEEJdHAQshhDjRnj17wHEcNmzY4OyhEOLSKGAhxAX89NNP4DgOx48fd/ZQLHLw4EGMGDECYWFhUCgUiI6OxksvvYSUlBRnD60GISAw9bV27VpnD5EQYgGZswdACHEv33zzDd544w20aNECr732GiIiInDhwgX8+OOPWLduHf766y/06dPH2cOs4fXXX0ePHj1qXN+7d28njIYQYi0KWAghFjt48CCmTZuGfv36Ydu2bfDy8hJve+WVV9C3b1+MGjUK586dQ2BgoMPGVVJSAm9vb7PH9O/fH6NGjXLQiAghtkZTQoS4kZMnT2Lo0KHw8/ODj48PBg0ahMOHDxscU1lZiY8++gitW7eGUqlEcHAw+vXrh507d4rHZGZmYtKkSWjSpAkUCgUiIiIwfPhw3Lx50+zjf/LJJ+A4DqtWrTIIVgCgZcuWWLhwITIyMvD9998DABYtWgSO43Dr1q0a55o1axbkcjnu3r0rXnfkyBE8/PDD8Pf3h5eXFx544AEcPHjQ4H4ffvghOI7D+fPn8cwzzyAwMBD9+vWz6PmrDcdxmDp1KlavXo22bdtCqVQiNjYW+/btq3GsJf8WAJCfn48333wT0dHRUCgUaNKkCcaPH4/c3FyD4zQaDT777DM0adIESqUSgwYNwtWrVw2OuXLlCkaOHInw8HAolUo0adIEY8aMQUFBgU1+f0JcGWVYCHET586dQ//+/eHn54d33nkHHh4e+P777zFgwADs3bsXvXr1AsDe0OfNm4cXXngBPXv2RGFhIY4fP46kpCQ89NBDAICRI0fi3LlzeO211xAdHY3s7Gzs3LkTKSkpiI6ONvr4paWlSEhIQP/+/dG8eXOjx4wePRovvvgi/vzzT8ycORNPP/003nnnHaxfvx4zZswwOHb9+vUYPHiwmInZtWsXhg4ditjYWMyZMwcSiQQrV67Egw8+iP3796Nnz54G93/qqafQunVrzJ07FzzP1/r8FRUV1QgSACA4OBgcx4k/7927F+vWrcPrr78OhUKBb7/9Fg8//DCOHj2KTp06WfVvUVxcjP79++PChQt4/vnn0b17d+Tm5mLLli24ffs2QkJCxMedP38+JBIJ3n77bRQUFGDhwoUYN24cjhw5AgBQqVQYMmQIKioq8NprryE8PBxpaWn4888/kZ+fD39//1qfA0LcGk8IcbqVK1fyAPhjx46ZPOaJJ57g5XI5f+3aNfG69PR03tfXl7///vvF67p27co/+uijJs9z9+5dHgD/+eefWzXG5ORkHgD/xhtvmD2uS5cufFBQkPhz7969+djYWINjjh49ygPgf/75Z57neV6j0fCtW7fmhwwZwms0GvG40tJSvnnz5vxDDz0kXjdnzhweAD927FiLxr17924egMmvjIwM8VjhuuPHj4vX3bp1i1cqlfyIESPE6yz9t5g9ezYPgN+4cWONcQm/pzC+9u3b8xUVFeLtX331FQ+AP3PmDM/zPH/y5EkeAP/bb79Z9HsTcq+hKSFC3IBarcaOHTvwxBNPoEWLFuL1EREReOaZZ3DgwAEUFhYCAAICAnDu3DlcuXLF6Lk8PT0hl8uxZ88eg+mY2hQVFQEAfH19zR7n6+srjgVgWZcTJ07g2rVr4nXr1q2DQqHA8OHDAQDJycm4cuUKnnnmGeTl5SE3Nxe5ubkoKSnBoEGDsG/fPmg0GoPHefnlly0eOwDMnj0bO3furPEVFBRkcFzv3r0RGxsr/ty0aVMMHz4c27dvh1qtturf4vfff0fXrl0xYsSIGuPRz+oAwKRJkyCXy8Wf+/fvDwC4fv06AIgZlO3bt6O0tNSq352QewEFLIS4gZycHJSWlqJt27Y1bmvfvj00Gg1SU1MBAB9//DHy8/PRpk0bdO7cGTNmzMDp06fF4xUKBRYsWIC///4bYWFhuP/++7Fw4UJkZmaaHYMQqAiBiylFRUUGQc1TTz0FiUSCdevWAQB4nsdvv/0m1n8AEIOrCRMmoFGjRgZfP/74IyoqKmrUaZialjKlc+fOiI+Pr/GlHyQAQOvWrWvct02bNigtLUVOTo5V/xbXrl0Tp5Fq07RpU4OfhakyIahs3rw5pk+fjh9//BEhISEYMmQIli5dSvUrpMGggIWQe8z999+Pa9euYcWKFejUqRN+/PFHdO/eHT/++KN4zLRp03D58mXMmzcPSqUSH3zwAdq3b4+TJ0+aPG+rVq0gk8kMgp/qKioqcOnSJXTo0EG8LjIyEv3798f69esBAIcPH0ZKSgpGjx4tHiNkTz7//HOjWZCdO3fCx8fH4LE8PT2te2JcnFQqNXo9r1ef88UXX+D06dN47733UFZWhtdffx0dO3bE7du3HTVMQpyGAhZC3ECjRo3g5eWFS5cu1bjt4sWLkEgkiIqKEq8LCgrCpEmT8OuvvyI1NRVdunTBhx9+aHC/li1b4q233sKOHTtw9uxZqFQqfPHFFybH4O3tjYEDB2Lfvn1GV/0ArJC2oqICjz32mMH1o0ePxqlTp3Dp0iWsW7cOXl5eGDZsmMFYAMDPz89oFiQ+Ph4eHh61Pk+2YGwq7fLly/Dy8hKzPpb+W7Rs2RJnz5616fg6d+6M999/H/v27cP+/fuRlpaGZcuW2fQxCHFFFLAQ4gakUikGDx6MzZs3Gyw9zsrKwpo1a9CvXz9xeiUvL8/gvj4+PmjVqhUqKioAsNU+5eXlBse0bNkSvr6+4jGmvP/+++B5HhMnTkRZWZnBbTdu3MA777yDiIgIvPTSSwa3jRw5ElKpFL/++it+++03PPbYYwZ9U2JjY9GyZUssWrQIxcXFNR43JyfH7LhsKTExEUlJSeLPqamp2Lx5MwYPHgypVGrVv8XIkSNx6tQpbNq0qcbj8BasbNJXWFiIqqoqg+s6d+4MiURS678bIfcCWtZMiAtZsWIFtm3bVuP6N954A59++il27tyJfv364dVXX4VMJsP333+PiooKLFy4UDy2Q4cOGDBgAGJjYxEUFITjx49jw4YNmDp1KgCWLRg0aBCefvppdOjQATKZDJs2bUJWVhbGjBljdnz3338/Fi1ahOnTp6NLly6YOHEiIiIicPHiRSxfvhwajQZ//fVXjaZxoaGhGDhwIL788ksUFRUZTAcBgEQiwY8//oihQ4eiY8eOmDRpEho3boy0tDTs3r0bfn5++N///lfXpxUAsH///hqBGgB06dIFXbp0EX/u1KkThgwZYrCsGQA++ugj8RhL/y1mzJiBDRs24KmnnsLzzz+P2NhY3LlzB1u2bMGyZcvQtWtXi8e/a9cuTJ06FU899RTatGmDqqoq/Pe//4VUKsXIkSPr8pQQ4l6cu0iJEMLzumXNpr5SU1N5nuf5pKQkfsiQIbyPjw/v5eXFDxw4kD906JDBuT799FO+Z8+efEBAAO/p6cm3a9eO/+yzz3iVSsXzPM/n5ubyU6ZM4du1a8d7e3vz/v7+fK9evfj169dbPN59+/bxw4cP50NCQngPDw++adOm/OTJk/mbN2+avM/y5ct5ALyvry9fVlZm9JiTJ0/yTz75JB8cHMwrFAq+WbNm/NNPP80nJCSIxwjLmnNyciwaa23LmufMmSMeC4CfMmUK/8svv/CtW7fmFQoFHxMTw+/evbvGeS35t+B5ns/Ly+OnTp3KN27cmJfL5XyTJk34CRMm8Lm5uQbjq75c+caNGzwAfuXKlTzP8/z169f5559/nm/ZsiWvVCr5oKAgfuDAgfw///xj0fNAiLvjeN7KvCQhhNyjOI7DlClTsGTJEmcPhRBSDdWwEEIIIcTlUcBCCCGEEJdHAQshhBBCXB6tEiKEEC0q6SPEdVGGhRBCCCEujwIWQgghhLi8e2ZKSKPRID09Hb6+vjV2QSWEEEKIa+J5HkVFRYiMjIREYjqPcs8ELOnp6QZ7qRBCCCHEfaSmpqJJkyYmb79nAhZhO/vU1FRxHw9CCCGEuLbCwkJERUWJ7+Om3DMBizAN5OfnRwELIYQQ4mZqK+egoltCCCGEuDwKWAghhBDi8ihgIYQQQojLu2dqWAghhBB74HkeVVVVUKvVzh6KW5JKpZDJZPVuOUIBCyGEEGKCSqVCRkYGSktLnT0Ut+bl5YWIiAjI5fI6n4MCFkIIIcQIjUaDGzduQCqVIjIyEnK5nBqTWonneahUKuTk5ODGjRto3bq12eZw5lDAQgghhBihUqmg0WgQFRUFLy8vZw/HbXl6esLDwwO3bt2CSqWCUqms03mo6JYQQggxo64ZAaJji+eQ/hUIIYQQ4vIoYCGEEEKIy6OAhRBCCCEmRUdHY/Hixc4eBhXdEkIIIfeaAQMGoFu3bjYJNI4dOwZvb+/6D6qeKMNSm91zgT+nA8XZzh4JIYQQYhNCMzxLNGrUyCVWSVHAUpsTPwHH/wMUZTp7JIQQQpyM53mUqqoc/sXzvMVjnDhxIvbu3YuvvvoKHMeB4zj89NNP4DgOf//9N2JjY6FQKHDgwAFcu3YNw4cPR1hYGHx8fNCjRw/8888/BuerPiXEcRx+/PFHjBgxAl5eXmjdujW2bNliq6fYJJoSqo3cB0AWoCp29kgIIYQ4WVmlGh1mb3f4457/eAi85Ja9ZX/11Ve4fPkyOnXqhI8//hgAcO7cOQDAzJkzsWjRIrRo0QKBgYFITU3FI488gs8++wwKhQI///wzhg0bhkuXLqFp06YmH+Ojjz7CwoUL8fnnn+Obb77BuHHjcOvWLQQFBdX/lzWBMiy1Ufiyy4oi546DEEIIsYC/vz/kcjm8vLwQHh6O8PBwSKVSAMDHH3+Mhx56CC1btkRQUBC6du2Kl156CZ06dULr1q3xySefoGXLlrVmTCZOnIixY8eiVatWmDt3LoqLi3H06FG7/l6UYakNBSyEEEK0PD2kOP/xEKc8ri3ExcUZ/FxcXIwPP/wQW7duRUZGBqqqqlBWVoaUlBSz5+nSpYv4vbe3N/z8/JCdbd9aTwpYakMBCyGEEC2O4yyemnFF1Vf7vP3229i5cycWLVqEVq1awdPTE6NGjYJKpTJ7Hg8PD4OfOY6DRqOx+Xj1ue+z7igUsBBCCHEzcrkcarW61uMOHjyIiRMnYsSIEQBYxuXmzZt2Hl3dUA1LbeQ+7JKKbgkhhLiJ6OhoHDlyBDdv3kRubq7J7Efr1q2xceNGJCcn49SpU3jmmWfsnimpKwpYakMZFkIIIW7m7bffhlQqRYcOHdCoUSOTNSlffvklAgMD0adPHwwbNgxDhgxB9+7dHTxay9CUUG0U2gwLBSyEEELcRJs2bZCYmGhw3cSJE2scFx0djV27dhlcN2XKFIOfq08RGesJk5+fX6dxWoMyLLVR+LFLClgIIYQQp6GApTZUw0IIIYQ4HQUstaEaFkIIIcTpKGCpjVjDQhkWQgghxFkoYKkN1bAQQgghTkcBS22EKSEVBSyEEEKIs9QpYFm6dCmio6OhVCrRq1cvsxseLV++HP3790dgYCACAwMRHx9v9PgLFy7g8ccfh7+/P7y9vdGjR49a9zJwCLnesmYrtvcmhBBCiO1YHbCsW7cO06dPx5w5c5CUlISuXbtiyJAhJjc92rNnD8aOHYvdu3cjMTERUVFRGDx4MNLS0sRjrl27hn79+qFdu3bYs2cPTp8+jQ8++ABKpbLuv5mtCBkWTRVQVe7csRBCCCENFMcb6wBjRq9evdCjRw8sWbIEAKDRaBAVFYXXXnsNM2fOrPX+arUagYGBWLJkCcaPHw8AGDNmDDw8PPDf//63Dr8CU1hYCH9/fxQUFMDPz6/O56nunfUnsfD8APbD21cBn0Y2OzchhBDXVV5ejhs3bqB58+au8QHajZl7Li19/7Yqw6JSqXDixAnEx8frTiCRID4+vkZHPVNKS0tRWVmJoKAgACzg2bp1K9q0aYMhQ4YgNDQUvXr1wh9//GH2PBUVFSgsLDT4sod9V++gmNc+uRX2eQxCCCGEmGdVwJKbmwu1Wo2wsDCD68PCwpCZmWnROd59911ERkaKQU92djaKi4sxf/58PPzww9ixYwdGjBiBJ598Env37jV5nnnz5sHf31/8ioqKsuZXsVigtxwl0AYs1DyOEEKIGxgwYACmTZtms/NNnDgRTzzxhM3OVxcOXSU0f/58rF27Fps2bRJTQsKukMOHD8ebb76Jbt26YebMmXjsscewbNkyk+eaNWsWCgoKxK/U1FS7jDnI2wPFvCf7gZY2E0IIIU5hVcASEhICqVSKrKwsg+uzsrIQHh5u9r6LFi3C/PnzsWPHDnTp0sXgnDKZDB06dDA4vn379mZXCSkUCvj5+Rl82UOQtwLFEAIWyrAQQkiDxvOAqsTxX1aUm06cOBF79+7FV199BY7jwHEcbt68ibNnz2Lo0KHw8fFBWFgYnnvuOeTm5or327BhAzp37gxPT08EBwcjPj4eJSUl+PDDD7Fq1Sps3rxZPN+ePXvs8OSaZ9VuzXK5HLGxsUhISBBTQxqNBgkJCZg6darJ+y1cuBCfffYZtm/fjri4uBrn7NGjBy5dumRw/eXLl9GsWTNrhmcXQV6UYSGEEKJVWQrMjXT8476XDsi9LTr0q6++wuXLl9GpUyd8/PHHAAAPDw/07NkTL7zwAv7973+jrKwM7777Lp5++mns2rULGRkZGDt2LBYuXIgRI0agqKgI+/fvB8/zePvtt3HhwgUUFhZi5cqVACDWoTqSVQELAEyfPh0TJkxAXFwcevbsicWLF6OkpASTJk0CAIwfPx6NGzfGvHnzAAALFizA7NmzsWbNGkRHR4u1Lj4+PvDxYT1OZsyYgdGjR+P+++/HwIEDsW3bNvzvf/9zSgRXnWENCwUshBBCXJu/vz/kcjm8vLzE2Y9PP/0UMTExmDt3rnjcihUrEBUVhcuXL6O4uBhVVVV48sknxWRB586dxWM9PT1RUVFR62yKPVkdsIwePRo5OTmYPXs2MjMz0a1bN2zbtk0sxE1JSYFEoptp+u6776BSqTBq1CiD88yZMwcffvghAGDEiBFYtmwZ5s2bh9dffx1t27bF77//jn79+tXjV7ONIG85ikAZFkIIIQA8vFi2wxmPWw+nTp3C7t27xUSBvmvXrmHw4MEYNGgQOnfujCFDhmDw4MEYNWoUAgMD6/W4tmR1wAIAU6dONTkFVD0rcvPmTYvO+fzzz+P555+vy3DsKshbjjyealgIIYQA4DiLp2ZcSXFxMYYNG4YFCxbUuC0iIgJSqRQ7d+7EoUOHsGPHDnzzzTf4v//7Pxw5cgTNmzd3wohror2EahHkJUcJZVgIIYS4EblcDrVaLf7cvXt3nDt3DtHR0WjVqpXBl7c3C8A4jkPfvn3x0Ucf4eTJk5DL5di0aZPR8zkDBSy1CPSWU9EtIYQQtxIdHY0jR47g5s2byM3NxZQpU3Dnzh2MHTsWx44dw7Vr17B9+3ZMmjQJarUaR44cwdy5c3H8+HGkpKRg48aNyMnJQfv27cXznT59GpcuXUJubi4qKysd/jtRwFKLIG85irVFtzwFLIQQQtzA22+/DalUig4dOqBRo0ZQqVQ4ePAg1Go1Bg8ejM6dO2PatGkICAiARCKBn58f9u3bh0ceeQRt2rTB+++/jy+++AJDhw4FAEyePBlt27ZFXFwcGjVqhIMHDzr8d6pTDUtDEuily7BUlRXCw8njIYQQQmrTpk0bo1vmbNy40ejx7du3x7Zt20yer1GjRtixY4fNxlcXlGGphVwmgdqDVVWry2kvIUIIIcQZKGCxAKf0BQDw5TQlRAghhDgDBSwWkHlq2/7T5oeEEEKIU1DAYgG5lz8AQEqdbgkhhBCnoIDFAgpvFrDIqkqt2oCKEEKI++Ppdb/ebPEcUsBiAS9fFrBIoAYqy5w8GkIIIY7g4cHWhZaWljp5JO5PeA6F57QuaFmzBbx9/aHhOUg4njWPk9dvTwdCCCGuTyqVIiAgANnZ2QAALy8vcBzn5FG5F57nUVpaiuzsbAQEBEAqldb5XBSwWCDYR4kSKOGLMm3hbZizh0QIIcQBhN2JhaCF1E1AQEC9d3qmgMUCgV5yFMOTBSwV1IuFEEIaCo7jEBERgdDQUKe0o78XeHh41CuzIqCAxQJB3nKU8EqAA+3YTAghDZBUKrXJmy6pOyq6tUCgN8uwAKANEAkhhBAnoIDFAsHechTzbAPEqjKaEiKEEEIcjQIWC/gpPVACtjKorDjfuYMhhBBCGiAKWCwgkXColAkBS4GTR0MIIYQ0PBSwWKhKxnZsrijJd+5ACCGEkAaIAhYL8XIWsFSVUdEtIYQQ4mgUsFhK4QsAUJfRlBAhhBDiaBSwWEii9AMA8LSsmRBCCHE4ClgsJPNiGRZORY3jCCGEEEejgMVCcq8AAIC0kgIWQgghxNEoYLGQ0odNCXlU0TbjhBBCiKNRwGIhL59AAIBCXeLkkRBCCCENDwUsFvLxCwAAKHnKsBBCCCGORgGLhXwDggAAXnwZeI3GyaMhhBBCGhYKWCwUEMCmhKQcj5ISWtpMCCGEOBIFLBby9PKDhucAAAX5d5w8GkIIIaRhoYDFQpxEglLOEwBQWHDXyaMhhBBCGhYKWKxQJmE7NpcUUsBCCCGEOBIFLFZQaQOW0iIKWAghhBBHooDFCpUybwBAeQltgEgIIYQ4EgUsVlB7+AAAVBSwEEIIIQ5FAYsVeDkLWKrKaFkzIYQQ4kgUsFhDyfYT0pQXOnkghBBCSMNSp4Bl6dKliI6OhlKpRK9evXD06FGTxy5fvhz9+/dHYGAgAgMDER8fb/b4l19+GRzHYfHixXUZml1Jlb7smwrKsBBCCCGOZHXAsm7dOkyfPh1z5sxBUlISunbtiiFDhiA7O9vo8Xv27MHYsWOxe/duJCYmIioqCoMHD0ZaWlqNYzdt2oTDhw8jMjLS+t/EAWSeLMPCqYqdPBJCCCGkYbE6YPnyyy8xefJkTJo0CR06dMCyZcvg5eWFFStWGD1+9erVePXVV9GtWze0a9cOP/74IzQaDRISEgyOS0tLw2uvvYbVq1fDw8Ojbr+NnSm9/QEA0koKWAghhBBHsipgUalUOHHiBOLj43UnkEgQHx+PxMREi85RWlqKyspKBAUFiddpNBo899xzmDFjBjp27GjReSoqKlBYWGjwZW9KnwAAgFxdCrWGt/vjEUIIIYSxKmDJzc2FWq1GWFiYwfVhYWHIzMy06BzvvvsuIiMjDYKeBQsWQCaT4fXXX7d4LPPmzYO/v7/4FRUVZfF968rTh2VYvFGGgrJKuz8eIYQQQhiHrhKaP38+1q5di02bNkGpVAIATpw4ga+++go//fQTOI6z+FyzZs1CQUGB+JWammqvYYtknixg8eXKcKdEZffHI4QQQghjVcASEhICqVSKrKwsg+uzsrIQHh5u9r6LFi3C/PnzsWPHDnTp0kW8fv/+/cjOzkbTpk0hk8kgk8lw69YtvPXWW4iOjjZ5PoVCAT8/P4Mvu1OwPiw+oICFEEIIcSSrAha5XI7Y2FiDglmhgLZ3794m77dw4UJ88skn2LZtG+Li4gxue+6553D69GkkJyeLX5GRkZgxYwa2b99u5a9jZwq2rNmbK6eAhRBCCHEgmbV3mD59OiZMmIC4uDj07NkTixcvRklJCSZNmgQAGD9+PBo3box58+YBYPUps2fPxpo1axAdHS3Wuvj4+MDHxwfBwcEIDg42eAwPDw+Eh4ejbdu29f39bEvBsjg+KMPdUgpYCCGEEEexOmAZPXo0cnJyMHv2bGRmZqJbt27Ytm2bWIibkpICiUSXuPnuu++gUqkwatQog/PMmTMHH374Yf1G72ja1vzeKMed4nInD4YQQghpODie5++J9bmFhYXw9/dHQUGB/epZVKXA3AgAwIKYf/Du8B72eRxCCCGkgbD0/Zv2ErKGhyc02qesrIh2bCaEEEIchQIWa3AcqmRsWqi8JN+5YyGEEEIaEApYrKT28AYAVJXRBoiEEEKIo1DAYiVeW3iLCvtvBUAIIYQQhgIWa2l7sYB2bCaEEEIchgIWK3FKFrDQjs2EEEKI41DAYiWpNmBRqEugqtI4eTSEEEJIw0ABi5WEDRB9UI6ictqxmRBCCHEEClisJFFq2/NzZSgsr3LyaAghhJCGgQIWaymE9vxllGEhhBBCHIQCFmtpVwn5cGUoLKMMCyGEEOIIFLBYS9uHxQflKKQMCyGEEOIQFLBYS8FqWHxRSlNChBBCiINQwGItmhIihBBCHI4CFmspKcNCCCGEOBoFLNYSpoRoWTMhhBDiMBSwWEsvw0JFt4QQQohjUMBiLW2GRcFVobSk1MmDIYQQQhoGClispfADDw4AoC7Ld+5YCCGEkAaCAhZrSSRQe3gDAPjyQicPhhBCCGkYKGCpA42cTQvx5QVOHgkhhBDSMFDAUge8to5FoqIMCyGEEOIIFLDUAaddKSSrLIZGwzt5NIQQQsi9jwKWOpB6+gMAfFCKEhX1YiGEEELsjQKWOpBoAxY/lFLzOEIIIcQBKGCpA2FKyJej9vyEEEKII1DAUhfaols/lNIGiIQQQogDUMBSF/rt+csow0IIIYTYGwUsdaG3AWJRBQUshBBCiL1RwFIXSlZ060tTQoQQQohDUMBSFwoquiWEEEIciQKWutCvYaFlzYQQQojdUcBSF/o1LJRhIYQQQuyOApa6MFglRBkWQgghxN4oYKkLbYZFwVWhrKzEyYMhhBBC7n0UsNSFwlf8tqqswIkDIYQQQhoGCljqQiKF2sOHfU8BCyGEEGJ3dQpYli5diujoaCiVSvTq1QtHjx41eezy5cvRv39/BAYGIjAwEPHx8QbHV1ZW4t1330Xnzp3h7e2NyMhIjB8/Hunp6XUZmsNo5NosS0WRcwdCCCGENABWByzr1q3D9OnTMWfOHCQlJaFr164YMmQIsrOzjR6/Z88ejB07Frt370ZiYiKioqIwePBgpKWlAQBKS0uRlJSEDz74AElJSdi4cSMuXbqExx9/vH6/mb1pC28lqkInD4QQQgi593E8z/PW3KFXr17o0aMHlixZAgDQaDSIiorCa6+9hpkzZ9Z6f7VajcDAQCxZsgTjx483esyxY8fQs2dP3Lp1C02bNrVoXIWFhfD390dBQQH8/Pws/4XqqGr5Q5ClHcXLqmlY/NFsKD2kdn9MQggh5F5j6fu3VRkWlUqFEydOID4+XncCiQTx8fFITEy06BylpaWorKxEUFCQyWMKCgrAcRwCAgJMHlNRUYHCwkKDL0eSemrb83OlKKLmcYQQQohdWRWw5ObmQq1WIywszOD6sLAwZGZmWnSOd999F5GRkQZBj77y8nK8++67GDt2rNlIa968efD39xe/oqKiLP9FbIDTTgn5gdrzE0IIIfbm0FVC8+fPx9q1a7Fp0yYolcoat1dWVuLpp58Gz/P47rvvzJ5r1qxZKCgoEL9SU1PtNWzj9PYTovb8hBBCiH3JrDk4JCQEUqkUWVlZBtdnZWUhPDzc7H0XLVqE+fPn459//kGXLl1q3C4EK7du3cKuXbtqrUNRKBRQKBTWDN+2xG63ZSgsowwLIYQQYk9WZVjkcjliY2ORkJAgXqfRaJCQkIDevXubvN/ChQvxySefYNu2bYiLi6txuxCsXLlyBf/88w+Cg4OtGZZzKHTt+amGhRBCCLEvqzIsADB9+nRMmDABcXFx6NmzJxYvXoySkhJMmjQJADB+/Hg0btwY8+bNAwAsWLAAs2fPxpo1axAdHS3Wuvj4+MDHxweVlZUYNWoUkpKS8Oeff0KtVovHBAUFQS6X2+p3tS2lrug2n2pYCCGEELuyOmAZPXo0cnJyMHv2bGRmZqJbt27Ytm2bWIibkpICiUSXuPnuu++gUqkwatQog/PMmTMHH374IdLS0rBlyxYAQLdu3QyO2b17NwYMGGDtEB1DCFhQilQKWAghhBC7sjpgAYCpU6di6tSpRm/bs2ePwc83b940e67o6GhY2QrGNYhFt2W0YzMhhBBiZ7SXUF0p9WtYKMNCCCGE2BMFLHVFy5oJIYQQh6GApa7ExnG0rJkQQgixNwpY6kqbYVFwlSgrK3XyYAghhJB7GwUsdaXwFb9VlxU4cSCEEELIvY8ClrqSSKH28GHflzt240VCCCGkoaGApR54bZaFq6AMCyGEEGJPFLDUh4I1j5NVFkGjccNeMg1Z6R1g7+dAfoqzR0IIIcQCFLDUg8STFd76oAxFFbS02a0krwF2fwocWuLskRBCCLEABSz1INHbT4iax7mZ8gLDS0IIIS6NApb6EHuxlFJ7fnejrjC8JIQQ4tIoYKkPg263lGFxK1Uqw0tCCCEujQKW+hD3EypDEbXndy+UYSGEELdCAUt9KHQbIFJ7fjcjZFbUlGEhhBB3QAFLfVDRrfsSMis0JUQIIW6BApb60M+w0JSQe6miKSFCCHEnFLDUh1DDwpVRhsXdqKnolhBC3AkFLPVhUMNCGRa3QhkWQghxKxSw1IeSljW7LTUV3RJCiDuhgKU+FELjOFrW7HaqqOiWEELcCQUs9aHNsCi4SpSWlTp5MMQq1IeFEELcCgUs9aHNsAAAX0Z70rgV6nRLCCFuhQKW+pBIofHwBgDw5YVOHgyxCmVYCCHErVDAUk+8NssiURWC53knj4ZYTMisaKoAjca5YyGEEFIrCljqS9vtVqkpQUUVvfG5Df3MCq0UIoQQl0cBSz1JPLXt+UFLm92Kfu0KTQsRQojLo4ClnjhhaTNHzePcin6QQoW3hBDi8ihgqS+heRzKKMPiLnjecBqIpoQIIcTlUcBSXwbt+SlgcQvVAxSaEiKEEJdHAUt96bXnzy2mT+puoapagEJTQoQQ4vIoYKkvhW5KKLuo3MmDIRahDAshhLgdCljqS7us2ZcrRXYhvfG5BcqwEEKI26GApb70alhyiihgcQvVMypUdEsIIS6PApb60qthoSkhN1E9o0JTQoQQ4vIoYKkvoQ8LSpFNGRb3UD1AoSkhQghxeRSw1JdehiWrsJz2E3IHlGEhhBC3QwFLfYkZljKUV2pQVEHdbl0eZVgIIcTt1ClgWbp0KaKjo6FUKtGrVy8cPXrU5LHLly9H//79ERgYiMDAQMTHx9c4nud5zJ49GxEREfD09ER8fDyuXLlSl6E5njbDouAqIUclrRRyB9VXCVHRLSGEuDyrA5Z169Zh+vTpmDNnDpKSktC1a1cMGTIE2dnZRo/fs2cPxo4di927dyMxMRFRUVEYPHgw0tLSxGMWLlyIr7/+GsuWLcORI0fg7e2NIUOGoLzcDYpYtRkWgK0UosJbN0B9WAghxO1YHbB8+eWXmDx5MiZNmoQOHTpg2bJl8PLywooVK4wev3r1arz66qvo1q0b2rVrhx9//BEajQYJCQkAWHZl8eLFeP/99zF8+HB06dIFP//8M9LT0/HHH3/U65dzCIkUkPsAYHUstLTZDVAfFkIIcTtWBSwqlQonTpxAfHy87gQSCeLj45GYmGjROUpLS1FZWYmgoCAAwI0bN5CZmWlwTn9/f/Tq1cvsOSsqKlBYWGjw5TT63W5pSsj1UYaFEELcjlUBS25uLtRqNcLCwgyuDwsLQ2ZmpkXnePfddxEZGSkGKML9rD3nvHnz4O/vL35FRUVZ86vYFvVicS+UYSGEELfj0FVC8+fPx9q1a7Fp0yYolcp6nWvWrFkoKCgQv1JTU200yjrwCQUAROAO9WJxB9TplhBC3I5VAUtISAikUimysrIMrs/KykJ4eLjZ+y5atAjz58/Hjh070KVLF/F64X7WnlOhUMDPz8/gy2lC2gAAWkrSaUrIHVAfFkIIcTtWBSxyuRyxsbFiwSwAsYC2d+/eJu+3cOFCfPLJJ9i2bRvi4uIMbmvevDnCw8MNzllYWIgjR46YPadL0QYsrbg0mhJyB9SHhRBC3I7M2jtMnz4dEyZMQFxcHHr27InFixejpKQEkyZNAgCMHz8ejRs3xrx58wAACxYswOzZs7FmzRpER0eLdSk+Pj7w8fEBx3GYNm0aPv30U7Ru3RrNmzfHBx98gMjISDzxxBO2+03tSciwcJRhcQuUYSGEELdjdcAyevRo5OTkYPbs2cjMzES3bt2wbds2sWg2JSUFEokucfPdd99BpVJh1KhRBueZM2cOPvzwQwDAO++8g5KSErz44ovIz89Hv379sG3btnrXuTiMNmBpxmWhvKIcZSo1POVSJw+KmEQZFkIIcTscf49sflNYWAh/f38UFBQ4vp6F58HPiwKnKkJ8xUL85+1n0SzY27FjIJbb/n9A4hKAkwK8Guj8NDByubNHRQghDZKl79+0l5AtcBy4kNYAtNNCtFLItQmrghS+2p/p34sQQlwdBSy2IhbeUh2LyxP6sAjbKtCUECGEuDwKWGylkTZgkdBKIZdHGRZCCHE7FLDYSkhbADQl5BbEDIuP9mfKsBBCiKujgMVW9JY25xSUOXkwxKwaGRYKWAghxNVRwGIrQc2h4WTw5ipQmX/b2aMh5ogZFpoSIoQQd0EBi61IPVDu2wwA4F14zcmDIWapqwUsNCVECCEujwIWG1IHs6XNgaU3nTsQYp4QoAirhCjDQgghLo8CFhuShbUDAERUpkBVpXHyaIhJQoAip6JbQghxFxSw2JAynAUsrSTpyCmmT+0uq4qKbgkhxN1QwGJDXCO9pc2F1IvFZVWvYaEpIUIIcXkUsNiSdmlzI64Ad/KynTwYYlL1DAtNCRFiG2V3gR3vA5lnnD0Scg+igMWWFD64I20EAKjMvOjkwRCT1NVa81OGhRDbOL8ZOPQNsP8LZ4+E3IMoYLGxO17RAAAu97JzB0JMq97pltcAGrXzxkPIvaK8gF2W5jl3HOSeRAGLjRX7tgAAKAuuOnkkxKTqnW4BXRBDCKm7Sm3tXnmhc8dB7kkUsNhYVSDrxeJfctO5AyGmVe90C9C0ECG2UKXdlqSCAhZiexSw2JgklK0UCq245eSREKM0aoDXTv94eAPg2PdUeEtI/VGGhdgRBSw25hXZHgAQpsnS/eclrkN/6kcmB2QK9j1lWAipv8pSdkkZFmIHFLDYWFBoExTwXpBCA3Uu1bG4HP3ARKpgXwCgrnTOeAi5l1RpP6SpVfSBjdgcBSw2FuyrxDU+EgBQfPuck0dDatCf+pF6sC+Aim4JsYXKMt33lGUhNkYBi41JJRxuS5sCAMqpF4vrETIsUgXAcTQlRIgt6QcsVMdCbIwCFjvI9WzGvsm55NyBkJqEDIsQqEjlhtcTQuquSm8aiDIsxMYoYLGDIh9tL5a8804eCalBzLBoAxXKsBBiOzQlROyIAhY7yA/ujgpeBv+SG0DGKWcPh+gTalWqZ1hox2ZC6o+mhIgdUcBiB76BjbBDE8d+OPmLcwdDDAmBiRCo0JQQIbZTRRkWYj8UsNhBIz8l1qsHsB9Or6flfa6keoaFpoQIsR391zrKsBAbo4DFDkJ9FTio6YRsSSOgPB+4tNXZQyICyrAQYj9C4ziAMizE5ihgsYMIfyU0kGAzBrArkv7r1PEQPZRhIcR+qijDQuyHAhY7aBbkDQBYVdaXXXF9D5Cf4rwBAUB6MpD4LaDROHcczqbfhwWgoltCbEWjqbasucB5YyH3JApY7MDfywP+nh64zYeipHFfADyQ/KvzBlRRBPwyEtg+C7h1wHnjcAViHxaaEiLEpqqq1epRhoXYGAUsdhId7AUAuNZkBLsi+RfnZTcSvwVKc9n3xdnOGYOrqJ5hoSkhQmyjesBCNSzExihgsZOmwWxa6LiyL6DwZ1NCN/c5fiAlucChb3Q/N/QXEcqwEGIf+j1YAJbZJcSGKGCxk2ZB2gxLvhroPIpd6YyeLPu/BFR6LxwNPU1LGRZC7KN6wNLQX2uIzVHAYifNtFNCKXdKge7PsSvPbwHK7jpuEPmpwLHl7PtG7dhlQ//UI64SqpZhoaJbQuqnqnqGhQIWYlsUsNhJM+2U0M28EiCiGxDWiX2Kv+jAnix75rM34uj+QLtH2XUN/UVE7MNCmx8SYlNC0zhO+7ZCGRZiYxSw2IlQdJt2twwqNQ+0fJDdkHbCMQPIvgicWsO+j/8QUPix7ynDwi6pDwshtiU0jfMOZZdVZYC60nnjIfccCljspJGvAp4eUmh4IC2/DIjsxm5IT3bMAHZ9AvAaoN1jQJM4QKkNWBr6px7qdEuIfQirhHwa6a5r6K83xKbqFLAsXboU0dHRUCqV6NWrF44ePWry2HPnzmHkyJGIjo4Gx3FYvHhxjWPUajU++OADNG/eHJ6enmjZsiU++eQT8Dxfl+G5BI7jxDqWW8K0EABknbP/p46MU8DFP1lqdtBsdp2YYWngLyCUYSHEPoSiW7kv4MGmxKl5HLElqwOWdevWYfr06ZgzZw6SkpLQtWtXDBkyBNnZxvt7lJaWokWLFpg/fz7Cw8ONHrNgwQJ89913WLJkCS5cuIAFCxZg4cKF+Oabb4we7y6aBgkBSykQ1IItb1ZXADkX7fvAt4+xy5aDgEZt2fcUsDDiKiEquiXEpoSAxUMJKHzZ95RhITZkdcDy5ZdfYvLkyZg0aRI6dOiAZcuWwcvLCytWrDB6fI8ePfD5559jzJgxUCgURo85dOgQhg8fjkcffRTR0dEYNWoUBg8ebDZz4w50GZZSgOOAiC7sBntPCxVlscuAprrr6AWEEfuwUNEtITYlrBKSeeqmoBv6ByRiU1YFLCqVCidOnEB8fLzuBBIJ4uPjkZiYWOdB9OnTBwkJCbh8+TIA4NSpUzhw4ACGDh1q8j4VFRUoLCw0+HI1wkqhW3kl7IqIruwyI9m+D1yUwS59I3TXKanoFgD1YSHEXoRVQh6euoxuQ/+ARGxKZs3Bubm5UKvVCAsLM7g+LCwMFy/WfZpj5syZKCwsRLt27SCVSqFWq/HZZ59h3LhxJu8zb948fPTRR3V+TEcQMyx3tNXzkTHsMuOUfR+4KJNd+upNwQkZlob+iYc63RJiH1V6U0L0AYnYgUusElq/fj1Wr16NNWvWICkpCatWrcKiRYuwatUqk/eZNWsWCgoKxK/U1FQHjtgy0doMS8qdUmg0vC7DknkWUFfZ74HFgEUvwyJ84lGrdIWnDRFlWAixj0q9KSGqmSN2YFWGJSQkBFKpFFlZWQbXZ2VlmSyotcSMGTMwc+ZMjBkzBgDQuXNn3Lp1C/PmzcOECROM3kehUJisiXEVEf5KyCQcVFUaZBaWIzKoJaugVxUBuZeAsI72eWBxSshIhgVgaVr9pYcNSY0Miwe7pKJbQupHLLr1pDYKxC6syrDI5XLExsYiISFBvE6j0SAhIQG9e/eu8yBKS0shkRgORSqVQuOs3Y1tRCaVIEq7UuhmXgkgkegKb+01LVSl0u3MrJ9hkUgBuQ/7viF/6qmeYREuaUqIkPqpMlLDQsuaiQ1ZPSU0ffp0LF++HKtWrcKFCxfwyiuvoKSkBJMmTQIAjB8/HrNmzRKPV6lUSE5ORnJyMlQqFdLS0pCcnIyrV6+KxwwbNgyfffYZtm7dips3b2LTpk348ssvMWLECBv8is4lLG1OydPWsQjTQvZaKVSiXV4u8QC8ggxvozQt9WEhxF7EKSEloPRn31OGhdiQVVNCADB69Gjk5ORg9uzZyMzMRLdu3bBt2zaxEDclJcUgW5Keno6YmBjx50WLFmHRokV44IEHsGfPHgDAN998gw8++ACvvvoqsrOzERkZiZdeegmzZ8+u56/nfDUKb4UGcvZaKaRfcMtxhrcpfIEiNOxCOOp0S4h9iFNCXrrrGvKHI2JzVgcsADB16lRMnTrV6G1CECKIjo6utWOtr68vFi9ebLQLrrursbRZaNGfeQbQqNlUjS0Zq18R0LwyZVgIsRdxSkip+yDQkF9riM25xCqhe1kz/W63ABDcirWtriwFcq/Y/gGNLWkWiEubKcNSs9MtbdJGSL0Imx/KPKmNArELCljsLDpEF7DwPM8yKuGd2Y32mBYy1jROQDUsNTMs4pQQZVgIqRdqHEfsjAIWO2sS6AWOA4orqnCnRPvp3p47N1uSYWnILyJihsXIlJAbb7ZJiNNVGVnW3JA/HBGbo4DFzpQeUkT4KQEAN/OqF97aYWmzELD4GKth0VbuN+QXETHDUm1KCKBpIULqQ3+VkII63RLbo4DFAZpqVwql3Km2p1DmacDWvWYsqmFpoAELz5vudAtQ8zhC6kOcEvLSfThSFbPFBYTYAAUsDtAsiK0UupmrzbCEtGGFaapiIO+qmXvWgUU1LA30U49+BsVohoUCFrdz5wawex5QesfZIyH6ewkJrzVAw/2ARGyOAhYHaBYiZFi0AYtUZp/C26oKoEz7wk3LmmvSX7osZFgkUoDTLi2nwlv3c/ArYO98IHm1s0dC9KeEZHJ2CTTc1xticxSwOICYYRF6sQC6aSFb1rEI00FSBeAZWPP2hr6sWb85nP5UEPVicV/F2n3NirOdOw5iuJcQQKsSic1RwOIAQrdbsT0/YJ+VQua63AL0AiIEJJzUsGEfdbt1X2X57LKc9qxxKnUlwGtrVYSApaFndInNUcDiAELAkleiQlG5to5Cf6WQrQpvi80U3AJUw1K9B4tAzLBQwOJ2yu6yy/J8pw6jwavU+zAmEzIsDbzIn9gcBSwO4Kv0QJA3+xQvdrxt1E5beFtku8JbcyuEAPrEU73LrUDsdktTQm5HDFgow+JUwgohcLoPANQ8jtgYBSwOImRZxDoWqUxXx5J2wjYPYm6FEGD4iachNkkTApbqGRaaEnJfQmaFAhbn0m8aJ0xHU/M4YmMUsDhIx0j2n3fPpRzdlY1j2WV6km0epLYMi7jUkGdLqhuaqmpdbgVUdOueKst0G+4JtSzEOfRXCAkU1KiS2BYFLA7yRLfGAIC/zmSgpKKKXdm4O7t0VIbFw1O3hLchpmnV1brcCijD4p6E6SCAMizOVn2FEEBT0MTmKGBxkNhmgYgO9kKpSo2/z2ozIULAknnGNm+WYlv+MOO3c5xemrYBFt4KRbfVa1io6NY96WdVygsa5jSnq6jS2/hQ0NBXJRKbo4DFQTiOw6jYJgCA30/cZlcGNmf9UtQqIOts/R9EnBIykWEBGvaLCBXd3lv0Myy8umFOc7oKYZWQzMIMS+ZZ9/zQREGxU1HA4kAjujcBxwGJ1/OQeqeUZTwibTQtVFmmK0A0VcMCNOyAxdSyZpoSck/6AQtA00LOJO4jpF/DYuK15vYJYFlfYNPLjhmbrSR8AnzSCFj9NHB+M3XGdgIKWByocYAn+rQMBgBsTErTXqkNWNJP1u/kQnZF5qnbeMyYhjyvbCrDQkW37ql67xUKWJzH2JSQqdeaWwfZZZqNFhs4yqW/AE0lcGU7sH488EU74K932H5WxCEoYHEwcVoo6TZ4ntetFKpvhqW2LreChtyenzIs95bqGRZaKeQ84ioh/RoWE43jss+zy6J0vf4tbqAwnV12G8em3cvuAEe/B34d49xxNSAUsDjYkI7h8FHIkHKnFMdu3tVNCeVcql8QUdsKIUFDnhISMigmlzVTwOJWaErIdVTq7dQsEJY1V8+wZJ3TfZ9/y77jshVVqS6jN2QuMO0sMFq74WbOJd3vT+yKAhYH85LL8EhnVmOy4UQq4BsG+DUBwNdvXyExw2JihZCgQWdYhMZx1YtuPdglTQm5l+oZFWrP7zxi4zgv3XXGGsepq9gbvODuTbsPzSaED4Qe3mzKXSoD2j0KKAMA8LbrVk7MooDFCUbFRgEA/jqTiVJVlW36sRRbsEIIaOA1LCYyLMLPNCXkXijD4jqEqR2ZsaLbIt1+aXeuG34wqE/AwvPAxpeAzVMAjbru57FEobbm0C9CN+XOcUBIG/Z97mX7Pj4BQAGLU/SIDkTTIC8UV1Rh+7lMvcLbehSh1dblVkAZlpoZFiq6dU9CwCJ8qqeAxXmEZc3Gim71O2tnnzO4W70KVvOuAafXAid/AfZ/WffzWKJQm2HxizS8vpEQsFyx7+MTABSwOAXHcRjZnRXfbjhxW6/wtj4Bi7U1LA3wxd1khoWKbt2SMAUUGM0uqejWeYytEpIpAYl2ulWYFsrSFtwK/wfrk2HJ0wsS9swDUo/W/Vy1ETIsvtUCFsqwOBQFLE7yZHfWqv/QtTzk+nYAwAEFqUBxdt1OaHGGhTrd1lglREW37knIsAQ2Z5eUYXEeY6uE9DtrC1PQwgqhFg+wy/oELGJWg2ONA3//l/3+BopMZFiEgCWHAhZHoIDFSaKCvNA1KgA8D2y7WqL7w69rlsWSLrdAA69hMdXplopu3ZIYsDRjlxSwOI+xVUJAzVWJwgqhto+wy7s36949Vsiw3PcKENAMyE8B/nzTPt1ohSXNpgKWvCu6Oh1iNxSwONHQTiwbsu1sPetYVCW6FwRT+wgJGvKyZpN9WKjo1iiNGsi+4JrtyDVqXYAiTAnRKiHnEVcJeRper/8BSVWiy6i0eRjgJOx+xVl1e0whwxLZHRj5H7ax69nfgVO/1u185ohFt9UCloBm7ANQVTnLkBO7ooDFiYSAJfF6HkpDurIr67JSSMiueHjrimpNsaboVlUKfNcXWDvO+jG5Iup0a519i4Bv7wNOrXX2SGrSz6aIAQtlWJxGXCVULWDR/4CUfREAD3iHstU2/qyOr87TQkLAEtIKiOoBDHyP/bz1bVaQa0umim6lMiCopXY8NC1kbxSwOFGzYG90iPCDWsPjYLk2rZ12wvpPtJZ2uQWsmxJKP8k2Zbz4571R0Eidbq2TeZpd1nfbCHsQpoPkPoBXCPueAhbnqW1KqLxAt0IorAO7FALNuqwUKrsLlOay74Nbsct+bwLN+gGVJUDiUuvPaYq6UpcFql50CwAhrdllfQKW9JNA6rG637++Uo8CmWec9/gWooDFyYQsy/pUP1ZRX3bX+k8clq4QAnQvIFVl7D+iOUKBHGDYndJdiauETGVYKGAxIATCrpjqFgJoz0DAM8DwOlvJucw2uSO1M9Y4DjBsHiesEArtyC6FgKUuGZZcbaM23whd1lgiZfUsgG6/IlsozgLAAxIZ4N2o5u2N2mrHVIeAJecS8OtY4IcBwMqhQOmd+oy0bopzgJ8eA1YNq/09wckoYHGyodqut3uuFUId1oldae20kKUrhADDKaPapoX0g5R7IWAR+7CYyLDQlJAhVw5YyrUZFs8A3WafqiLWSdVWNr3ENrlzxQyTqzHWOA7Qy7AUGsmwaFd31SVgEQpuheyKoGlvdplzESjJs/68xggFt74RgMTIW2ZIHXqxFGYAW15nU66X/mLXaSoNuwA7SuZp9tpXdtfwQ6oLooDFyVqF+qJ1qA8q1TxuKbR/+BnJ1p1EzLBYELBIPXTzzLUV3hpkWFw/XVgr6sNiOY1GlwbPd8GARcimKAMMdye3ZTG5sM+NM95E3I2xxnGAiQxLtSmhu3WYEhLrV1obXu8dDDRqx75PSbT+vMaYWiEkEMZg6d/JzYPAN92BpFUArwHaPQZEaGsYndHiP+ei7nsX30GbAhYXIBbfFmsDjuyLZo42wpoMC2BZHQvPsxUiAmsyLLePA1+0B879Yfl9HIE63Vqu7A77xAew1Teu1rdHqGHxDGRBuIc3+9lWK4U0at1j5KfY5pz3MmON4wBdhiXvmrbmhNMFFPWZEhIyLEJ2Q1+zPuzy1iHrz2uMfobFmGBtwFKaa9mUzqGvWYAXGQM8vx0Ysxpo0pPd5oyARf91vj7d1h2AAhYX8HAn9h/hr8wAdkWOlQGLWBBmQQ0LYNlKoYJUw0+rWect368j6We2dfyZ3yw73lEow2I5IQgWFNx2zjhM0a9hAXRZFlsV3pbls0+/gPvsKOxMxhrHAboPR7e1BaVBLQC5ts4lSDslVJzFViRaQ6hhCW5d87Zmfdllio0CliIhw9LY+O0KH+0Gtqh9WkhVAlzfw74fvhRoeh/7XpjacnbAkuba058UsLiA9hG+iA72wrkqbcqxINW6T7TWTAkBlvViEdK3jdqxF6GqMrZxmSVuH2eXd13shb7WDAsFLCKXD1j0algA2wcspXr1D644JeZqalslJOwlJNSvACzYFP7drMmyaNS616KQVjVvF+pYMk7ZJjMoTgmZ+UAorhSqZVro+h6WjQpoqpsaA3QBi6WvsbbC84ZTWdnnrQ8eHYgCFhfAcRwe7hSBfPiiQBrErrR0PlRdpXtBFfoa1MaSDItQvxLWCQhtz77POlv7ucsLdfd1tVR6bRkWmhLSEYJggasV3upPCQG2XykkLJkFXO/v2NVoNLr/O6YyLAJhhZCgLtNC+Sns8aQKwD+q5u3+jVlDN14DpB6x/LymmOrBos/SPYWEAtu2jxi2oAjW9nLJu+bYjrkFt1mxukTG2gPwapde3kwBi4sQ6ljOC1kW/TSdOXdvsv+8Hl6Af1PL7qPU641gihiwdADCtauXMi0IWNKTAGj7yFQU6N5YXAH1YbFccbUMi6tlGYRaFXtNCelnWApuWz4d2hAJ9SuAkRoWf8Of9TMsQN1WCgnTLsEt2VJmY4RpoVs2KLw1tfGhPkt2bdaogUvb2Pdthxre5h/F2lqoK4BCB2YzhfKD4NZAkzj2vQvXsdQpYFm6dCmio6OhVCrRq1cvHD1qepfMc+fOYeTIkYiOjgbHcVi8eLHR49LS0vDss88iODgYnp6e6Ny5M44fP16X4bmlLk380TjAExfV2nlSS+tYcrSBTUgb40vujBFeRCyZEgrtyLIsgGWFt9WbH7nStBB1urWc2D1ZW2/gqlNCygDtpR0DFk1lzSkyoiNMBwFGApZqnbdNZlisWClkakmzvmbaaaH6Ft7yvOmND/VZkmFJO8Eydwp/XUAlkMp0NT227tJrjvDBNLQd2+IAcOll/FYHLOvWrcP06dMxZ84cJCUloWvXrhgyZAiys43vMlxaWooWLVpg/vz5CA83XmNx9+5d9O3bFx4eHvj7779x/vx5fPHFFwgMDLR2eG6L4zgM7RSOy7x2WsfS9fDCiiKh8t4StU0JqSt1//HCOugFLBZkWG5XC1hcqWCRMiyWE96gI2PYpatPCQmBi61WCZXkGv5M00KmCU3jJB41Mx76U0IyT92bsqAuU0KmljTrEwKCtOO6HjF1UZqn+6BjblGDELDcvWn68YTpoNYP6TZc1eeMwlvh/SO0g24/Oxde2mx1wPLll19i8uTJmDRpEjp06IBly5bBy8sLK1asMHp8jx498Pnnn2PMmDFQKBRGj1mwYAGioqKwcuVK9OzZE82bN8fgwYPRsmVLa4fn1kb3iMJlDQtY1FkWTgkJmZhQKwKW2pY1515hnyoVfixVKaRxC1LN1wjwvC5gEVO9LhSw1JphoYBFJAQsQprY5TIs+ezSblNC1ZanUsBimvAGXb3LLaArugVYR9jqAU1QHaaE8sysEBLP24JtBKtW1W1/NoFQcOvdqGaxvj6fMJY54TWmC2cv/c0uq08H6Y8ZcGyGRcjQN9LLsORdMf7/6MQq4Ppep26GalXAolKpcOLECcTHx+tOIJEgPj4eiYl1nyvcsmUL4uLi8NRTTyE0NBQxMTFYvny52ftUVFSgsLDQ4MvdtQ7zhW9UZwCAtDjDsgJCIWBp1N7yB6otwyKmCduzwjDPQF1xm7lpoTvXWf8OqQJo9yi7zp0yLJpK2iJeICyVF/pDFKbbtotsffC8Y1cJAUABBSwmVZlYIQQAcm+2izIAhHWsebuYYbll+f89SzIsHKdbLVSf5c219WDRfzxzewrlXWOv1RIZ0Cq+5u2A3kohBwUsGo1ucUdoe9Z0L0BbB5mebHhseSGw/T3g58dt15CvDqwKWHJzc6FWqxEWFmZwfVhYGDIz6z7He/36dXz33Xdo3bo1tm/fjldeeQWvv/46Vq1aZfI+8+bNg7+/v/gVFWWkWtwNjejTAZk8+9RYVVuWRV2l+88h7GdhidqWNQtBif6yO0vqWFK1tUyR3XT/eV3lk6lGo2uEZmqVEEBZFoA9V0KGJaILS/Xz6porh5ylskxXb2TvVULCC7ir/B27IrEHi5GAheN0H5BCO9S83a8JexNXV1j291VeqCsIN1fDAugV3tYjYKmtB4s+cy36hexKs766v9XqHD0llH+LNbCTynUZcWEKuHrh7el1bGl6SBtdIOgELrFKSKPRoHv37pg7dy5iYmLw4osvYvLkyVi2bJnJ+8yaNQsFBQXiV2qqi82x19HDncJxg2PB1+Uztezeefcme4P18GLL+CxlaYZF/xOR8L25Fv3CdFCTHrrxuMqUkH4gYqoPC0CFt4Bhl1vfCLZMFHCdaSGhTkUiY7s1A/bLsAhpcgpYTBN7sBiZEgIAL22rBmMZFqlMl721ZFpIeDP3DjX9xi8QOt6mHq17dtCSHiwCc71YxOmgR0zfX1jafPeWYzYhFLLzIW3ZvwOg+3vXr2PheeCodsajxwuGy7EdzKqAJSQkBFKpFFlZWQbXZ2VlmSyotURERAQ6dDCMvtu3b4+UFNMvEgqFAn5+fgZf9wKFTAqJtmbk9uVaip/qskIIqL2GpfqeH4BuabO5DMttbYalSQ8gUBuw5Kc4dc5TpB+ImM2wuPZupQ4hZFe8QlhxoPCG4iqFt/orhIQXT7Ho1tYBi/YTJwUspolt+Y1kWAAg/iPgvilA8/uN327NSiEhYDE3HSQI7cACWVUx2+CvLmrbR0ifqV2bS+/oplHaPmz6/r4RLOjj1Y75oKe/QkjQ2MhKoZsHWBDm4Q10HWP/cZlhVcAil8sRGxuLhIQE8TqNRoOEhAT07l33NFHfvn1x6ZJhVHr58mU0a2ZF1uAe0qIjK3T0KriC23fNdB2sywohwPyUUHmhbr4+VK8uRpwSMtGiX1WiC2aa9GCpXk7C5reLja8gcyj9FUDVi245Tm+lEGVYdHtTaT9VumrAIkwHAXoZlnzbPEZJtYCl4DbVN5kibHxYvWmcoMPjwMNzTfdMMbZSSFUKbP8/4NRaw2PFHiy1TAcB7ENc03ouby6s45SQ/t/KlZ0sCAntqPtdjeE4vQZyDpgWMvb+EdENAMf+rxfnsOuOabMrXZ423GjUCayeEpo+fTqWL1+OVatW4cKFC3jllVdQUlKCSZMmAQDGjx+PWbNmicerVCokJycjOTkZKpUKaWlpSE5OxtWrun+QN998E4cPH8bcuXNx9epVrFmzBj/88AOmTJlig1/R/TRq3g0A0Jq7jbVHDd8k/jiZhke+2o9NJ2/XbYUQYD5gERrW+UboUrkAq2AXW/Qb+SSUlsQq5P0asykEmVzXaMkVCm+FDIvEw3g2irrd6gg1Ar7aWjWhg3J9msfZMstWfYUQYNspocoyoLKEfR/emRWNqlW6QmR7UJUCyWuAimL7PYa9iKuETAQstam+UkijAf54GUhcAmx6mX3CF+RZUHCrr74bIVpadAuwYEQiYwGc0GwO0C1nbmdmOkgQ5MCARcjQ62fSlX665zY9iXX5vfAn+7nHC/YfUy2sDlhGjx6NRYsWYfbs2ejWrRuSk5Oxbds2sRA3JSUFGRm64qn09HTExMQgJiYGGRkZWLRoEWJiYvDCC7pfvkePHti0aRN+/fVXdOrUCZ988gkWL16McePG2eBXdEPa1GIYl4+/jl1ApVqDMpUa72w4hWnrknE+oxBv/3YaJbe1fVGsWSEE6G35XlTzjSTbSMEtwD4diS36jdSxiPUrcbrrAl2ojsXUCiEB9WLRqb43VYCQYaljDUvWeeCLtsCR7+s/NqDmCiH976vK69d3A9AtaZZ4aFfIaT9d23NaKHEp8McrwF8z7PcY9iKuEqpjwCJkHYQPQrs/A85v1t7Is+dFqLcTMyyWBizCRoiJdcuQiU3jLMiwSD10Acf2WcCvzwDL+gEXtW/4ppYz63NU4a1GDeRop66qf+DVbyB34ieWHWraW1cW4ER1KrqdOnUqbt26hYqKChw5cgS9evUSb9uzZw9++ukn8efo6GjwPF/ja8+ePQbnfOyxx3DmzBmUl5fjwoULmDx5cp1+oXuC0g+89j9IUMk1/LDvOoYvPYD1x2+D44COkX6Apgoe+do/amtWCAG6oltNlWGXSkBXv1K9hTZgvo5F2PBQWAYL6Apv829aNz57MNWDRUDdbnWKqu3+LWRY6joldGUHy06c21T/sQHGp4TkvgC09Sz1zbIIK4S8glmaPkCvHstehPqvM7/pnn93YW6VkCX0p4ROrQX2L2I/D/2crdLKTwF2vM8CDqFHiaUZloiurPai7I71HVwrinRZaEuKbgHda/GF/wGXtrJ9eTRVbEo9Iqb2+ztqafOdG+y1TuYJBEQb3ibUsaQeYQEL4BLZFQCQOXsAxDgutD1QmIa2ktv4fDur72nkq8BXY7qhe9NAvPXdBsjvVKEMCqgUkbBqZlHuA/bizrP/lHK96n5hSqh6C20ACGM9YmrsKcTzhgW3gkAHvNBbytIMCxXd6j5V+ghTQtqlvQW32b+1tasEhEZatvo7qL6PEMCm+ZR+LFgpL9BNZ9WFUHDrFcwuxaXNdswUChvOaSqBEyuBATPt91i2VmmjDEtpLrDlNfZ9v+lArxdZVnfVY+yNM6Iry+ZIPCxfFSn1ANoMAc5tBM5vAprEWj4uYdNDhV/NLQZMGTCTTU96BbHar4BmLEMZ3MqyhRFihsXOAYvYMM7Igg0hw3JtF7v0DgXaP27f8VjIJZY1EyO0hVBtJCwN3791CP56vT/6tAyB0kOKuf1Ya+crmkhM+TUZlWor0p0cZ7yOhed1U0LGMizi0uZqAUv+LaAkh72QRHTVXe9KS5stzbBQ0a2uVkPMsGjT4arium1mKQQshem2mXKrvo+QwFYrhYSCW6GGy969WIpzDHuQHPuPe/0dVtWzhkXpD3hqn2u1Cmg/DHjwA/Zz8/5Ar1fY98J0WVBz3TJcS3QcwS7Pbbaulkrc9NDC7ArAXiOHLwEe+hjoORloM5gFXcZa8RsjFN0WprG6JnvRb8lfXXhnVosjiJ1gvsuvA1HA4qq09SLDIgrx5dNdsWpSTzTy1WUH/ItYBH6di8KBq7n45E8L9x4SGFvaXJTJ3gw4KVubX50QsFRv0S9seBjRxXBpo5hhcYGAxeIMixu9UdiLuEpIW8Pi4clakwN1q2MRi7R52+xEa2xKCLDdSiEhw+Idwi6FVVL2CliEJbeB0axQvSTbdtNnjlDfKSFAV3gb0RUY8b3hp/74OaxmRaPtpWJp/Yqg9UNsWqggxbp9cizZ9NDWvIJ0f9emWvzbgrCk2dgKUw+lLpDhJEDsRPuNw0oUsLgqbcASVHINT3ZvAomkWhpem9Lr0KUHOA74OfEWNienVT+LaWLzOL2ARciuBLc03lPBM8B4i379hnH6hAxLwW3jS6EdSQhEqvdgEVDRLcPzNQMWQK+OxcqAo7LMMEixxZu+sVVCgO1WCpmaErLXsm5hOigyBujxL/b94e9co3+RJWprHGeJB2YCXUYDY9exdv76PDyBEcvYmycAhFiwpLn6/YWC13MbjR/z1wxWIFuol+kSMiyODFgAxxTeiitMTSzYaKydOmv7iO7/vguggMVVCRmOkhxdilqfdg+INp164rUH2SeO9zedReodC9OIxqaEjDWMq07ox7JhErDqceDPN4HL2i6O1QMW33A2TaSpMlzm5wxCIGIqtUlFt0ypXpdb71Dd9XUtvK0+HWiTgMXIKiH9n+udYdErugX0poRS7dOLRQhYwjsDsZNYpiIjmRU9uoPaGsdZos1g4MkfTBe3NokD4j9kr1ttH7X+/OK00B81A8Hbx4GjP7B/h7/f0V1f6IQMC2B6aXNxTs36wbpQV+pWW5kKWPpPB3pMBh6eX//HsyEKWFyVwkf3QikUSAn09xAKbYfXH2yF2GaBKKqowpvrklFlST2Lsfb8wq6m5gKW9o8B4Fidw429wPEVujeh6gGLRKpbEuvsOhZLMywNvehWSIN7hRgGd/51zDJUT2vbNGAxkWGp735CYoZFOyXk11jbi6WCTdfYmhiwdGEb0HV+iv18xPTWJC6ltsZxttL3DWBmCtC0V+3HVtcqni02KLytW9Eo2PWp7vsLW3Rt9K3pwWJL4kohvf875YXA8geB7/vX3JjQWnnX2IcSuY8uY15dQFPg0UW6128XQQGLKxP6q2RXC1ju3tDtIeTfFDKpBItHd4OvQobjt+5i6W4LKsyr17Ckn9T1Pmj5oOn7xTwLzLgKPL8dGP4t0P8t9ull0GxdzYq+ABepY7E0w+JOxY72UGxkOgioe/M4uwQs+eyyRsASwC7rPSWk7cMiFN1KZbo+HLauY1GV6pqhhWtX4fV6mV2e3+I6+zeZU9/Gcdao6z42HkrdPj769UE3DwLXd7MiUyFQ3Po2a+BnzcaHtmSs2+3OD1gNDq/R7etjTPYFdru5qW1xhVBbp+4LVBcUsLgyoaGPMN8oEDet0i1Jiwrywqcj2HTNVwmXceLWHfPn1s+waDTaCnwe6DQKiOph9q7wDgGa3gfEjGOBylM/scDFGFNLm9VVwJEfgDMbHNO63+IMSwMPWIzVrwB1bx4nBCzCbrD1fcPXqIEKbUBit1VC1aaEAN3vb+uAJfs8exPyDtU95+GdgOj+rGHXsR9t+3j2UN/GcY4iTAud/4O95vE8a1IHADHPAcO+Zh+wCm+z663Z+NCWqgcs13br+qEAwNkNuqBan7oS+HUM8NfbQMJHps8vtuS3suGoC6CAxZWJGZZqAUu28YKp4d0aY0RMY2h44I21ySgsNzO9oV/DcmoNK5yV+wCDPzV9n7owtbT5+Arg7xnA7/8CFrUGvu0DbHsPuLHPto8vEFcJmciwUNEtYypgqWsNixCwtHiAXdanvT9gGIxUr2GxZpVQ9gX26dqY6quEgPr1Ysk4DWx9S7c3iz5hhZCQXREIWZYTP9W/c6+91bJKqFKtQX6pC/y/avkge90rTGOvd9f3ALcOsg8x989g/age+zc79sgyVj8IOD7DItSwlOaxDwhbXmc/95jMemFVlQOnfq15vzO/6bY3SFxq/LW0JJdtAQG4ROdaa1HA4sqEDEv2ecNCMf2UXjUfD++IqCBP3L5bho+2mFnqLEwJFaQCO+ew7x94x/afJkwtbT75M7sUXgyyzwGHlwKrhpkPWpJ+BpbeB+RaWUEv9mExkWGholtGCFh8qgcs2jfs4izrps3EgGWA9vz17MUi1K/IfWv2thCLbmvJsPA88PNw9remvypEuK36KiHAsPDWGoXpwC8jWaZk/xc1b88wEbC0Hcr+Dcruun7xbS2rhF75JQl95+/Cpcwio7c7jMG00EZd7UrcJF2voVaD2NQQr60DlMoN/w4cQeGjq5v5bRKbCgpoxoqOezzPrj/2H8MCcHUVsE/bIdg/CgDP9mHS75tUVQGse5adL7C503dergsKWFxZSFv2qaXsDvDHq7qCUO0KIWMpPV+lBxaPjgHHAb8n3cbey0Y+1QEo5bQvLuc3s1URIW10DZpsSWj7rJ9hyTjFCg2lcuDlA8CMa8Colbp9P46vNH6uqgrgnw9ZwHbUyn1pLO7D4gKfBJ3JVA2LV5CuqNLSaaEqlS4jE3Uf+1vmNfVbMSbWrwTUvM3Sotv8FBZ48WrdUn5BeT67HjARsFgxJVSlAtaP1xXqnttUc3m//gohfRIp0Px+9r3+5n+uqJZVQkkpd1GiUmPpbgds6Febjk+wy+MrgbTj7G+633TDY4bM000v+kY4p85DKLwVOog//g0LZDo/zYL1O9eAG3t0x5/byK7zDAIm72Kb1RamsXocgAXif05neyop/IBn1tWsAXMDFLC4MiFFyUnZtM3qp1jErLdCyJjYZoGY1IfVDLy38QxKKqoMbldrePxyMt/wTkMX2KebofBCX5ShCxpOrmaX7R5lb4TeIUCnJ4Ehc9n1F/80Pkd78U/dp9/zW6zr7WJxp9sGHrCYmhLiOOvrWPK1RYIeXux8tmjAZmpJM2B5Hxb9HkLVM3XC353c1zC4rUvAsn0Wm3pQ+rM3ieJM9oYh0Kh1Y9HvEC2I7scuXT1gEaeEatawqDU87mqng/48nY5beSWOHFlNwrSQkEntObnmNg4+jXSvRdUDSUcJaqH7PnaSbkpV4aPLjBz7D7vUqIF9n7Pv+0wFfEKBJ5ez942zG4DTv7EpouRfWC+bUSut33/ORVDA4uq6PcOiYQ9vVs3+/QMGK4RMeWtwGzQO8ERafhm+2HHZ4Lav/rmM45m6+pajnv3Atxhon/F7h2hTxTxLp1dVAGfWs9u6PWt4bGQ39gKhVgGn19c8l37hWXEmkHLY8nFQp1vLiAGLkalBa5vHCdNBQS20AY8NWtybWtIMWF50q59VEVboCMTpoCDD6/Wbx1nS0O3kal3B7JPLdXuxnNVrXJZ3jRWsengZvkEJmvdnl7eP2bdNe32Z2Usov1QlPl0aHvh+nx27t1pCpmAflABWs9d3mvHjYsYBLySwzIYzCAGFfxRr869PaC546S+gII0VEedeZn//PbSbBjeJY1P8APDnNLbKCGCBWOt4Ow/efihgcQetHwImbWUrCYRaEL0VQsZ4K2SY+yT7dLDy0A2cTGEv9DvPZ+HrXVeRx7MaljJejml3n8b2c5n2GbvBbre3WI+DsrusBXlLI0FSzHh2efK/hm8Mede0tS0c0Fz7aeP8H5aPo7YMizsX3ZYX2qaTsH6XW5+wmrcLGRJLC2/valvyC23XrQ1YqlTsBVmfUFBbfYUQYJhhMRdU6GdYqjfnMrZCCND2YpGw6Y/aVrWlJ7OGigAwYBbbfK+TsEJlM6s3AHQFt2Ed2RRQdYHN2eNqKnVTA67IzJTQnRL2/0mYVdlw/DayCp1cRHzfKywgf+gj1vfGlCZxNQNXR4l5FujzOvDMel29oSC0PdCsH8tenlgJ7NVmV3pPMTy2/9tA4zi2BxivAbpP0BVzuykKWNxFZAzwwk7dPhoRXWq9ywNtGuHJmMbgeWDm72dwOasI09clAwC63PcQMGAW/uq4COkIwSd/XkCZyk7t8/ULb5O100Fdxxh/ke7yFCuMzTpruB28kF1p/RDQR7uj6/nNlr9R15Zhcdei2ys7gYXNgS/asp1uL++oey8Z/S63tghY9DMsgPUBy9/vAP/uyH4ngdkMizZg4dXsRdoUs1NCRlYIAazA11fb8dTc+CuKgHXPsb+j1kOA+7Wfcps/wOoLSnOBm/vZdaZWCAk4zvWnhXjebOO4PG3A0jzYG3HNAqFSa/CfAzdqHOdQEV2Bty4CPV5w7jjMUfoDgz8xvgktoCu+PbCY1fQp/ICeLxoeI5Wx7sGBzdmGko8scru+K9VRwOJOAqOBf+0Ahi4EBrxn0V3ef6wDgrzluJRVhOFLDqKoogpxzQIx69GOwICZeOSJZxHpr0Rafhm+32enLc2FDEvKEeDqP+z7buOMH+sZCHTQps9P/pddVlXoAp3YSezFX+nPCictnRayuA+LG2VYKsvZcllNFVuCmfQzsOYpYGFL4I8p1gcuQsFt9S63ArEXiQMCFo1G2+BL2ytDyJiYC1g8PHX/jqamhSrLDLMqhbcNp1uMrRASiNNCZsZ/dLl2VUdT4Em9TfykHkCH4ex7YT8b/Q63pkRrp4Vu7Dd9jDOpK3UrasxkWIK85Xh1IFuuu/rwLRSUNvCO0vXVbhjLuAsfMHq9bLyuK7gl8PpJYPQvLrPjcn1QwOJuvIKAXi9ZvPw4yFuOOcNYlF5WqUYjXwW+Hdcdchn7p/eUS/Heo2y10Xd7ruH2XTvMlQsZljO/sRe3qPvMb2AW85z2+A3szUQotvWNAFoPZv/x2j3GjrF0V1uLO926UcBy6BuWtfKNBMZtYJ8YfcIBVRErsBOCQ0sJbfmrF9wK6lPDAlgXsGSd0U3/ZCQD13ax782tEuK42lcK5Vxif4OeQbpppTt6gXr1fYT01TZ+VQmQuIR9P+C9mkFVpyfZ5fkt7O9MXNJsLmDRZljSTrDz24JGDSR8ApxaV/9zCU3jAKPLmvP0ApaBbUPRLtwXJSo1ViXerP9jN2QyORA7gX0v92HTXKa4eVZFHwUsDcDjXSPxaJcIeMul+HZcd4T6GX4SerRzBHo1D0JFlQZz/7pg4iz1IGRYhOWiMSayK4Lo/uw+FYVsbw9hmXPMcyzNCei6Vl6wcLXQvdbpNj9V19dj8CdsquzRL4DpF3QtxtOSrDtnURa7tCRgqW0TQHWVbil79YClKL32PZuq9+I5oG3oZS7DAtReeCtMB4V1BEK006v6GRexLX8dApbjK1hgHRit+zfQ16wvm2orzwdOr2XBEScxvQEdwM7l14R9kk61UR3Lhf8B+xcBf7xS/830xKZ2nNH6sDvFLGAJ9pGD4zi8MoBlWVYevIFSVVWN44kV7nuVTfU89m/n1do4GAUsDQDHcVgyNgYnZw9Gj+iaf9gcx+HDxztCwgF/ncnEgM9344VVxzD/74vYcOI28orr+SYuvNAD7FOYEGyYIpHosiz7Fmnn/Dmg+3jdMQbTQolGT2OgtgyLuxXd7vyAfbpt1hfoNFJ3vUQCNO3Nvk+3NmDRZliqN40T+DVhn+bUFazGyJzC2+xNVqrQ1X54h7KfLenFcn0vu7xvCtvx++Z+9oZda8BSy9JmMWDppOt1oV/HYqroFtD9HecZmTqtLAMOfs2+7/+WLrDWJ5HqpoX2aHfBDW7N2heYYlDHYqNpoeMr2CWvZm3cLVn1ZIpQv+LhafSTfF4Je+0I8mb/vx7tHIGmQV64W1qJX4/Ws+txQ+cVxKZ6ujzt7JE4DAUsDQTHceI0kDHtI/zwxqA2AICbeaX450I2lu29hrd/O4Uhi/cjp6geQYv+pogdhuv2MTKn2zPs06ew7LT1Q4Y7hxpMC/1R+/lqy7C4U9HtjX1sKoyTsP451d8oImPYZfpJ696MimvJsEhlupqKawnmzyVOBzXX1XFIJJbtyaOuBG4dYt93Gwt0Hc2+3/+l+VVCQO3t+bP1MixCwGKQYTFTwyIUut/YCyT91/C2E6tYgzj/pkAXMx1EO2qnhYSAzYLieXF5sy0Kb3OvsvGDY0WyKYnA6XpMDYkrhIzvIyRMCQV7s/9fMqkELz3AMm5rjjh5Q1TidihgIaI34lvj6HuDsOaFXvh4eEeM790MjQM8kVtcgXd/Pw2+rp/ElP66T+0xz5o/VuDfGGg5SPdz7KSax4ibmVmwWsjiPiwuXgyorgL+fpd9H/e88RUmYZ3Y71N2V7e3iCVqq2EBdDt5CzUlplSvXxFYUseSlgRUlrCgIbQj0PdNABxw+W/gjnaFiakMS23t+bOMBSx6vVhMrRIC2OoSYdXP/97Q1QhVlgMHF7Pv+79pvrgxqpcu4wRY1pjMlnUsJ7TTq60H6/p07Hi/9u7ApphpGgcYTgkJhnWNhIeUw7WcElzPMbOai5BqKGAhBkL9lOjTKgTje0fj4+GdsGJiD8hlEuy6mI01R+vR8Oupn4Anf9S9+FpCKCrza8xeYKsTpoVKsmufFrK4062LZVjK8oGcy2w65PJ2NhWUfZ4VjQ78P+P3kclZ0AJYNy1kqsutPiFgSTls/s1TCCyEXZoFlgQsQv1KdH+WlQlppWupLmTA6jIlVJyt3dCOAxq109Ww5F7VZaKqZVhUVdVqdQa+xzIovBpYP4Gt9En+hQV7fo1Nr34TSCSGU6KWBCwBzdiSck2Vdc0Sq6ss0622i3se6D2VTUmV5AB75tX9nIDJtvz6q4QEfkoP3NeCPb87z2fV7XFJg0QBCzGrbbgv3hnCui5++ucF3Mit4ye8Zr1ZjxVrtHsMeOI71unXWE2A/rTQ2d/Nn8vdOt1WVQDbZrEeK0t7AP95CFjzNHD4W3b7oA/MF9oJ00KmCm9zr7Ci3Wy9Imuh6NZUDQvAlkkGNGUBoKndjgHDKSF9FgUs2voVYS8dAOj3puExxlYJAeZXCQl1N8EtWd1IUAsAHFBRwGpXqlSs0BsAvILx9m+n0HPuPziVqncujmPdT6P7s14vq59iU1UA65pq6u9Ln7BaCGC779aG43RTcfWZFjq/mWXd/KPYFKtMDjyibTp29AfdMmtrCKuEapkS0g9YAOChDqzPzz8XKGAhlqOAhdTq+b7N0adlMMoq1XhzXTKq1LWsELEVjmO1LOY+hQqfVo+vYNsWHPqmZndUwL063eZdYwHK4W9ZgarSn33KjugGtBgI9H2Dda00p3F3dqnffE/flteAhI+Bb+8DfnqMLbU1tfGhPo6zbFrI5JSQ0ETQRMBSWaZbDSN0NAbYdEyrh9j3Ehkr/jXG3CqhLO3u5WEd2aWHp64ZXt4VtskowGqDlAHYfTEb+aWVeOWXE4aF5zI5K3Zs1I5lVgrTWJCnXxRuTuNYFoA9+D7bt8YStmggJxTbxk7QNW1sOZD9H+I1rKfP7ROsUV/yr8ChJeaDUkC3SsjIlJBGbx8hoYZFMKg9C1hO3Lpb/6J+0mBQwEJqJZFwWPRUV/gpZUhOzceSOuy6ml1UjstZdthevsVAVhfDSVm/jh3vs+6oPz1muJqjLp1uS7W7ZF/fY92Ybh5k9xN21bbG6d+A7+9nO1p7BgFj1wEzU4Bpp4GX9gLj/2B7ixjrEqwvUhuwZJyqWd9TnKObWuAkbPXJ+ud0QZ2xLrf6agtYNBrdlJC1NSypR9i/gW8ky4To6/8WuwyMNt1bwtyUkP4KIUGIXuGtsELIMwjlal7MDqQXlOP1tScNA3XPAGDcb7rnqu8bJqdFauA4IP5D4P4Zlh0P6AKW9CSgopa6j/ICI7tCn2XPrUSmW4EnGPwZ26ss9Qjw44Os+eAfLwM7/g/47wjjG5EKzEwJFZZXQq1hU22B3h4GtzUO8ETHSD9oeCDhYi1bHRCiRQELsUhkgCc+eYK90H+z6yq2ns6wuAg38VoeBn2xF4P/vQ8fbjmH8kobbgEglQHDlwJvX2atp5v2BsCzN+Ffx+pe3MUMixVFt/u/YHP+f7xqeTFuZTnw+7/Y/ZYPAi7+Zdn9eJ7tP7PxBTbV0Kwv8PIBoO3Dlt2/upA2bAm5qphN/+i7sgMAz7IWb5wG+k3XrYrxj6q9I2bzB1igk3vJeBO5onQWdEhkugyGQAhYCtOMP6dC/UqLB2oGJc16AxP+BMasMT02c6uEhCmhUL125+LS5isGBbcZBSxzIJdJ4CWX4uDVPHy+o1oAGtAUeH47myLq9ZLpMdlCYDP2eJoqINVMHcvFrcDnrYAlPQy3NBCKbds9WjOD5t8YeHgeqwvyj2KN7FoMZMGYusJ8c0ZxSqjm0uxcbcGtr0IGhaxmgC1MC1EdC7EUBSzEYsO7NcbwbpFQa3hMWZOEf606jtQ75jvjbk5Ow4QVR1FUzppE/XToJoYvOYiLmYW2HZx3CNsq/vltrBW1bwR7Q936FgsGxAyLhUW3qhLd1gCFaZYtnQZYoCKstlEVAWvHArvn1d5o7cgybcqeAx54Fxi/hb2R1JVUxgISoGbh7SVtENX2EbbMOH4O8OZ54OmfgTGraz+3ZwDbVA0wnmURpoMCmtWsPfIOZcEhrwEK02veVwhY9OtX9DXvr9vJ1tTYgJoZFnWVLuMlTAkBur258q4ZFNym57M34qZBXvh8FHsev997HX+fyTA8b1BzNhVUW8bLFoQ6lotbjd+eehTY8DwLzu9cY5mS1U+xzRiFrrZxzxu/b+wE4N2bwJtngZf3s0xe76nstjO/mR6TOCVkui2//gohfULAsv9Kjv32MSP3FApYiFUWjOyCqQNbwUPKYdfFbDz0771YuvtqjdUUPM9j2d5reGNtMlRqDR7pHI4fnotFiI8Cl7KK8Pg3B/GfAzeg0dSjaZUpQS2Akf9hWYDTa4GTv1jf6fb0esM3vUNf197TRF3JNiMDWJpd2Ixs73xg3Ti2q7IxaUnADu3270MXsJUoxoqMrSVMC+nXsVSW64KMNnrZGw8l65EjBDm1MTctZKp+BWCrZISsS/VpofJCXZGw8OZsLVNTQneusX9buY+ujgbQmxLSy7B4BYkBS4S/Eo92icCL97Pf5e3fTuFqth2mNi0h/HsdXwH8NUO36zPAVjqtGc36orQezHb6lXiwbNoPD7DgOaglEG0iEDSm8ygAHFuBZ7LmSK9xXDV3qjWNq65DhB8aB3iivFKDA1dzLR8XabAoYCFWUXpI8faQtvj7jf7o3SIY5ZUafL79Enp89g9GfncIM347hW/3XMXM389g/t8XAQD/6tccS8Z2x+CO4dg2rT/i24dCpdbgkz/PY8CiPZj31wWcTLlbpz4vxRVVmPf3Bfx2vFrXzOi+rKgRYN08hakhSzrd8jxw5Hv28/0zWLo783TNdvHVnV7HNr7zDgV6/IutwBi+lJ370l/A8gcNV+UA7E16w/OsK2y7x2ruuFofxlYK3dzP3mR8Iy0PTowRApbre2rWS5gLWADTdSy3DrHlwkEtDJsEWkMouq2+Skh/Okii97InTAnduaFrnOcVgvR8ljloHMDeiN8Z0ha9WwSjRKXGh1vO121s9dV+GDBoDvv+6A/A6lFs1U9RFvDLk6xoOLI7ayEw+BPg1cOG7QDiJhn+7rXxi9TVzpjKsphpHKdbIWT8QwLHcXrTQpmWj4s0WBSwkDppFeqLNZN7YfHobgjxUaCgrBInbt3FbyduY+G2S1h3PBUcB7z/aHt88FgHSCSsHiHER4Hl4+Pw6ROd4C2XIuVOKb7fdx0jvj2EPvN3Yd5fFyyucbmYWYjHvzmA7/dex6yNZ2ruANv3TbaypKpct4+RJZ1ub+5nW7Z7eLO0uNBb49A3pgejUev29unzmu4FPOZZYNI21qMj7woLWs5sYLfxPPDnNODuDdYhdfgS225UJqwUyjyjW/0kTgcNrd9jNY4FFP7sDTM92fC2ugYs4nTQA6gzoT+Lqshwnxyx4LaD4fF+Tdh0hqZSl4nSmxKK1AYsMqkEcx5n901Oza97E8X64Dig/3S2QsnDC7i+G/gxngUu+bdYz5tn1gNyb3Z8SCtWGPzs78BDnwA961Bn00XbZfj0euMZRjON48SmcSYyLIBuWijhQrZYoEuIKRSwkDrjOA5PxDTGwZkDsfX1fvhmbAzejG+DJ7pF4v42jfD9s7F4oX/NNy2O4/Dsfc1w7P14fDuuO4Z1jYS3XIqMgnJ8v+86XvzviVqDlvXHUzF8yUFc1/aFqdLw2FH9U5pEAoz43rCzaG19WHgNkKjtddJ1DKuJ6P0qAA64ulO3NLa6sxvZG7VnYM06gSaxwEv72BtxZSkryv1rBnDsR9Y/hpMCo/5juhlaXQW1YFMk6goWgPE8cGkbu63t0PqdWyoDWminF/SnhXgeyKtvwGLFtEV1XkG6DslrRuua4RlbIQSwv5Eg7Wqk1GPacwQjvUA3JSRo2cgHcqkExRVVuH23DE7Tfhgr9vVrwlY3ZZ4GvEJYYGJsmXSreKDv67UXUxvT4XEW5OdcNN6nxcwqITHDYqKGBQB6Ng+Cr1KGvBIVTqbctX58pEGhgIXUm0ImRcdIfwzrGok34ltj8ZgY/Px8TwzuaKafBwAvuQyPdI7AN2NjcOKDh/DN2Bh4ekix73IOpqxOqtllFECpqgpv/3YK72w4jYoqDe5v0wgT+0QDAP6qXhAJAN7BwFMrWVAg99F9+qxOP5C5/De7FKZnglqwNwkASFxa874aDdv9FmCb9SmM9AjxDgGe2wT0f5v9fPQHNlUFsCZwUT2Nj6s+OM5wWijjFFvB4+Fd9xoRfdXrWErygPXjdfv1NGpj/H7GerEUpgNZ2jfE+o5t1H9YMW3hbeDXMayAunoPFn1CHUuFtu7FO0TMsAhTQgDgIZWgZSj7t72Y6aQ6FkFEF2DyLqBZPxasPLO+5jJwW1D6A22GsO/PrK95u5nGcWLRrZkMi4dUgoFtQwHQaiFSOwpYiEtQekgxrGsk/jMhDgqZBAkXs/Har0mo1Pa+KK9UY8WBG3jg8z3YcOI2JBwwY0hb/DSxB569j31iP3A1FwVlRpbKNr0PmJwATPhf7RkWQYsBQGg73c99XmeXp9fpPrULLv6PfQJV+AO9zNSgSKQsOHlmva44tOUgoM8bpu9TX+JGiEnAZW12peVAy3uGmCMELLePsgzTd72BC1vYcubBn7F+KcZUz7Bc+Qf4YSD7PqKr5c3UTPEMBMatZ31s0k+yFvoF2scK7VDzeKGORYv3DBJrWCIDDN+I24WzjTsv2XqVW134hgGTtrIl/U1i7fc4wm7AZ36vWa9kpnGcsFOzqVVCAlreTCxFAQtxKX1ahWD5+DjIpRJsP5eFaeuS8XPiTTzw+W58/Od55BRVoEmgJ1a/cB+mDGwFiYRDq1BftAnzQaWaN/2iFxmjq+kwRiIDD72ajl4vG94e1QOIuo/VOhz9gV2nKmVp8r3a9ua9XtQFIua0GcJ6rDz6BSuQtKYQ0lr6K4X0lzPbQmA0m07RVAEbJrGi1ZC2wAsJQJ+ppu8n9mK5Dfw5HVg9knXZDWkDPLHMNmMLasH6tUjlbCoPYKuTjLX0F5Y2axVL/VGmnZIM9zcM7ISA5YKzMyz67L2kuvVg9nddlA7cqtb5VlwlZGRKqNh80a1gQNtG8JByuJ5bgj2XqIkcMY0CFuJy7m/TCMue6w4PKYetpzMwe/M5ZBVWINJfibkjOmPXWwPQu2WwwX0e6RwBwMS0kAVOpNyFCqwbZ5VfU+ObLQpvwoe/A/7dGZgbASzrx6YyPLyB+161/AEDmgI9XgCUfnUar8WEIC3rHJsSAqdL8duCkGUBgF6vsG68kd3M38cnTNeL5fh/tPd9mdX5VC+KrY9mvdkqLYGx7Aqg2wRRK6OKTRuG+Mih9DAMBtqKGRYXCljsTaYAOjzBvj9dbVpIXCVUs3GcJVNCAOCr9MCgdizLMnHlMUxfn4ycImrXT2qigIW4pAfbhWHpM90hl0kQ7qfEJ090wu4ZA/BMr6aQy2r+2T6qDVj2X8kxPi1kQpVag3/vvIynliWigme9T/7weMT4p9a2j7Dpg8pS3RSDZyDQpCfw+NfmNyN0Fr/GgHcjFhwArFbGO8R25+/zGlsJNX4zMHS+yU3wDEgkuuki30hW2zN0gWX3tVaXp4EHtT1u2hgJQoEatR+p5ezNt/p0EAC0j2AB5o3cEtt2bHZ1wrTQ+c26aSDAZOM4ntftI2SqD4u+BSO7YGzPKHAcsDEpDQ9+sQc/J96klUPEgA26UxFiH4M7huPY/8XDSy6Fh9R8bN06zBetQ31wJbsYO89nYVRsk1rPn5JXimnrTiIpJR8AcNJvIIIKzuPjtFiEXclB/9bVaikkUuDZjWwfnsBmbCrBO7jmiV0Jx7FpoSvb2c/1XR1UXWAzwyyGpR75nG3kd9+r9g/07n+bdUE2NV3nGcgKV0tzAZkn0rQbkkf415zmCPVVIMDLA/mllbiaXYxOjS2YArwXNO3DViUV3gYu/qltKgeTjeMKy6tQqWbBhiUBi7+XB+Y92QVPx0Xh/T/O4lx6IWZvPoclu66id8tg3NciGL1bBKNZsBc4Wy79J26lThmWpUuXIjo6GkqlEr169cLRo0dNHnvu3DmMHDkS0dHR4DgOixcvNnvu+fPng+M4TJs2rS5DI/cYf0+PWoMVgalpoZKKKkxZnYQen/2Dnp/9g15z/8F9cxPw0L/3IiklH74KGb4a0w0PvLUGG3usRiG88eGWc0ZXKSGwGdB1NCvkdfVgRaBfu9PGxgFLXbUYwBr7OSorVVttkVB46x2CtGo9WPRxHCfWsTh9pZAjSSTs7x5gO31f+Yd9b6JxnDAd5C2X1phWMyemaSC2TO2Hj4d3hJ9ShuyiCmxOTsesjWcwYNEePPD5Hhy/aWYzRnJPszpgWbduHaZPn445c+YgKSkJXbt2xZAhQ5CdbbxYqrS0FC1atMD8+fMRHm5+meuxY8fw/fffo0uXLtYOixA82qXmtFBFlRov/3ICW89kIKeoAtlFFcgqrEBmYTkqqjToGR2Ev6f1x/BubN+eafFtEOwtx7WcEvx06EaNx8gsKMfh63nOaRxWV8KS6aCW5vfhaciEpc1eQTW63FbXLpxNC7nESiFH6v8WW9VWWQr8OprVs5hoHCe25a9lhZAxUgmH8b2jcfT/4vHr5Pvw+qDW6BkdBA8ph5Q7pfjXquPO2x6BOJXVU0JffvklJk+ejEmTJgEAli1bhq1bt2LFihWYOXNmjeN79OiBHj16AIDR2wXFxcUYN24cli9fjk8//dTaYRGCNnrTQv+cz8ITMY0xfd0p7L+SCy+5FF+PiUFEgFJs2CmXSdCqkY/YhRdgGZ13h7bDOxtO46t/rmB4t8YI81NCreGx8uANfLHjMsoq1egRHYg5wzq6x5RAi4HA8G9ZMSyl040TMixewcgwk2EB0DAzLADrYTR2LbD5Vdaqf+Nk1t8IqLFKKE/scmt+hZA5Sg8percMZgX2D7FtOMb/5wiSUvIxYcUxbHq1D0L9bLA8n7gNqzIsKpUKJ06cQHx8vO4EEgni4+ORmJhYr4FMmTIFjz76qMG5zamoqEBhYaHBFyH600Lv/3EWW89kwEPK4fvnYhHfIQwdI/3RqTH7ahPmaxCsCEZ1b4JuUQEoUakx/++LOJdegBHfHsSnWy+grFINjgOO3byLYUsOYNbGM8grts+KhsPX8/D094nYfq6e+6xwHBAzznjTNMJ0GM6Wvsc8a7DxoTFtG2rAArBuuSN+0K2IE7a8qLZKKM/CFULW8FHI8OOEHmge4o20/DJM+ukYiiuqar8juWdYFbDk5uZCrVYjLCzM4PqwsDBkZtb9RXXt2rVISkrCvHnzLL7PvHnz4O/vL35FRdVxszRyTxGmhRIuZuPXoyngOGDx6JiaBbRmSCQcPh7eERwHbDqZhseXHMTp2wXwVcow78nOOPjugxjeLRI8D/x6NAUDF+3BnM1nsf54Ks6mFaCiqv6rRy5kFOKFVcdx9MYdvPbrSSRR23L7CmoBvLgHVe1HILPQ/JRQmzAWsOQUVdgtWHVpEgkwZK5uI0ZwNbaVuFNi+QohawR5y7FqUk+E+MhxLr0Qr/xyQmwuSe59Tl/WnJqaijfeeAOrV6+GUml5em/WrFkoKCgQv1JTU2u/E7nntQnzRatQXWv8z57oLAYx1ujSJABjerAGZ2oNj0c6hyNh+gMY27MpIgM88dWYGPz2cm90jPRDYXkVViXewjsbTuOxbw6g05ztGL7kAHbXsQlWRkEZJq1knx6VHhKoqjR48ecTYjFobXKKKnDoWi6q6IXcallFFdDwgIeUQ4iP8ekMb4UMzYJZRqFB9WPRJ2zE+OzvbCuEakvlxaZxdahhqU3TYC+smNgDnh5S7L+Si3c2nKa/9QbCqoAlJCQEUqkUWVmG3USzsrJqLag15cSJE8jOzkb37t0hk8kgk8mwd+9efP3115DJZFCrjX9aVSgU8PPzM/giBAAm9G4GCQfMHNoOz/RqWufzvPdIO0wd2AorJsbh23GxNebLe0QHYcvUfvhuXHe80K85ercIhp9Shko1j1O3CzBp5TFMWZOE7MJyE49QU1F5JSatPIbMwnK0CvXBrrcGoF24L3KLK/DCquMoqSUFXqqqwqhlh/DM8iN44PM9WL7vOgrLa+9Lo6rS4NC1XKTeKbV4rPXxy+FbeP3XkxaNzZGE+pVwf6XR6UJB27AGPC2kr1U80GlkjauFoltbTgnp69IkAN+O6w6phMOmk2l4ftVxFLnY3xKxPauKbuVyOWJjY5GQkIAnnngCAKDRaJCQkICpU8204jZj0KBBOHPGcBfQSZMmoV27dnj33Xchldq57TS55zzXOxpPxUVZtZzSGF+lB94eYn5VjVTCYWjnCAzV1s7wPI/bd8uw6tBNrDh4A1tPZ2DfpRy8M7QdBrRphHPpBTiTVoDTtwuQdrcMnRr7o1/rEPRvHYIQHwVeXZ2Ei5lFCPFRYOXEHogM8MSPE+LwxNKDuJBRiGnrkvH9s7Em30wXbruEW3ks6EjLL8Nnf13A4n8u46m4KDzYLhSRAUpE+HvCWyGDqkqDg9dysfV0Bnacy0RheRVCfBTYM2MAfBQ1XxrKK9UY88NhaHgeP03qWed0/6Grufhg81nwPOtr8v5jNuxuW0/ikmZ/803s2kX4Ycf5LFxsaCuFLCTu1FyPotvaDGwXiu/Gdccba5Ox73IOnlqWiP9M7GFyKo+4P6tXCU2fPh0TJkxAXFwcevbsicWLF6OkpERcNTR+/Hg0btxYrEdRqVQ4f/68+H1aWhqSk5Ph4+ODVq1awdfXF506GW757u3tjeDg4BrXE2Kp+gYrdcVxHKKCvPD+Yx3wRExjvLfpDE7fLsAHf5w1evz13BJsOZUOgLWCzy1WwdNDipUTeyAqiE07NAn0wvfPxWHsD4ex83wWFm6/hJlD29U41+Hrefjp0E0AwPLxccgrrsB/DtzAlexi/HTopngbAPgpZeB5oKhaxia3uAIrD9zAa4MM29UDwH8TbyE5NR8AMGnlUayZfB+8jQQ25twpUeHN9cniSq2fDt3E2F5N0bKRkR2unaC2Jc2Cdg2xRb8VLG3LX1+DO4Zj/Uu98fyqY7iYWYQnlh7EfybEoUuTALs+LnEOq2tYRo8ejUWLFmH27Nno1q0bkpOTsW3bNrEQNyUlBRkZusZd6enpiImJQUxMDDIyMrBo0SLExMTghRdesN1vQYgL6tTYH5te7YsPh3WAj0IGmYRDhwg/jOkRhU+f6ISVE3tg6sBW6BoVAAkH5BarIOGApeNi0LmJ4XLp2GaBWDCqMwBg2d5r+OTP8wZty0tVVXj399MAgLE9o/BQhzCM6dkUO968Hz8/3xOPdA5H2zBf+CpZgFFYXoWiCpZRGd+7Gda9eB8Wj+4GAPhh/3UUlBqm1wtKK7Fk91UArL7j1O0CvPzLCePN9UzgeR7vbDiNrMIKtGzkjfvbNEKVhsenf5637om1o4wC7QqhAPP1dGLAklVE7eONEAMWO9SwVNe5iT/+mNIX7cJ9kVNUgae/T8TBq7l2f1zieBzvVh2wTCssLIS/vz8KCgqonoW4nCq1BlUa3mTmp6C0Eodv5CHER4HYZoFGjwGA7/dew7y/LwIABncIw+Ix3eAll+Gj/53DyoM3EemvxPY374ev0sPkOYorqpBZUIbySg3aR/hBqp1e0mh4PPL1flzMLMKrA1rinYd1WZz5f1/Esr3X0CbMB/Oe7IxnfzyKsko1hnWNxFeju5mt9xD89/AtfPDHWcilEvwxpS+UHhIMWbwPlWoeKyf2wMB2oWbvz/M8lu+/jqhAL3EKztZeWHUM/1zIxmcjOmFcr2Ymj1NreHScsw3llRrsfnsAmod422U87ojnebR9fxtUag0OvDsQTQJrboxoD0XllZi65iT2Xs5BiI8cf79xPxr52m9KCgDulqjgrZAZ3d+MWM7S9296lglxAJlUYnaayt/LA0M6hpsNVgDgpQda4uuxMZDLJNhxPgtjfjiMv85kiNM980Z2MRusAKyfRatQX3Rq7C8GKwBbzj39oTYAgJUHb4o75qbnl2HlQdb1992H2yG2WRCWPRcLmYTD/06l46P/nau18++lzCIxkzJzaDt0iPRDi0Y+mNgnGgDwydbztS5PPXg1D3P/uoipv57E2bQCs8fWVZp2SshU0ziBVMKJy5svZlAdi77iiiqotP+W9WkcZy1fpQe+fy4WbcN8kVuswjsbTtm1I/X59EL0W7AL9y/cjaM3aLsAR6CAhRA383jXSKx5oRcCvTxw+nYBXl2dBJ4HRsdF4YE2lvebMeahDmHoGhWAsko1vt3DpoAW/3NZ3MbgQW0W5IE2jfDF010BAKsSb+Hz7ZdMvjmUqdR4/deTqKjSYEDbRpjUN1q87bVBrRHsLcf1nBL8nHjL7Ng2nUwDwLIb72w4bZf+G8KUUG1FtwCtFDJFmA7y9JDCU+7YWjKlh1QM6HdfysEqvbotW+J5HrM3n0WJSo3MwnKMXX4YS3dfhYamB+2KAhZC3FBcdBA2vdpXnIqI8Ffi/x5rX+/zchyHtwezLMvqwynYcykbG07cBgDMfKSdwU65w7s1xofD2Aqfb/dcw0f/O1/jBTuzoBxjfkjEpSy28unzUV0NzuGn9MAM7Uqsxf9cNtmIrUylxrazrDZOLpPgfEYhlu+/Xu/fV19JRRXytbU7kbXUsAD6HW8pw6Ivz05N4yzVNtwX72mL0uf+fdEu/z6bTqbh+K278PSQ4tEuEVBreHy+/RImrDwqZiaJ7VHAQoibig7xxsZX+mDGkLb47796wq+WqSBL9WsVgl7Ng6BSazD55+PQ8MDQTuHo3rTmdNXEvs3xyXDW8v+nQzfx7u+nxSLU5NR8PL7kAE7dLkCglweWPdvdaE3BU3FR6Bjph6LyKnyx87LRMe28kIUSlRpNAj3x2RNs9eDif67gek6xTX5nQJdd8VXKap1WA4D2EcImiJRh0Xen2HEFt6ZM6BONgW0bQVWlwRu/JqO8sv7dpwVF5ZWY+xerI3ttUCssGRuDhaO6QOkhwf4ruRj61X6sOnSz1p5JxHoUsBDixgK95ZgysBVahfra7Jwcx4n9ZyrVPKQSzmw/mud6R+PLp7tCKuHw24nbeP3Xk/jteCqe/j4R2UUVaBvmi81T+iEuOsjo/aUSDrO1vVjWHUvFrbySGsf8oZ0OGhHTGKNim6B/6xCoqjSY+fsZm6XhhSXNlkwHAboMy607pShVuc6b04lbd8RpGWewV1t+a3Ach8+f6ooQHzkuZRVh3l8Xar0Pz/O4kVuC1UduYcqaJAz4fDfe23SmRuDx1T9XkFtcgeYh3vhXv+bgOA5Px0Xhf1P7oU2YD3KLKzBnyzn0npeA+X9fFANhUn8UsBBCaugRHYQBbVk9zJgeUbX2SXmyexMsfaY75FIJtp7JwIwNp6Gq0iC+fRh+f7UPmgabXynSq0Uw7m/TCGoNj292XTW4La+4Ansv5wBg01Acx2HuiM7wkktx9OYdrDmaUo/fVCdd3KXZsi1CQnwUCPFRgOeBy1m2y/TUx8GruRj5XSKe+88Rp9VT6DY+dFzBrTEhPgp8/pSuzmrr6QyTx/64/zr6zN+FgYv24P82ncXW0xm4mVeKNUdS8PiSA+K00uWsIqzU1sV8+HhHKGS6Gp3WYb7YMrUfPhneEdHBXigsr8KyvdfQf8FuLNx20X6/aANCAQshxKh/P90Nc0d0xgcWdqJ9uFM4fpwQB6UHe1mZMrAlfngu1mjXXGOEFUobk24bTPVsPZMBtYZHlyb+4j5RUUFeeHswy/rM//siNienIbeeGxHqAhbLO6V2asymhf46Y/rN0FbKK9X442Sa2a0ehHqjc+mF2FbfXb7rSGzL78QpIcHAtqF46f4WAIAZG04Znb5bceAGPt16ARkF5ZBLJejVPAhvxrfB4tHdEO6nxLWcEgxfchBrjqRgzuZzUGt4DO4QZrTAXekhxXO9o5Hw1gD88FwsejYPQpWGx7d7ruECrSarN6s73RJCGoZAb7nVezHd36YRdkx7AHdLVegaFWDVfbtFBWBQu1AkXMzG1wlXsHhMDADd6qAnujU2OH5Cn2j873Q6Tqbk4421yQDYyp0+rYLRLtwXcpkEcqkUcpkE3nIpYqMDDT4RV5deYNmSZoMx9I7Gnks5+DnxJl7o17zGflO2kl+qwuSfj+PYzbt4oE0jrHq+Z41jyivV2KEXpCz+5zIe7hhuUY8cWxI3PnTilJC+GUPa4mx6AQ5ezcNL/z2OzVP7wd+T1ShtOZWOj7XL7V8f1BqvPNDSYGXT/W0aYfr6ZOy5lIP3NrEtZBQySa1BvFTCYXDHcAzuGI4pq5Ow9UwGfk68hXlPdjZ6/ObkNJy+XYA2YT5oG+6HNmE+8JLT23N19IwQQmyqabBXrVNAprz5UBskXMzG5lPpmPpgK8gkEpxMyYeEAx7ratgsTirh8OP4OHy35xoOXsvDhYxCXMoqwqUs40WwjQM88fqgVhjZvQlk0prJZWunhABgQNtG6N40AEkp+fh2zzV8+HhHK35by6TeKcWElUdxPYfV9uy9nIOUvNIaz/Gui9koUakR4a9EcUUVLmcVY+uZDAzrGmnzMZnj7FVC1cmkEnwztjuGfXMAN/NKMX1dMpaPj0Pi9Ty8tT4ZANsw9c341gYr2AD2O6yY0AM/7L+Oz7dfglrD49UBrcRtMyzxXO9m2HomA3+cTMPMoe3EYElwKbMI09bptqsA2GbYzUO88X+PtMeg9mF1/t3vNTQlRAhxGZ0a+2NwhzDwPFsF9Ecyy670a90Iob41A4lgH7Z54t9v9MeJ9+Ox9JnuGNerKQa1C0X/1iHo2TwI3aICEOIjR1p+Gd79/Qwe+vc+bE5Oq1HjkW7hxof62DJwNjW15kiKuHmirZy+nY8R3x7E9ZwSRPor0UW7ZYOxup3/afekGt6tMV7ox6ZBvkq44vCtAxy1j5A1grzl+P65WChkEiRczMaMDafx0n9PoFLN45HO4Zg9rGONYEUgkXB4+YGW2DylL+Y92RmvDmxp1WP3ah6ENmE+KKtUi1N2+r7YcQk8D3SI8EO/ViFiXdT1nBK89utJ3MytWYTeUFHAQghxKdPiWS3Ln6cz8Mth1kxuREztWYJgHwUe7RKBz0Z0xn8m9sB//9UL61/qjT+m9MWBdx/E+4+2R5C3HDdyS/DG2mQ89s0BsWMuz/N1mhICgD6tQtC7RTBUag2WVCsYro+d57Mw+vvDyC1WoX2EHzZN6YtXB7QCAGw4kWqwj1NReSUSLmYDAIZ1jcCkftHwU8pwNbsYf55Ot9mYLOEKq4SM6dTYX5yS+T3pNoorqnBfiyB8+XQ3g47P5u4/tmdTeBjJzpnDcRye6x0NAPjl8C2DQPlUaj52nM+ChAO+HtsNv7zQC8ffj8fx9+NxX4sglKrUeGPtSbs0SXRHFLAQQlxKh0g/PNI5HADE3asHdwiv1zmVHlK80L8F9r0zEG891Aa+ShnOZxTiiaUHsfify8gqrICqSgOOA8LqUIfylrbZ3m/HjS/LtkZ2YTle+/UkJv98HGWVavRvHYL1L92HMD8lBrUPRZifArnFKuw4r6tX2Xk+C6oqDVo08kaHCD/4KT0wub9zsix52qLbEB/nrhIy5snuTcTtINpH+OGH8XEO2dn9yZjG8FXIcCO3BAf0NmZctOMSAGBETBOD1gQhPgp8+XQ3+Ht64NTtAiz+x3h/ouKKqgbVXZcCFkKIy5kW3wZChn5IxzB4W7jSqDY+ChleG9Qau98egKGdwlGl4bH4nysY+d0hAECor6JOG9nFRQfhAe3u018lXKnT2NQaHqsO3cSgL/bif6fSIeGAf/VrjhUTe4iN7DykEoyOiwLAOhELtmingx7vGilObUzsG40ALw9czynBllNpdRpTbW7fLTXoJFuqqkJ5JcsGuFqGRTD7sQ5Y++J92PByb5s1W6yNt0KGkbFNAEDcgiLxWh72X8mFh5TDtPjWNe4TGeApZoS+3XMNh6/nibcVlFbiwy3n0PWjHRj4xR78N/EmylS2a47nqihgIYS4nDZhvnimZ1PIJLp0ui2F+Cjw7bju+GoM+xQr1J5EWFG/Up2QZfnjZBquZpvufltQVoklu65g+rpkvLkuGdPWnsS0tSfx2DcHMGfLORRVVKFrVAC2TO2HDx7rUGMKYnTPppBwQOL1PFzLKcadEhUOXGGf2h/rops689XLsnydcBVVVkwrlKqq8E3CFaw8eMPkHlHn0gsw5N/78PDi/fj0z/NQVWnEFUIKmQReDt5HyFISCYf7WgTbLAi21LP3sd2/d13Mwu27pWJ2ZWzPpiaLeB/pHIGn45qA54E31yXjbokKa4+mYOAXe/DToZtQa3jcyivFB5vPoe+CXfj3TtPbW9wLON6e21k6kKXbUxNC3INGw6O0Um1xH5e6yiosx6yNZ7DrYjaeva8pPn3C+NJTS7z483HsOJ+FblEBmDqwFe5v00jM2JRXqrHq0E18u+caCsoqjd7fTynDOw+3w9ieTc3WVTz/0zHsupiNF/o1R4tGPnhv0xl0iPDDX2/0NziuuKIK/Rfswt3SSoyIaYwFI7vUmkE6cCUXMzeexu27LIib2Ccac4Z1MChKvX23FE9+ewjZevvmdG7sj3/1a45p65IR6a/EoVmDzD9ZDdC4Hw/j4NU8xDQNwMmUfCg9JNg3Y6DZ5fAlFVV49Ov9uJlXCl+FDEXazrutQn3wf4+0R8qdUvx44DpS77B/L6WHBM/2aoaXHmhpdCsMV2Tp+zcFLISQBo/neVzOKkbzEO86TQkJLmYW4vElB8WCWH9PDwztFI6WjXzw44HryCpkb/CtQ30wontjeEgk4tSXwkOKhzuGW/Qmk3AhC/9adRwBXh5o2cgHJ27dxcyh7fDyAzVXsPzvVDqmrUuGWsOjd4tgLHsutsbSWoBlfj7beh7rj7OVLI18FcgtrgDPA8/d1wwfPd4REgmHgtJKjFx2CFezi9E2zBevDmyJOVvOiRtHAqyh3p+v9a/xGA3dtrOZePmXE+LPLz3QArOG1r5p6anUfIz87hCqNDx8FTJMe6gNxvduJmbfqtQabD+XhR/2XcOp26yQ3NNDivG9m+HF+1sg2Mp6ojO3C7Dy4A2Mu68ZYpvV3EPM1ihgIYQQJ7iUWYT1x1Pxv1PpBhkIgPWCefOhNhgR09iilSmmqDU8+i/YJa5sAoD97ww0ObWw93IOXv3lBEpUarQO9cHKST3QJNALPM/jfEYhdl/Mxs+Jt8Txju/dDO883A5/ncnAu7+fBs8Dz/RqitmPdcD4FUdx9MYdhPspsfHVPogM8ERGQRmmrU3GkRt3ALCGaz8baW7X0FWpNbh/4W6kF5TDVyHDvncGItDCWp8d5zJxJq0AE/pEmyxo5nke+67k4sudl3EqNR8A4CWX4q3BbfGvfs0tepzz6YUY80MiCsurIJdK8PlTXTC8WtNGW6OAhRBCnEit4XHkRh62JKfjUlYRHu8aiWd6NTXbbdcaX/1zBf/Wrh7p3jQAG1/ta/b4c+kFeP6nY8gqrEAjXwUebBuKvZdzkKnX6r95iDcWjOyCns11G1X+fuI23t5wCjwPRPorxTfb317pjXbhutdatYbHt7uvYumeq3h7cFu8oK2fIYZ+TryJ2ZvP4f8eaY/J99vnOeJ5HrsvZePfO6/gjHbp/rwnO2NsT/Odq6/lFGP094nILVbBVylDUTmbfnp7cBtMGdjKZK+a+qKAhRBC7mGZBeXou2AX1BoeHw7rgIl9a/8EnZ5fhud/OoaLenvqeHpI0bdVMB5sF4Ynuzc2usz3j5NpmL4+GRoe8JBy+GlST/RtFWL0MdQavl7Zo3sdz/PIKa4w2gjRHo/1xY7LWLL7qtgZemC7UKPH3r5biqeWJSKjoBwdI/2w+oVeWLr7KpbvvwEAGBXbBHNHdK7XlKkpFLAQQsg97sudl3H4Wh6Wj4+Dv5dlS3QLyyuxcNtFyCQSDGjbCPe1CLaoF8nW0xn4ds9VvDqgFR7tElHr8cQ18DyPt387jd+TbsNLLsW6F3ujs7ZjsiC7qBxPL0vEzbxStGzkjfUv9RbrXn45fAtztpzT1UA9G2vx35qlKGAhhBBCCCrVGjz/0zHsv5KLEB8FNmlrj06m3EXCxWxsSU5HWn4ZmgR64reXe9dY3r/nUjamrjkJlVqD9S/1RjcrNzatDQUshBBCCAHAtm94+vvDuJBRiDA/BSqqNAYru8L8FFj/Um80C/Y2ev8LGYVIvVOKwR3r13XaGApYCCGEECLKLCjHk98eFFeX+Xt64IE2jfBgu1A82D7UYZ1/q7P0/duxrf4IIYQQ4hTh/kqse6k3tp7JQGyzQMREBUBm5WaOzkQBCyGEENJARAV5GW0w6A7cJ7QihBBCSINFAQshhBBCXB4FLIQQQghxeRSwEEIIIcTlUcBCCCGEEJdHAQshhBBCXB4FLIQQQghxeRSwEEIIIcTlUcBCCCGEEJdHAQshhBBCXB4FLIQQQghxeRSwEEIIIcTlUcBCCCGEEJd3z+zWzPM8AKCwsNDJIyGEEEKIpYT3beF93JR7JmApKioCAERFRTl5JIQQQgixVlFREfz9/U3ezvG1hTRuQqPRID09Hb6+vuA4zmbnLSwsRFRUFFJTU+Hn52ez85Ka6Ll2HHquHYeea8ei59txbPVc8zyPoqIiREZGQiIxXalyz2RYJBIJmjRpYrfz+/n50R+/g9Bz7Tj0XDsOPdeORc+349jiuTaXWRFQ0S0hhBBCXB4FLIQQQghxeRSw1EKhUGDOnDlQKBTOHso9j55rx6Hn2nHouXYser4dx9HP9T1TdEsIIYSQexdlWAghhBDi8ihgIYQQQojLo4CFEEIIIS6PAhZCCCGEuDwKWAghhBDi8ihgqcXSpUsRHR0NpVKJXr164ejRo84eklubN28eevToAV9fX4SGhuKJJ57ApUuXDI4pLy/HlClTEBwcDB8fH4wcORJZWVlOGvG9Y/78+eA4DtOmTROvo+fattLS0vDss88iODgYnp6e6Ny5M44fPy7ezvM8Zs+ejYiICHh6eiI+Ph5Xrlxx4ojdk1qtxgcffIDmzZvD09MTLVu2xCeffGKweR4913Wzb98+DBs2DJGRkeA4Dn/88YfB7ZY8r3fu3MG4cePg5+eHgIAA/Otf/0JxcXH9B8cTk9auXcvL5XJ+xYoV/Llz5/jJkyfzAQEBfFZWlrOH5raGDBnCr1y5kj979iyfnJzMP/LII3zTpk354uJi8ZiXX36Zj4qK4hMSEvjjx4/z9913H9+nTx8njtr9HT16lI+Ojua7dOnCv/HGG+L19Fzbzp07d/hmzZrxEydO5I8cOcJfv36d3759O3/16lXxmPnz5/P+/v78H3/8wZ86dYp//PHH+ebNm/NlZWVOHLn7+eyzz/jg4GD+zz//5G/cuMH/9ttvvI+PD//VV1+Jx9BzXTd//fUX/3//93/8xo0beQD8pk2bDG635Hl9+OGH+a5du/KHDx/m9+/fz7dq1YofO3ZsvcdGAYsZPXv25KdMmSL+rFar+cjISH7evHlOHNW9JTs7mwfA7927l+d5ns/Pz+c9PDz43377TTzmwoULPAA+MTHRWcN0a0VFRXzr1q35nTt38g888IAYsNBzbVvvvvsu369fP5O3azQaPjw8nP/888/F6/Lz83mFQsH/+uuvjhjiPePRRx/ln3/+eYPrnnzySX7cuHE8z9NzbSvVAxZLntfz58/zAPhjx46Jx/z99988x3F8WlpavcZDU0ImqFQqnDhxAvHx8eJ1EokE8fHxSExMdOLI7i0FBQUAgKCgIADAiRMnUFlZafC8t2vXDk2bNqXnvY6mTJmCRx991OA5Bei5trUtW7YgLi4OTz31FEJDQxETE4Ply5eLt9+4cQOZmZkGz7e/vz969epFz7eV+vTpg4SEBFy+fBkAcOrUKRw4cABDhw4FQM+1vVjyvCYmJiIgIABxcXHiMfHx8ZBIJDhy5Ei9Hv+e2a3Z1nJzc6FWqxEWFmZwfVhYGC5evOikUd1bNBoNpk2bhr59+6JTp04AgMzMTMjlcgQEBBgcGxYWhszMTCeM0r2tXbsWSUlJOHbsWI3b6Lm2revXr+O7777D9OnT8d577+HYsWN4/fXXIZfLMWHCBPE5NfaaQs+3dWbOnInCwkK0a9cOUqkUarUan332GcaNGwcA9FzbiSXPa2ZmJkJDQw1ul8lkCAoKqvdzTwELcZopU6bg7NmzOHDggLOHck9KTU3FG2+8gZ07d0KpVDp7OPc8jUaDuLg4zJ07FwAQExODs2fPYtmyZZgwYYKTR3dvWb9+PVavXo01a9agY8eOSE5OxrRp0xAZGUnP9T2MpoRMCAkJgVQqrbFiIisrC+Hh4U4a1b1j6tSp+PPPP7F79240adJEvD48PBwqlQr5+fkGx9Pzbr0TJ04gOzsb3bt3h0wmg0wmw969e/H1119DJpMhLCyMnmsbioiIQIcOHQyua9++PVJSUgBAfE7pNaX+ZsyYgZkzZ2LMmDHo3LkznnvuObz55puYN28eAHqu7cWS5zU8PBzZ2dkGt1dVVeHOnTv1fu4pYDFBLpcjNjYWCQkJ4nUajQYJCQno3bu3E0fm3niex9SpU7Fp0ybs2rULzZs3N7g9NjYWHh4eBs/7pUuXkJKSQs+7lQYNGoQzZ84gOTlZ/IqLi8O4cePE7+m5tp2+ffvWWKJ/+fJlNGvWDADQvHlzhIeHGzzfhYWFOHLkCD3fViotLYVEYvj2JZVKodFoANBzbS+WPK+9e/dGfn4+Tpw4IR6za9cuaDQa9OrVq34DqFfJ7j1u7dq1vEKh4H/66Sf+/Pnz/IsvvsgHBATwmZmZzh6a23rllVd4f39/fs+ePXxGRob4VVpaKh7z8ssv802bNuV37drFHz9+nO/duzffu3dvJ4763qG/Sojn6bm2paNHj/IymYz/7LPP+CtXrvCrV6/mvby8+F9++UU8Zv78+XxAQAC/efNm/vTp0/zw4cNpqW0dTJgwgW/cuLG4rHnjxo18SEgI/84774jH0HNdN0VFRfzJkyf5kydP8gD4L7/8kj958iR/69Ytnucte14ffvhhPiYmhj9y5Ah/4MABvnXr1rSs2RG++eYbvmnTprxcLud79uzJHz582NlDcmsAjH6tXLlSPKasrIx/9dVX+f9v545tE4aiMIwqlS2EkFzRUVC5YAsmoHSFmIABEIuwBgN4Dk9ARQMVDT9dlEQpoiQSL9E5rV9xdYunr3hy0zQZjUZZrVY5nU7PG/of+Rgsdv27jsdjFotFqqpK27Y5HA7vvt/v9+z3+0yn01RVleVymWEYnjTt33W5XLLdbjObzVLXdebzeXa7XW632+sZu/6evu8/vaPX63WSr+31fD6n67qMx+NMJpNsNptcr9cfz/aSvPk1IABAgbxhAQCKJ1gAgOIJFgCgeIIFACieYAEAiidYAIDiCRYAoHiCBQAonmABAIonWACA4gkWAKB4D2ZgtVoAV5hrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_losses, label='train')\n",
    "plt.plot(range(epochs), test_losses, label='test')\n",
    "plt.legend()\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), train_f1_scores, label='train')\n",
    "plt.plot(range(epochs), test_f1_scores, label='test')\n",
    "plt.legend()\n",
    "plt.title('F1 Score Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6950240770465489"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Loss: 0.1526340704407543 Test Loss: 0.14869250311923865\n",
      "Epoch: 2 Train Loss: 0.14051736576259136 Test Loss: 0.14687698493940762\n",
      "Epoch: 3 Train Loss: 0.13930131083279848 Test Loss: 0.1492627762025966\n",
      "Epoch: 4 Train Loss: 0.13634079025611281 Test Loss: 0.14060143845530745\n",
      "Epoch: 5 Train Loss: 0.1347521905735135 Test Loss: 0.14703113193543385\n",
      "Epoch: 6 Train Loss: 0.13232848938852548 Test Loss: 0.14154507608090441\n",
      "Epoch: 7 Train Loss: 0.1326153350546956 Test Loss: 0.14068467730876452\n",
      "Epoch: 8 Train Loss: 0.1324405610397458 Test Loss: 0.13932220144465138\n",
      "Epoch: 9 Train Loss: 0.131782396119833 Test Loss: 0.14125056325282437\n",
      "Epoch: 10 Train Loss: 0.13175879689604045 Test Loss: 0.14648314563039774\n",
      "Epoch: 11 Train Loss: 0.13110668652057647 Test Loss: 0.146717376807651\n",
      "Epoch: 12 Train Loss: 0.13064057995304465 Test Loss: 0.13956380608720712\n",
      "Epoch: 13 Train Loss: 0.13013650746494532 Test Loss: 0.13868924993843126\n",
      "Epoch: 14 Train Loss: 0.1324908905029297 Test Loss: 0.14302684942754312\n",
      "Epoch: 15 Train Loss: 0.13184555504843593 Test Loss: 0.14171883116622036\n",
      "Epoch: 16 Train Loss: 0.13196781535148622 Test Loss: 0.1388367102407038\n",
      "Epoch: 17 Train Loss: 0.13291161734461784 Test Loss: 0.1420994291540247\n",
      "Epoch: 18 Train Loss: 0.13326074366867544 Test Loss: 0.1386129145328991\n",
      "Epoch: 19 Train Loss: 0.13492534762471914 Test Loss: 0.14244162747130606\n",
      "Epoch: 20 Train Loss: 0.13139739384502172 Test Loss: 0.14368852695967918\n",
      "Epoch: 21 Train Loss: 0.13142002223283053 Test Loss: 0.14288849545458254\n",
      "Epoch: 22 Train Loss: 0.13230439632982016 Test Loss: 0.13963815606178376\n",
      "Epoch: 23 Train Loss: 0.13392135080993176 Test Loss: 0.14182566085491127\n",
      "Epoch: 24 Train Loss: 0.13635704700648785 Test Loss: 0.15433335180629415\n",
      "Epoch: 25 Train Loss: 0.13524672675579785 Test Loss: 0.14078741092770436\n",
      "Epoch: 26 Train Loss: 0.13378571036309003 Test Loss: 0.1394754292520757\n",
      "Epoch: 27 Train Loss: 0.13591615069806576 Test Loss: 0.13853290859467018\n",
      "Epoch: 28 Train Loss: 0.1325754264205694 Test Loss: 0.1385954023419192\n",
      "Epoch: 29 Train Loss: 0.13427426292449235 Test Loss: 0.1433531889043296\n",
      "Epoch: 30 Train Loss: 0.13469223269075156 Test Loss: 0.14131437251552606\n",
      "Epoch: 31 Train Loss: 0.1371705699518323 Test Loss: 0.14086569793903217\n",
      "Epoch: 32 Train Loss: 0.1351855840444565 Test Loss: 0.1408442289303667\n",
      "Epoch: 33 Train Loss: 0.1336997237548232 Test Loss: 0.1438463185958493\n",
      "Epoch: 34 Train Loss: 0.1330344438686967 Test Loss: 0.14495772495865822\n",
      "Epoch: 35 Train Loss: 0.1331468239083886 Test Loss: 0.14815238794198812\n",
      "Epoch: 36 Train Loss: 0.13152078477293253 Test Loss: 0.13939848717766257\n",
      "Epoch: 37 Train Loss: 0.13264257504343988 Test Loss: 0.14189826283223048\n",
      "Epoch: 38 Train Loss: 0.13327119922488928 Test Loss: 0.1402488180671256\n",
      "Epoch: 39 Train Loss: 0.13478581951856614 Test Loss: 0.14237110081096047\n",
      "Epoch: 40 Train Loss: 0.13579754901975394 Test Loss: 0.13906018629360695\n",
      "Epoch: 41 Train Loss: 0.1348981971040368 Test Loss: 0.14317146503625397\n",
      "Epoch: 42 Train Loss: 0.13577983733564616 Test Loss: 0.13820216368538693\n",
      "Epoch: 43 Train Loss: 0.13341042492836713 Test Loss: 0.1387003249944018\n",
      "Epoch: 44 Train Loss: 0.13363756330907345 Test Loss: 0.14017989977408712\n",
      "Epoch: 45 Train Loss: 0.13538204903006554 Test Loss: 0.13917324396844108\n",
      "Epoch: 46 Train Loss: 0.13675103229135274 Test Loss: 0.14143947450616678\n",
      "Epoch: 47 Train Loss: 0.13584990126043558 Test Loss: 0.13717977798427827\n",
      "Epoch: 48 Train Loss: 0.13709022836983203 Test Loss: 0.1443457177902658\n",
      "Epoch: 49 Train Loss: 0.13692729345858098 Test Loss: 0.141197889382704\n",
      "Epoch: 50 Train Loss: 0.13617921455949544 Test Loss: 0.1423197834285351\n",
      "Epoch: 51 Train Loss: 0.13425949480980634 Test Loss: 0.14294986140589935\n",
      "Epoch: 52 Train Loss: 0.13349155960977077 Test Loss: 0.1407354674108636\n",
      "Epoch: 53 Train Loss: 0.13401768502295017 Test Loss: 0.13990119151985303\n",
      "Epoch: 54 Train Loss: 0.13333379747718574 Test Loss: 0.139871242000891\n",
      "Epoch: 55 Train Loss: 0.13412219479531048 Test Loss: 0.13907054449303652\n",
      "Epoch: 56 Train Loss: 0.13149778650701047 Test Loss: 0.13902284327549294\n",
      "Epoch: 57 Train Loss: 0.13564395278245212 Test Loss: 0.14054000419906723\n",
      "Epoch: 58 Train Loss: 0.1340905551224947 Test Loss: 0.1399734723218047\n",
      "Epoch: 59 Train Loss: 0.13197232196778058 Test Loss: 0.13965589858401126\n",
      "Epoch: 60 Train Loss: 0.13158424526154994 Test Loss: 0.1425027075363472\n",
      "Epoch: 61 Train Loss: 0.1318368326112628 Test Loss: 0.14235604149750627\n",
      "Epoch: 62 Train Loss: 0.1347949788093567 Test Loss: 0.13969620840011027\n",
      "Epoch: 63 Train Loss: 0.1333684947296977 Test Loss: 0.14254160932958507\n",
      "Epoch: 64 Train Loss: 0.1339594266295433 Test Loss: 0.14426212024669677\n",
      "Epoch: 65 Train Loss: 0.1348241115093231 Test Loss: 0.14290117682776035\n",
      "Epoch: 66 Train Loss: 0.13190846762210132 Test Loss: 0.1424348132250408\n",
      "Epoch: 67 Train Loss: 0.13112528730854392 Test Loss: 0.14053899328858135\n",
      "Epoch: 68 Train Loss: 0.13305263328701258 Test Loss: 0.14304080520408413\n",
      "Epoch: 69 Train Loss: 0.13573186918944122 Test Loss: 0.14696326917602706\n",
      "Epoch: 70 Train Loss: 0.13511144500374794 Test Loss: 0.14295070624937073\n",
      "Epoch: 71 Train Loss: 0.13421658459305763 Test Loss: 0.13989228876039814\n",
      "Epoch: 72 Train Loss: 0.13484560939222573 Test Loss: 0.14214633005900315\n",
      "Epoch: 73 Train Loss: 0.1350482938796282 Test Loss: 0.14799519416879112\n",
      "Epoch: 74 Train Loss: 0.13553944560438394 Test Loss: 0.14137050402335846\n",
      "Epoch: 75 Train Loss: 0.13484293741583825 Test Loss: 0.14327515928616252\n",
      "Epoch: 76 Train Loss: 0.13192167946994304 Test Loss: 0.140222802222632\n",
      "Epoch: 77 Train Loss: 0.13462157091349364 Test Loss: 0.14053104466761643\n",
      "Epoch: 78 Train Loss: 0.13626920694410802 Test Loss: 0.14323841781614308\n",
      "Epoch: 79 Train Loss: 0.13665232139974834 Test Loss: 0.1465869534213227\n",
      "Epoch: 80 Train Loss: 0.1352460134163499 Test Loss: 0.14182866453981627\n",
      "Epoch: 81 Train Loss: 0.13631834449768065 Test Loss: 0.14747139705589024\n",
      "Epoch: 82 Train Loss: 0.13623308642953635 Test Loss: 0.14061126817529573\n",
      "Epoch: 83 Train Loss: 0.13445246528983115 Test Loss: 0.14863537533131366\n",
      "Epoch: 84 Train Loss: 0.13835435093492268 Test Loss: 0.1416860953770792\n",
      "Epoch: 85 Train Loss: 0.13618679773956538 Test Loss: 0.147613329116624\n",
      "Epoch: 86 Train Loss: 0.13938158263117076 Test Loss: 0.14262633949827652\n",
      "Epoch: 87 Train Loss: 0.13585760975033045 Test Loss: 0.14216870688401853\n",
      "Epoch: 88 Train Loss: 0.13397336530685425 Test Loss: 0.14212552799631994\n",
      "Epoch: 89 Train Loss: 0.13287215873152017 Test Loss: 0.1448624098953157\n",
      "Epoch: 90 Train Loss: 0.136034265576303 Test Loss: 0.14034866508298788\n",
      "Epoch: 91 Train Loss: 0.13465775187015533 Test Loss: 0.14008148494786538\n",
      "Epoch: 92 Train Loss: 0.1357853044733405 Test Loss: 0.14390179512802118\n",
      "Epoch: 93 Train Loss: 0.13393635565191508 Test Loss: 0.14069271433991365\n",
      "Epoch: 94 Train Loss: 0.13518347979187964 Test Loss: 0.14241675948932433\n",
      "Epoch: 95 Train Loss: 0.13690175405517221 Test Loss: 0.14144366349989232\n",
      "Epoch: 96 Train Loss: 0.13428971334844828 Test Loss: 0.14309407089250728\n",
      "Epoch: 97 Train Loss: 0.13576276381909846 Test Loss: 0.1426971914401403\n",
      "Epoch: 98 Train Loss: 0.13661041376143693 Test Loss: 0.14182051071248497\n",
      "Epoch: 99 Train Loss: 0.1367015906125307 Test Loss: 0.13934247589078003\n",
      "Epoch: 100 Train Loss: 0.13584158542454242 Test Loss: 0.14173029910047025\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "lstm = LSTMModel(hidden_size=128, out_channels=40).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters())\n",
    "train_losses, test_losses, train_f1_scores, test_f1_scores = train(criterion, optimizer, lstm, lstm_train_dataloader3, lstm_test_dataloader3, epochs=epochs, save_best=True, save_name='best_rnn_model2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7133956386292835\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('best_rnn_model2.pt')\n",
    "model.eval()\n",
    "real = []\n",
    "pred = [] \n",
    "for x, y in lstm_test_dataloader3:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    real.append(y)\n",
    "    out = model(x)\n",
    "    pred.append(torch.argmax(out, dim=1))\n",
    "print(f1_score(torch.cat(real).cpu(), torch.cat(pred).cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hw1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
